<!DOCTYPE NETSCAPE-Bookmark-file-1>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=UTF-8">
<TITLE>Raindrop.io Bookmarks</TITLE>
<H1>Raindrop.io Bookmarks</H1>
<DL><p>
	<DT><H3>Export</H3>
	<DL><p>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-schema" ADD_DATE="1724170306" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-schema" DATA-IMPORTANT="false">CREATE SCHEMA | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724170306">TRANSIENT

Specifies a schema as transient.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-approximate-percentile-values" ADD_DATE="1724071362" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-approximate-percentile-values" DATA-IMPORTANT="false">Estimating Percentile Values | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724071362">The following Aggregate functions are provided for using t-Digest to approximate percentile values:

APPROX_PERCENTILE: Returns an approximation of the desired percentile value.

APPROX_PERCENTILE_ACCUMULATE: Skips the final estimation step and, instead, returns the intermediate t-Digest state at the end of an aggregation.

APPROX_PERCENTILE_COMBINE: Combines (i.e. merges) multiple input states into a single output state.

APPROX_PERCENTILE_ESTIMATE: Computes a percentile estimate of a t-Digest state produced by APPROX_PERCENTILE_ACCUMULATE or APPROX_PERCENTILE_COMBINE.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-approximate-frequent-values" ADD_DATE="1724071343" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-approximate-frequent-values" DATA-IMPORTANT="false">Estimating Frequent Values | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724071375">The following Aggregate functions are provided for using Space-Saving to estimate frequent values:

APPROX_TOP_K: Returns an approximation of frequent values in the input.

APPROX_TOP_K_ACCUMULATE: Skips the final estimation step and returns the Space-Saving state at the end of an aggregation.

APPROX_TOP_K_COMBINE: Combines (i.e. merges) input states into a single output state.

APPROX_TOP_K_ESTIMATE: Computes a cardinality estimate of a Space-Saving state produced by APPROX_TOP_K_ACCUMULATE and APPROX_TOP_K_COMBINE.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-approximate-similarity" ADD_DATE="1724071290" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-approximate-similarity" DATA-IMPORTANT="false">Estimating Similarity of Two or More Sets | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724071290">Snowflake uses MinHash for estimating the approximate similarity between two or more data sets. The MinHash scheme compares sets without computing the intersection or union of the sets, which enables efficient and effective estimation.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724071310">The following Aggregate functions are provided for estimating approximate similarity using MinHash:

MINHASH: Returns a MinHash state containing a MinHash array of length k (input argument).

MINHASH_COMBINE: Combines two (or more) input MinHash states into a single output MinHash state.

APPROXIMATE_SIMILARITY (or APPROXIMATE_JACCARD_INDEX): Returns an estimation of the similarity (Jaccard index) of input sets based on their MinHash states.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-arrays-for-distinct-counts" ADD_DATE="1724071269" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-arrays-for-distinct-counts" DATA-IMPORTANT="false">Using Arrays to Compute Distinct Values for Hierarchical Aggregations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724071269">If you are counting distinct values for hierarchical aggregations (e.g. multiple grouping sets, rollups, or cubes), you can improve performance by producing ARRAYs that contain the distinct values and computing the number of distinct values from these ARRAYs. Using this approach can be faster than using COUNT(DISTINCT &lt;expr&gt;).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-bitmaps-for-distinct-counts" ADD_DATE="1724071245" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-bitmaps-for-distinct-counts" DATA-IMPORTANT="false">Using Bitmaps to Compute Distinct Values for Hierarchical Aggregations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724071245">If you are counting distinct values for hierarchical aggregations (e.g. multiple grouping sets, rollups, or cubes), you can improve performance by producing bitmaps that represent the distinct values and computing the number of distinct values from these bitmaps. Using this approach can be faster than using COUNT(DISTINCT &lt;expr&gt;).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url" ADD_DATE="1724069610" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fget_presigned_url" DATA-IMPORTANT="false">GET_PRESIGNED_URL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724069610">Server-side encryption is required on the internal or external stage.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/build_scoped_file_url" ADD_DATE="1724069405" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fbuild_scoped_file_url" DATA-IMPORTANT="false">BUILD_SCOPED_FILE_URL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724069405">A scoped URL is encoded and permits access to a specified file for a limited period of time. The scoped URL in the output is valid for the caller until the persisted query result period ends (until the results cache expires). That period is currently 24 hours.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions-system" ADD_DATE="1724010475" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions-system" DATA-IMPORTANT="false">System functions | Snowflake Documentation</A>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/execute-task" ADD_DATE="1724009235" LAST_MODIFIED="1730207787" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fexecute-task" DATA-IMPORTANT="false">EXECUTE TASK | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724009235">EXECUTE TASK does not automatically resume child tasks in the task graph. The command skips any child tasks that are suspended.

To recursively resume all dependent tasks tied to a root task in a task graph, query the SYSTEM$TASK_DEPENDENTS_ENABLE</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/desc-task" ADD_DATE="1724008818" LAST_MODIFIED="1730207773" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fdesc-task" DATA-IMPORTANT="false">DESCRIBE TASK | Snowflake Documentation</A>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-task" ADD_DATE="1724007951" LAST_MODIFIED="1730207790" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-task" DATA-IMPORTANT="false">CREATE TASK | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1724008332">The following are supported in a task WHEN clause:

SYSTEM$STREAM_HAS_DATA is supported for evaluation in the SQL expression.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/show-pipes" ADD_DATE="1724000746" LAST_MODIFIED="1730207797" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fshow-pipes" DATA-IMPORTANT="false">SHOW PIPES | Snowflake Documentation</A>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/desc-pipe" ADD_DATE="1724000685" LAST_MODIFIED="1730207809" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fdesc-pipe" DATA-IMPORTANT="false">DESCRIBE PIPE | Snowflake Documentation</A>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-pipe" ADD_DATE="1724000473" LAST_MODIFIED="1730207813" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-pipe" DATA-IMPORTANT="false">ALTER PIPE | Snowflake Documentation</A>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/drop-file-format" ADD_DATE="1723978458" LAST_MODIFIED="1730207818" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fdrop-file-format" DATA-IMPORTANT="false">DROP FILE FORMAT | Snowflake Documentation</A>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/udf/udf-overview" ADD_DATE="1723969973" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fudf%2Fudf-overview" DATA-IMPORTANT="false">User-defined functions overview | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723969973">Supported languages¶

You write a function’s handler – its logic – in any of several programming languages. Each language allows you to manipulate data within the constraints of the language and its runtime environment. Regardless of the handler language, you create the procedure itself in the same way using SQL, specifying your handler and handler language.

You can write a handler in any of the following languages:

Language

	

Developer Guides




Java

	

Java UDFs

Java UDTFs




JavaScript

	

JavaScript UDFs

JavaScript UDTFs




Python

	

Python UDFs

Python UDTFs




Scala

	

Scala UDFs




SQL

	

SQL UDFs

SQL UDTFs</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-pipe#usage-notes" ADD_DATE="1723969682" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-pipe%23usage-notes" DATA-IMPORTANT="false">CREATE PIPE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723969682">All COPY INTO &lt;table&gt; copy options are supported except for the following:

FILES = ( &#39;file_name1&#39; [ , &#39;file_name2&#39;, ... ] )

ON_ERROR = ABORT_STATEMENT

SIZE_LIMIT = num

PURGE = TRUE | FALSE (i.e. automatic purging while loading)

FORCE = TRUE | FALSE

Note that you can manually remove files from an internal (i.e. Snowflake) stage (after they’ve been loaded) using the REMOVE command.

RETURN_FAILED_ONLY = TRUE | FALSE

VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ecosystem-etl" ADD_DATE="1723967563" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fecosystem-etl" DATA-IMPORTANT="false">Data Integration | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723967563">In addition, the scope of data integration has expanded to include a wider range of operations, including:

Data preparation.

Data migration, movement, and management.

Data warehouse automation.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges#label-create-data-exchange-listing-on-account" ADD_DATE="1723965607" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-exchange-marketplace-privileges%23label-create-data-exchange-listing-on-account" DATA-IMPORTANT="false">Grant privileges to other roles | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723965607">Global CREATE DATA EXCHANGE LISTING privilege¶

If the global CREATE DATA EXCHANGE LISTING privilege is granted to a role, any user with the role can create a listing or provider profile. As the creator and therefore owner of the listing, the role can be used to perform all tasks on the listing, including:

Create listings.

Modify listings properties.

View listings.

View incoming listing requests.

Reject listing requests.

Submit listings for approval.

Publish a listings.

Create and view provider profiles.</mark>
		<DT><A HREF="https://other-docs.snowflake.com/en/collaboration/provider-listings-preparing" ADD_DATE="1723965570" LAST_MODIFIED="1730207824" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fother-docs.snowflake.com%2Fen%2Fcollaboration%2Fprovider-listings-preparing" DATA-IMPORTANT="false">Prepare data for a listing | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723965570">If you choose to limit trial consumers to specific data and functionality, create a single share for your paid listing and use secure views and a system function provided by Snowflake, SYSTEM$IS_LISTING_PURCHASED, to control which data is visible to trial consumers and which data is available only to paying consumers.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724070912">You cannot transfer the OWNERSHIP privilege for a share.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724071082">When you offer a paid listing on the Snowflake Marketplace, you must offer consumers the ability to trial the listing before they purchase it. Trials are optional for paid private listings.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724071118">If your listing includes a secure user-defined function (UDF), you cannot limit visibility of the UDF. Both paying customers and trial customers of your listing can view the secure UDF.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724071147">When you configure your listing, you can choose to offer it in different regions. Offering listings in other regions requires replicating data.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-external-table" ADD_DATE="1723965525" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-external-table" DATA-IMPORTANT="false">ALTER EXTERNAL TABLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723965525">ALTER EXTERNAL TABLE¶

Modifies the properties, columns, or constraints for an existing external table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-approximate-cardinality" ADD_DATE="1723965472" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-approximate-cardinality" DATA-IMPORTANT="false">Estimating the Number of Distinct Values | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723965472">HyperLogLog is a state-of-the-art cardinality estimation algorithm, capable of estimating distinct cardinalities of trillions of rows with an average relative error of a few percent.

HyperLogLog can be used in place of COUNT(DISTINCT …) in situations where estimating cardinality is acceptable.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-time-travel#restoring-objects" ADD_DATE="1723965317" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-time-travel%23restoring-objects" DATA-IMPORTANT="false">Understanding &amp; using Time Travel | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723965317">If an object with the same name already exists, UNDROP fails. You must rename the existing object, which then enables you to restore the previous version of the object.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/info-schema" ADD_DATE="1723965272" LAST_MODIFIED="1730207829" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Finfo-schema" DATA-IMPORTANT="false">Snowflake Information Schema | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723965272">What is INFORMATION_SCHEMA?¶

Each database created in your account automatically includes a built-in, read-only schema named INFORMATION_SCHEMA. The schema contains the following objects:

Views for all the objects contained in the database, as well as views for account-level objects (i.e. non-database objects such as roles, warehouses, and databases)

Table functions for historical and usage data across your account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723982099">COMPLETE_TASK_GRAPHS

	

60 minutes

	

Results returned only for the ACCOUNTADMIN role, the task owner (i.e. the role with the OWNERSHIP privilege on the task), or a role with the global MONITOR EXECUTION privilege.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-overview#roles" ADD_DATE="1723965232" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-overview%23roles" DATA-IMPORTANT="false">Overview of Access Control | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723965232">Although additional privileges can be granted to the system-defined roles, it is not recommended. System-defined roles are created with privileges related to account-management. As a best practice, it is not recommended to mix account-management privileges and entity-specific privileges in the same role. If additional privileges are needed, Snowflake recommends granting the additional privileges to a custom role and assigning the custom role to the system-defined role.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724071812">Discretionary Access Control (DAC): Each object has an owner, who can in turn grant access to that object.

Role-based Access Control (RBAC): Access privileges are assigned to roles, which are in turn assigned to users.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724072058">in a managed access schema, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724072290">There are a small number of system-defined roles in a Snowflake account. System-defined roles cannot be dropped. In addition, the privileges granted to these roles by Snowflake cannot be revoked.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724072322">A role owner (i.e. the role that has the OWNERSHIP privilege on the role) does not inherit the privileges of the owned role. Privilege inheritance is only possible within a role hierarchy.</mark>
		<DD><mark COLOR="green" ADD_DATE="1724073231">Every active user session has a “current role,” also referred to as a primary role. When a session is initiated (e.g. a user connects via JDBC/ODBC or logs in to the Snowflake web interface), the current role is determined based on the following criteria:

If a role was specified as part of the connection and that role is a role that has already been granted to the connecting user, the specified role becomes the current role.

If no role was specified and a default role has been set for the connecting user, that role becomes the current role.

If no role was specified and a default role has not been set for the connecting user, the system role PUBLIC is used.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724073291">while a session must have exactly one active primary role at a time, one can activate any number of secondary roles at the same time.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724073303">A database role can neither be a primary nor a secondary role.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724073354">There is no concept of a “super-user” or “super-role” in Snowflake that can bypass authorization checks. All access requires appropriate access privileges.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/result_scan#usage-notes" ADD_DATE="1723921647" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fresult_scan%23usage-notes" DATA-IMPORTANT="false">RESULT_SCAN | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723921647">Returns the result set of a previous command (within 24 hours of when you executed the query) as if the result was a table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724075039">only the user who runs the original query can use the RESULT_SCAN function to process the output of the query. Even a user with the ACCOUNTADMIN privilege cannot access the results of another user’s query by calling RESULT_SCAN.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724075061">If the original query is executed via a task, the role that owns the task, instead of a specific user, triggers and runs the query. If a user or a task is operating with the same role, they can use RESULT_SCAN to access the query results.</mark>
		<DT><A HREF="https://docs.snowflake.com/developer-guide/stored-procedure/stored-procedures-javascript" ADD_DATE="1723921608" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fdeveloper-guide%2Fstored-procedure%2Fstored-procedures-javascript" DATA-IMPORTANT="false">Writing stored procedures in JavaScript | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723921608">JavaScript delimiters¶

The JavaScript portion of the stored procedure code must be enclosed within either single quotes &#39; or double dollar signs $$.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/network-policies#activating-network-policies-for-individual-users" ADD_DATE="1723921404" LAST_MODIFIED="1730207832" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fnetwork-policies%23activating-network-policies-for-individual-users" DATA-IMPORTANT="false">Controlling network traffic with network policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723921404">Only the role with the OWNERSHIP privilege on both the user and the network policy, or a higher role, can activate a network policy for an individual user.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723921419">Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global ATTACH POLICY privilege can activate a network policy for an account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724075283">A security administrator (or higher) can use a network policy to allow or deny access to a request based on its origin.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724075338">Network policies that existed before the introduction of network rules still work. However, all new network policies should use network rules, not the ALLOWED_IP_LIST and BLOCKED_IP_LIST parameters, to control access from IP addresses. Best practice is to avoid using both ways to restrict access in the same network policy.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724075368">Activate the network policy for an account, user, or security integration.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724075521">Account:

Network policies applied to an account are the most general network policies. They are overridden by network policies applied to a security integration or user.

Security Integration:

Network policies applied to a security integration override network policies applied to the account, but are overridden by a network policy applied to a user.

User:

Network policies applied to a user are the most specific network policies. They override both accounts and security integrations.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724075813">when a user-level network policy is associated with the user and the user is already logged into Snowflake, if the user’s network location does not match the user-level network policy rules, Snowflake prevents the user from executing further queries.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets#label-snowsight-worksheet-session-context" ADD_DATE="1723921305" LAST_MODIFIED="1730207837" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-worksheets%23label-snowsight-worksheet-session-context" DATA-IMPORTANT="false">Managing and using worksheets in Snowsight | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723921305">Each worksheet is a unique session and can use roles different from the role you select in the user menu (your active role). Changing your active role does not change the role assigned to the worksheet with the context selector.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724076086">You must be granted the ACCOUNTADMIN role to recover worksheets of dropped users.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-mfa#label-mfa-token-caching" ADD_DATE="1723921054" LAST_MODIFIED="1730207843" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-mfa%23label-mfa-token-caching" DATA-IMPORTANT="false">Multi-factor authentication (MFA) | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723921054">A cached MFA token is valid for up to four hours.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724076395">MFA login is designed primarily for connecting to Snowflake through the web interface, but is also fully-supported by SnowSQL and the Snowflake JDBC and ODBC drivers.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/object-tagging#specify-tag-values" ADD_DATE="1723920824" LAST_MODIFIED="1730207847" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fobject-tagging%23specify-tag-values" DATA-IMPORTANT="false">Object Tagging | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920836">The ALLOWED_VALUES tag property enables specifying the possible string values that can be assigned to the tag when the tag is set on an object. The maximum number of possible string values for a single tag is 300.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724076647">A tag is a schema-level object that can be assigned to another Snowflake object.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724076848">The maximum number of 50 unique tags includes dropped tags for a time period of 24 hours starting from when the tag is dropped using a DROP TAG statement. The reason for this time period is to allow the user who dropped the tag to execute an UNDROP TAG statement, if necessary. When the UNDROP TAG operation executes within the 24-hour time interval, Snowflake restores the tag assignments (i.e. references) that were current prior to the drop operation.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/last_query_id" ADD_DATE="1723920783" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Flast_query_id" DATA-IMPORTANT="false">LAST_QUERY_ID | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920783">Usage notes¶

Positive numbers start with the first query executed in the session. For example:

LAST_QUERY_ID(1) returns the first query.

LAST_QUERY_ID(2) returns the second query.

LAST_QUERY_ID(6) returns the sixth query.

Etc.

Negative numbers start with the most recently-executed query in the session. For example:

LAST_QUERY_ID(-1) returns the most recently-executed query (equivalent to LAST_QUERY_ID()).

LAST_QUERY_ID(-2) returns the second most recently-executed query.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/insert" ADD_DATE="1723920691" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Finsert" DATA-IMPORTANT="false">INSERT | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920691">OVERWRITE

Specifies that the target table should be truncated before inserting the values into the table. Note that specifying this option does not affect the access control privileges on the table.

INSERT statements with OVERWRITE can be processed within the scope of the current transaction, which avoids DDL statements that commit a transaction, such as:</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/kafka-connector-overview" ADD_DATE="1723920579" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fkafka-connector-overview" DATA-IMPORTANT="false">Overview of the Kafka connector | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920579">Each Kafka message is passed to Snowflake in JSON format or Avro format. The Kafka connector stores that formatted information in a single column of type VARIANT. The data is not parsed, and the data is not split into multiple columns in the Snowflake table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#label-exploding-join" ADD_DATE="1723920531" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-activity%23label-exploding-join" DATA-IMPORTANT="false">Monitor query activity with Query History | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920531">“Exploding” joins¶

One of the common mistakes SQL users make is joining tables without providing a join condition (resulting in a “Cartesian product”), or providing a condition where records from one table match multiple records from another table. For such queries, the Join operator produces significantly (often by orders of magnitude) more tuples than it consumes.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/name-resolution" ADD_DATE="1723920480" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fname-resolution" DATA-IMPORTANT="false">Object name resolution | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920480">The SEARCH_PATH is not used inside views or UDFs. All unqualifed objects in a view or UDF definition will be resolved in the view’s or UDF’s schema only.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/constructs/sample#syntax" ADD_DATE="1723920247" LAST_MODIFIED="1730207852" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fconstructs%2Fsample%23syntax" DATA-IMPORTANT="false">SAMPLE / TABLESAMPLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920247">BERNOULLI (or ROW): Includes each row with a probability of p/100. Similar to flipping a weighted coin for each row.

SYSTEM (or BLOCK): Includes each block of rows with a probability of p/100. Similar to flipping a weighted coin for each block of rows. This method does not support fixed-size sampling.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724083569">probability specifies the percentage probability to use for selecting the sample. Can be any decimal number between 0 (no rows selected) and 100 (all rows selected) inclusive.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724083570">num specifies the number of rows (up to 1,000,000) to sample from the table. Can be any integer between 0 (no rows selected) and 1000000 inclusive.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/network-policies#label-associating-network-policies" ADD_DATE="1723920166" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fnetwork-policies%23label-associating-network-policies" DATA-IMPORTANT="false">Controlling network traffic with network policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723920166">You can create multiple network policies, however only one network policy can be associated with an account at any one time. Associating a network policy with your account automatically removes the currently-associated network policy (if any).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920213">Only a single network policy can be activated for each user at a time. The ability to activate different network policies for different users allows for granular control. Associating a network policy with a user automatically removes the currently-associated network policy (if any).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/object-tagging#label-object-tags-ddl" ADD_DATE="1723919781" LAST_MODIFIED="1730207856" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fobject-tagging%23label-object-tags-ddl" DATA-IMPORTANT="false">Object Tagging | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723919781">Snowflake supports the following DDL to create and manage tags:

CREATE TAG

ALTER TAG

ALTER &lt;object&gt; (to set a tag on a Snowflake object)

SHOW TAGS

DROP TAG

UNDROP TAG</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078051">Note that Snowflake does not support the describe operation for the tag object.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/streams-intro#label-streams-staleness" ADD_DATE="1723919739" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fstreams-intro%23label-streams-staleness" DATA-IMPORTANT="false">Introduction to Streams | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723919739">If the data retention period for a table is less than 14 days and a stream hasn’t been consumed, Snowflake temporarily extends this period to prevent the stream from going stale. The retention period is extended to the stream’s offset, up to a maximum of 14 days by default, regardless of your Snowflake edition. The maximum number of days for which Snowflake can extend the data retention period is determined by the MAX_DATA_EXTENSION_TIME_IN_DAYS parameter value. Once the stream is consumed, the extended data retention period reverts to the table’s default.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078468">Multiple queries can independently consume the same change data from a stream without changing the offset. A stream advances the offset only when it is used in a DML transaction.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078502">Querying a stream alone does not advance its offset, even within an explicit transaction; the stream contents must be consumed in a DML statement.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078567">To ensure multiple statements access the same change records in the stream, surround them with an explicit transaction statement (BEGIN .. COMMIT).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078700">METADATA$ACTION:

Indicates the DML operation (INSERT, DELETE) recorded.

METADATA$ISUPDATE:

Indicates whether the operation was part of an UPDATE statement. Updates to rows in the source object are represented as a pair of DELETE and INSERT records in the stream with a metadata column METADATA$ISUPDATE values set to TRUE</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078816">Types of Streams</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078818">Standard</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078822">Append-only</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078860">Insert-only</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078896">A stream becomes stale when its offset falls outside of the data retention period for its source table</mark>
		<DD><mark COLOR="green" ADD_DATE="1724078913">In a stale state, historical data and any unconsumed change records for the source table are no longer accessible. To continue tracking new change records, you must recreate the stream using the CREATE STREAM command.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078956">To prevent a stream from becoming stale, consume the stream records within a DML statement during the table’s retention period. Additionally, calling SYSTEM$STREAM_HAS_DATA on the stream prevents it from becoming stale, provided the stream is empty and the SYSTEM$STREAM_HAS_DATA function returns FALSE.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724078969">This restriction doesn’t apply to streams on directory tables or external tables, which have no data retention period.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724079207">After the STALE_AFTER timestamp has passed, the stream can become stale at any time, even if it has no unconsumed records.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724079251">Recreating an object (using the CREATE OR REPLACE TABLE syntax) drops its history, which also makes any stream on the table or view stale. In addition, recreating or dropping any of the underlying tables for a view makes any stream on the view stale.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724079769">Currently, streams cannot track changes in materialized views.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724079904">Prior to creating a stream on a view, you must enable change tracking on the underlying tables for the view</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724080042">CHANGES Clause: Read-only Alternative to Streams¶

As an alternative to streams, Snowflake supports querying change tracking metadata for tables or views using the CHANGES clause for SELECT statements. The CHANGES clause enables querying change tracking metadata between two points in time without having to create a stream with an explicit transactional offset. Using the CHANGES clause does not advance the offse</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-column-ddm-intro" ADD_DATE="1723798647" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-column-ddm-intro" DATA-IMPORTANT="false">Understanding Dynamic Data Masking | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723798647">Snowflake provides two Account Usage views to obtain information about masking policies:

The MASKING POLICIES view provides a list of all masking policies in your Snowflake account.

The POLICY_REFERENCES view provides a list of all objects in which a masking policy is set.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-materialized#dropping-the-base-table" ADD_DATE="1723798511" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-materialized%23dropping-the-base-table" DATA-IMPORTANT="false">Working with Materialized Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723798511">If a base table is altered so that existing columns are changed or dropped, then all materialized views on that base table are suspended; the materialized views cannot be used or maintained. (This is true even if the modified or dropped column was not part of the materialized view.)</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/cost-understanding-data-transfer" ADD_DATE="1723798175" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fcost-understanding-data-transfer" DATA-IMPORTANT="false">Understanding data transfer cost | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723798175">Snowflake charges a per-byte fee for data egress when users transfer data from a Snowflake account into a different region on the same cloud platform or into a completely different cloud platform. Data transfers within the same region are free.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723798191">Snowflake does not charge data ingress fees. However, a cloud storage provider might charge a data egress fee for transferring data from the provider to your Snowflake account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724084024">Snowflake features that incur transfer costs¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724084040">Unloading data from Snowflake to Amazon, Google Cloud Storage, or Microsoft Azure.

Typically this involves the use of COPY INTO &lt;location&gt; to unload data to cloud storage in a region or cloud platform different from where your Snowflake account is hosted.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724084047">Replication of databases, creating a snapshot of the database to a secondary database.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724084082">Using auto-fulfillment to offer listings to consumers in other cloud regions</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724084098">Snowflake does not apply data egress charges when a Snowflake client or driver retrieves query results across regions within the same cloud platform or across different cloud platforms.</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/classify-intro" ADD_DATE="1723798121" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fclassify-intro" DATA-IMPORTANT="false">Introduction to Classification | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723798121">Classification is a multi-step process that associates Snowflake-defined system tags to columns by analyzing the fields and metadata for personal data; this data can be tracked by a data engineer using SQL and Snowsight. A data engineer can classify columns in a table to determine whether the column contains certain kinds of data that need to be tracked or protected</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/search-optimization-service#how-does-the-search-optimization-service-work" ADD_DATE="1723798024" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsearch-optimization-service%23how-does-the-search-optimization-service-work" DATA-IMPORTANT="false">Search Optimization Service | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723798024">To improve performance of search queries, the search optimization service creates and maintains a persistent data structure called a search access path. The search access path keeps track of which values of the table’s columns might be found in each of its micro-partitions, allowing some micro-partitions to be skipped when scanning the table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/explain" ADD_DATE="1723797721" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fexplain" DATA-IMPORTANT="false">EXPLAIN | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797721">EXPLAIN¶

Returns the logical execution plan for the specified SQL statement.

An explain plan shows the operations (for example, table scans and joins) that Snowflake would perform to execute the query.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/query-acceleration-service" ADD_DATE="1723797678" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquery-acceleration-service" DATA-IMPORTANT="false">Using the Query Acceleration Service | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797678">Examples of the types of workloads that might benefit from the query acceleration service include:

Ad hoc analytics.

Workloads with unpredictable data volume per query.

Queries with large scans and selective filters.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#what-is-restricted-allowed-in-a-reader-account" ADD_DATE="1723797509" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-reader-create%23what-is-restricted-allowed-in-a-reader-account" DATA-IMPORTANT="false">Manage reader accounts | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797509">What is restricted/allowed in a reader account?¶

A reader account is intended primarily for querying data shared by the provider of the account. You can work with data, for example, by creating materialized views.

You cannot perform the following tasks in a reader account:

Set a data metric function on objects in the reader account.

Upload new data.

Modify existing data.

Unload data using a storage integration. However, you can use the COPY INTO &lt;location&gt; command with your connection credentials to unload data into a cloud storage location.

Additionally, you cannot execute the following commands in a reader account:

INSERT

UPDATE

DELETE

MERGE

COPY INTO &lt;table&gt;

CREATE MASKING POLICY

CREATE PIPE

CREATE ROW ACCESS POLICY

CREATE SHARE

CREATE STAGE

SHOW PROCEDURES

All other operations are allowed.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-file-format" ADD_DATE="1723797442" LAST_MODIFIED="1730207860" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-file-format" DATA-IMPORTANT="false">CREATE FILE FORMAT | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797442">FIELD_OPTIONALLY_ENCLOSED_BY = &#39;character&#39; | NONE</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723797453">Definition:

Character used to enclose strings. Value can be NONE, single quote character (&#39;), or double quote character (&quot;). To use the single quote character, use the octal or hex representation (0x27) or the double single-quoted escape (&#39;&#39;).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724006739">{ TEMP | TEMPORARY | VOLATILE }

Specifies that the file format persists only for the duration of the session that you created it in. A temporary file format is dropped at the end of the session.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724006781">When you load data from files into tables, Snowflake supports either NDJSON (newline delimited JSON) standard format or comma-separated JSON format.

When you unload table data to files, Snowflake outputs only to NDJSON format.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724006949">If a value is not specified or is AUTO, the value for the TIME_INPUT_FORMAT (data loading) or TIME_OUTPUT_FORMAT (data unloading) parameter is used.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724007143">ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE | FALSE
Use:

Data loading only

Definition:

Boolean that specifies whether to generate a parsing error if the number of delimited columns (i.e. fields) in an input file does not match the number of columns in the corresponding table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724007193">STRIP_OUTER_ARRAY = TRUE | FALSE
Use:

Data loading and external tables

Definition:

Boolean that instructs the JSON parser to remove outer brackets (i.e. [ ]).

Default:

FALSE</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#overview" ADD_DATE="1723797364" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-reader-create%23overview" DATA-IMPORTANT="false">Manage reader accounts | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797364">Warehouses in a reader account can consume an unlimited number of credits each month, which will be charged to your provider account. To limit usage, set up a resource monitor for the warehouse.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-usage" ADD_DATE="1723797165" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fstored-procedure%2Fstored-procedures-usage" DATA-IMPORTANT="false">Working with stored procedures | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797179">Currently, the following privileges apply to stored procedures:

USAGE

OWNERSHIP

For a role to use a stored procedure, the role must either be the owner or have been granted USAGE privilege on the stored procedure.</mark>
		<DT><A HREF="https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling" ADD_DATE="1723797117" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://www.snowflake.com/wp-content/themes/snowflake/assets/img/community/community-social-share.jpg" DATA-IMPORTANT="false">Snowflake Community</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797129">The spilling can&#39;t always be avoided, especially for large batches of data, but it can be decreased by:

Reviewing the query for query optimization especially if it is a new query.
Reducing the amount of data processed. For example, by trying to improve partition pruning, or projecting only the columns that are needed in the output.
Decreasing the number of parallel queries running in the warehouse.
Trying to split the processing into several steps (for example by replacing the CTEs with temporary tables).
Using a larger warehouse. This effectively means more memory and more local disk space.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/get_ddl#examples" ADD_DATE="1723797042" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fget_ddl%23examples" DATA-IMPORTANT="false">GET_DDL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723797042">GET_DDL¶

Returns a DDL statement that can be used to recreate the specified object.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-file-format" ADD_DATE="1723796946" LAST_MODIFIED="1730207864" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-file-format" DATA-IMPORTANT="false">ALTER FILE FORMAT | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723796946">ALTER FILE FORMAT does not support the following actions:

Changing the type (CSV, JSON, etc.) for the file format.

Unsetting any format options (i.e. resetting the options to the defaults for the type).

Unsetting (i.e. removing) a comment.

To make any of these changes, you must recreate the file format.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/streams-intro#data-retention-period-and-staleness" ADD_DATE="1723796384" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fstreams-intro%23data-retention-period-and-staleness" DATA-IMPORTANT="false">Introduction to Streams | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723796384">If the data retention period for a table is less than 14 days and a stream hasn’t been consumed, Snowflake temporarily extends this period to prevent the stream from going stale. The retention period is extended to the stream’s offset, up to a maximum of 14 days by default, regardless of your Snowflake edition. The maximum number of days for which Snowflake can extend the data retention period is determined by the MAX_DATA_EXTENSION_TIME_IN_DAYS parameter value. Once the stream is consumed, the extended data retention period reverts to the table’s default.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/constructs/sample" ADD_DATE="1723796258" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fconstructs%2Fsample" DATA-IMPORTANT="false">SAMPLE / TABLESAMPLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723796258">SAMPLE and TABLESAMPLE are synonymous and can be used interchangeably.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723796280">Parameters¶
BERNOULLI | ROW or . SYSTEM | BLOCK</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920350">Return a sample of a table in which each row has a 10% probability of being included in the sample:

SELECT * FROM testtable SAMPLE (10);</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-overview#external-stages" ADD_DATE="1723796205" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-overview%23external-stages" DATA-IMPORTANT="false">Overview of data loading | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723796205">External stages¶

Loading data from any of the following cloud storage services is supported regardless of the cloud platform that hosts your Snowflake account:

Amazon S3

Google Cloud Storage

Microsoft Azure</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724080949">The Snowpipe Streaming API writes rows of data directly to Snowflake tables without the requirement of staging files.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724081037">INFER_SCHEMA

Detects the column definitions in a set of staged data files and retrieves the metadata in a format suitable for creating Snowflake objects.

GENERATE_COLUMN_DESCRIPTION

Generates a list of columns from a set of staged files using the INFER_SCHEMA function output.

These SQL functions support both internal and external stages.

Create tables or external tables with the column definitions derived from a set of staged files using the CREATE TABLE … USING TEMPLATE or CREATE EXTERNAL TABLE … USING TEMPLATE syntax. The USING TEMPLATE clause accepts an expression that calls the INFER_SCHEMA SQL function to detect the column definitions in the files. After the table is created, you can then use a COPY statement with the MATCH_BY_COLUMN_NAME option to load files directly into the structured table.</mark>
		<DT><A HREF="https://docs.snowflake.com/developer-guide/udf-stored-procedure-naming-conventions#overloading-procedures-and-functions" ADD_DATE="1723795997" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fdeveloper-guide%2Fudf-stored-procedure-naming-conventions%23overloading-procedures-and-functions" DATA-IMPORTANT="false">Naming and overloading procedures and UDFs | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795997">Overloading procedures and functions¶

Snowflake supports overloading procedures and functions. In a given schema, you can define multiple procedures or functions that have the same name but different signatures. The signatures must differ by the number of arguments, the types of the arguments, or both.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/data-sharing-usage" ADD_DATE="1723795934" LAST_MODIFIED="1730207868" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fdata-sharing-usage" DATA-IMPORTANT="false">Data Sharing Usage | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795934">DATA_SHARING_USAGE views¶

The DATA_SHARING_USAGE schema contains the following views:

View

	

Type

	

Latency [1]

	

Retention duration




APPLICATION_STATE

	

Current state

	

up to 10 minutes

	

Not applicable.




LISTING_ACCESS_HISTORY

	

Historical

	

up to 2 days

	

Data retained for 1 year.




LISTING_AUTO_FULFILLMENT_DATABASE_STORAGE_DAILY

	

Historical

	

up to 2 days

	

Data retained for 1 year.




LISTING_AUTO_FULFILLMENT_REFRESH_DAILY

	

Historical

	

up to 2 days

	

Data retained for 1 year.




LISTING_CONSUMPTION_DAILY

	

Historical

	

up to 2 days

	

Data retained for 1 year.




LISTING_EVENTS_DAILY

	

Historical

	

up to 2 days

	

Data retained for 1 year.




LISTING_TELEMETRY_DAILY

	

Historical

	

up to 2 days

	

Data retained for 1 year.




MARKETPLACE_DISBURSEMENT_REPORT

	

Historical

	

up to 2 days

	

Data retained for 1 year.




MARKETPLACE_PAID_USAGE_DAILY

	

Historical

	

up to 2 days

	

Data retained for 1 year.




MONETIZED_USAGE_DAILY

	

Historical

	

up to 2 days

	

Data retained for 1</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url" ADD_DATE="1723795819" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fbuild_stage_file_url" DATA-IMPORTANT="false">BUILD_STAGE_FILE_URL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795819">BUILD_STAGE_FILE_URL¶

Generates a Snowflake file URL to a staged file using the stage name and relative file path as inputs. A file URL permits prolonged access to a specified file. That is, the file URL does not expire.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage/metering_history" ADD_DATE="1723795677" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage%2Fmetering_history" DATA-IMPORTANT="false">METERING_HISTORY view | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795677">METERING_HISTORY view¶

The METERING_HISTORY view in the ACCOUNT_USAGE schema can be used to return the hourly credit usage for an account within the last 365 days (1 year).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-clustering-keys#defining-a-clustering-key-for-a-table" ADD_DATE="1723795643" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-clustering-keys%23defining-a-clustering-key-for-a-table" DATA-IMPORTANT="false">Clustering Keys &amp; Clustered Tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795643">Where each clustering key consists of one or more table columns/expressions, which can be of any data type, except GEOGRAPHY, VARIANT, OBJECT, or ARRAY. A clustering key can contain any of the following:

Base columns.

Expressions on base columns.

Expressions on paths in VARIANT columns.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage" ADD_DATE="1723795205" LAST_MODIFIED="1730207871" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage" DATA-IMPORTANT="false">Account Usage | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795205">Historical data retention¶

Certain account usage views provide historical usage metrics. The retention period for these views is 1 year (365 days).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/typeof" ADD_DATE="1723795162" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Ftypeof" DATA-IMPORTANT="false">TYPEOF | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795162">TYPEOF¶

Returns the type of a value stored in a VARIANT column. The type is returned as a string.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/search-optimization/queries-that-benefit" ADD_DATE="1723795085" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsearch-optimization%2Fqueries-that-benefit" DATA-IMPORTANT="false">Identifying queries that can benefit from search optimization | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723795095">Supported predicate types¶

Search optimization can improve the performance of queries using these kinds of predicates:

Point lookup queries using equality and IN.

Character data (text) queries using the SEARCH function.

Substring queries using wildcards and regular expressions.

Searches in semi-structured data.

Geospatial queries.

Queries using conjunctions (AND) and disjunctions (OR).

Other potential improvements¶

Search optimization can also improve the performance of views and of queries that use JOIN.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723965184">the search optimization service does not support the following:

External tables.

Materialized views.

Columns defined with a COLLATE clause.

Column concatenation.

Analytical expressions.

Casts on table columns (except for fixed-point numbers cast to strings).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-cloud-platforms" ADD_DATE="1723793557" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-cloud-platforms" DATA-IMPORTANT="false">Supported Cloud Platforms | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723793557">The cloud platform you choose for each Snowflake account is completely independent from your other Snowflake accounts. In fact, you can choose to host each Snowflake account on a different platform, although this may have some impact on data transfer billing when loading data</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#preparing-delimited-text-files" ADD_DATE="1723793443" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-considerations-prepare%23preparing-delimited-text-files" DATA-IMPORTANT="false">Preparing your data files | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723793443">Consider the following guidelines when preparing your delimited text (CSV) files for loading:

UTF-8 is the default character set, however, additional encodings are supported. Use the ENCODING file format option to specify the character set for the data files. For more information, see CREATE FILE FORMAT.

Fields that contain delimiter characters should be enclosed in quotes (single or double). If the data contains single or double quotes, then those quotes must be escaped.

Carriage returns are commonly introduced on Windows systems in conjunction with a line feed character to mark the end of a line (\r \n). Fields that contain carriage returns should also be enclosed in quotes (single or double).

The number of columns in each row should be consistent.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724086693">we recommend aiming to produce data files roughly 100-250 MB (or larger) in size compressed.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724086715">Loading very large files (e.g. 100 GB or larger) is not recommended.

If you must load a large file, carefully consider the ON_ERROR copy option value. Aborting or skipping a file due to a small number of errors could result in delays and wasted credits. In addition, if a data loading operation continues beyond the maximum allowed duration of 24 hours, it could be aborted without any portion of the file being committed.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/cost-understanding-compute#serverless-credit-usage" ADD_DATE="1723793314" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fcost-understanding-compute%23serverless-credit-usage" DATA-IMPORTANT="false">Understanding compute cost | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723793314">Usage for cloud services is charged only if the daily consumption of cloud services exceeds 10% of the daily usage of virtual warehouses.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793347">The 10% adjustment for cloud services is calculated daily (in the UTC time zone) by multiplying daily warehouse usage by 10%.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793385">Charges for serverless features are calculated based on total usage of snowflake-managed compute resources measured in compute-hours. Compute-Hours are calculated on a per second basis, rounded up to the nearest whole second.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/semistructured-data-formats" ADD_DATE="1723793217" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsemistructured-data-formats" DATA-IMPORTANT="false">Supported Formats for Semi-structured Data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723793217">Avro is an open-source data serialization and RPC framework originally developed for use with Apache Hadoop</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793240">ORC (Optimized Row Columnar) is a binary format used to store Hive data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793250">Parquet is a compressed, efficient columnar data representation designed for projects in the Hadoop ecosystem.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793261">JSON (JavaScript Object Notation) is a lightweight, plain-text, data-interchange format based on a subset of the JavaScript Programming Language.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/network-policies#creating-network-policies" ADD_DATE="1723793029" LAST_MODIFIED="1730207874" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fnetwork-policies%23creating-network-policies" DATA-IMPORTANT="false">Controlling network traffic with network policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723793029">You can apply a network policy to an account, a security integration, or a user.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793041">Account:

Network policies applied to an account are the most general network policies. They are overridden by network policies applied to a security integration or user.

Security Integration:

Network policies applied to a security integration override network policies applied to the account, but are overridden by a network policy applied to a user.

User:

Network policies applied to a user are the most specific network policies. They override both accounts and security integrations.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-multiple-db" ADD_DATE="1723706957" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-multiple-db" DATA-IMPORTANT="false">Share data from multiple databases | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723706957">you must also grant the REFERENCE_USAGE privilege on each database referenced by a secure view that you wish to share. However, you do not need to grant REFERENCE_USAGE on the database that contains the secure view.</mark>
		<DT><A HREF="https://other-docs.snowflake.com/en/collaboration/collaboration-listings-about" ADD_DATE="1723706746" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fother-docs.snowflake.com%2Fen%2Fcollaboration%2Fcollaboration-listings-about" DATA-IMPORTANT="false">About listings | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723706746">When you offer a listing, you choose how to make your data product available to consumers:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706754">Privately, available only to specific consumers.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706760">Publicly, visible on the Snowflake Marketplace.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706768">A free listing is available privately to specific consumers, or publicly on the Snowflake Marketplace, and provides instant access to a full published dataset.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706772">A limited trial listing is available on the Snowflake Marketplace and provides instant limited access to a data product.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706777">A paid listing is available privately or on the Snowflake Marketplace. As a provider, you can create paid listings to charge consumers to access or use your listing.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/operators-query#intersect" ADD_DATE="1723706640" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Foperators-query%23intersect" DATA-IMPORTANT="false">Set operators | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723706640">INTERSECT¶

Returns rows from one query’s result set which also appear in another query’s result set, with duplicate elimination.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges" ADD_DATE="1723706567" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-exchange-marketplace-privileges" DATA-IMPORTANT="false">Grant privileges to other roles | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723706567">Granting administrator privileges in a Data Exchange¶

By default, only an account administrator (a user with the ACCOUNTADMIN role) in the Data Exchange administrator account can manage a Data Exchange, which includes the following tasks:

Add or remove members.

Approve or deny listing approval requests.

Approve or deny provider profile approval requests.

Show categories.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-task" ADD_DATE="1723706368" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-task" DATA-IMPORTANT="false">ALTER TASK | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723706368">ALTER TASK mytask SET SCHEDULE = &#39;USING CRON */3 * * * * UTC&#39;;</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724008874">Before resuming the root task of your Task Graph, resume all child tasks. To recursively resume the root task’s child tasks, use SYSTEM$TASK_DEPENDENTS_ENABLE.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724009010">Currently, the following functions are supported for evaluation in the SQL expression:

SYSTEM$STREAM_HAS_DATA

Indicates whether a specified stream contains change tracking data. Used to run a triggered task if no schedule is defined for the task. You can also use this to skip the current task run if the stream contains no change data.

If the result is FALSE, then the task does not run.

SYSTEM$GET_PREDECESSOR_RETURN_VALUE

Retrieves the return value for the predecessor task in a task graph. Used to decide whether the task should run based on the returned result.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage/resource_monitors" ADD_DATE="1723706284" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage%2Fresource_monitors" DATA-IMPORTANT="false">RESOURCE_MONITORS view | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723706284">RESOURCE_MONITORS view¶

This Account Usage view displays the resource monitors that have been created in the reader accounts managed by the account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706291">This view is only available in the READER_ACCOUNT_USAGE schema.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#type-parquet" ADD_DATE="1723705703" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcopy-into-location%23type-parquet" DATA-IMPORTANT="false">COPY INTO location | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723705703">TYPE = PARQUET¶
COMPRESSION = AUTO | LZO | SNAPPY | NONE</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723705719">TYPE = JSON¶
COMPRESSION = AUTO | GZIP | BZ2 | BROTLI | ZSTD | DEFLATE | RAW_DEFLATE | NONE</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723705732">TYPE = CSV¶
COMPRESSION = AUTO | GZIP | BZ2 | BROTLI | ZSTD | DEFLATE | RAW_DEFLATE | NONE</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-table" ADD_DATE="1723705073" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-table" DATA-IMPORTANT="false">CREATE TABLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723705073">CREATE TABLE … LIKE (creates an empty copy of an existing table)</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/current_client" ADD_DATE="1723704577" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fcurrent_client" DATA-IMPORTANT="false">CURRENT_CLIENT | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723704577">CURRENT_CLIENT¶

Returns the version of the client from which the function was called. If called from an application using the JDBC or ODBC driver to connect to Snowflake, returns the version of the driver.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/parse_json" ADD_DATE="1723704389" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fparse_json" DATA-IMPORTANT="false">PARSE_JSON | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723704389">PARSE_JSON¶

Interprets an input string as a JSON document, producing a VARIANT value.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704415">This function supports an input expression with a maximum size of 8 MB compressed.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-table-column" ADD_DATE="1723704307" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-table-column" DATA-IMPORTANT="false">ALTER TABLE … ALTER COLUMN | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723704307">When setting a column to NOT NULL, if the column contains NULL values, an error is returned and no changes are applied to the column.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/constructs/at-before" ADD_DATE="1723704220" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fconstructs%2Fat-before" DATA-IMPORTANT="false">AT | BEFORE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723704220">OFFSET =&gt; time_difference

Specifies the difference in seconds from the current time to use for Time Travel, in the form -N where N can be an integer or arithmetic expression (e.g. -120 is 120 seconds, -30*60 is 1800 seconds or 30 minutes).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/grant-privilege" ADD_DATE="1723703953" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fgrant-privilege" DATA-IMPORTANT="false">GRANT privileges | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723703953">FUTURE

Specifies that privileges are granted on new (i.e. future) database or schema objects of a specified type (e.g. tables or views) rather than existing objects.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-encryption-end-to-end" ADD_DATE="1723703828" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-encryption-end-to-end" DATA-IMPORTANT="false">Understanding end-to-end encryption in Snowflake | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723703828">Client-side encryption means that a client encrypts data before copying it into a cloud storage staging area. Client-side encryption provides a secure system for managing data in cloud storage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723703862">We recommend client-side encryption for data files in external stages; but if the data is not encrypted, Snowflake immediately encrypts the data when it is loaded into a table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/data-types-geospatial#geometry-data-type" ADD_DATE="1723703609" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fdata-types-geospatial%23geometry-data-type" DATA-IMPORTANT="false">Geospatial data types | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723703623">Snowflake provides the following data types for geospatial data:

The GEOGRAPHY data type, which models Earth as though it were a perfect sphere.

The GEOMETRY data type, which represents features in a planar (Euclidean, Cartesian) coordinate system.</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/admin-security-fed-auth-overview" ADD_DATE="1723703213" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fadmin-security-fed-auth-overview" DATA-IMPORTANT="false">Overview of federated authentication and SSO | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723703213">In a federated environment, user authentication is separated from user access through the use of one or more external entities that provide independent authentication of user credentials. The authentication is then passed to one or more services, enabling users to access the services through SSO. A federated environment consists of the following components:

Service provider (SP):

In a Snowflake federated environment, Snowflake serves as the SP.

Identity provider (IdP):

The external, independent entity responsible for providing the following services to the SP:

Creating and maintaining user credentials and other profile information.

Authenticating users for SSO access to the SP.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-monitor" ADD_DATE="1723703121" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-monitor" DATA-IMPORTANT="false">Monitor data loading activity by using Copy History | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723703121">You can monitor data loading activity for all tables in your account, or for a specific table, by using Snowsight or SQL.

Monitor data loading for your account by using Copy History.

Monitor data loading for a table by using Copy History.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/snowsql-config" ADD_DATE="1723702988" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsnowsql-config" DATA-IMPORTANT="false">Configuring SnowSQL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723702988">SnowSQL supports multiple configuration files that allow organizations to define base values for connection parameters, default settings, and variables while allowing individual users to customize their personal settings in their own &lt;HOME_DIR&gt;/.snowsql/config files. When SnowSQL starts, it loads configuration parameter values from the following configuration file locations in order, overriding values from files loaded previously:

/etc/snowsql.cnf

/etc/snowflake/snowsql.cnf

/usr/local/etc/snowsql.cnf

&lt;HOME_DIR&gt;/.snowsql.cnf (supported only for backward compatibility)

&lt;HOME_DIR&gt;/.snowsql/config

For example, if the /etc/snowsql.cnf configuration file sets the log_level parameter to info, you can override this by setting the parameter to debug in your file &lt;HOME_DIR&gt;/.snowsql/config file.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-intro" ADD_DATE="1723640300" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-intro" DATA-IMPORTANT="false">About Secure Data Sharing | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723640300">The only charges to consumers are for the compute resources (i.e. virtual warehouses) used to query the shared data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723640342">With Secure Data Sharing, no actual data is copied or transferred between accounts. All sharing uses Snowflake’s services layer and metadata store.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723798693">What is a share?¶

Shares are named Snowflake objects that encapsulate all of the information required to share a database.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/parameters#min-data-retention-time-in-days" ADD_DATE="1723639707" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fparameters%23min-data-retention-time-in-days" DATA-IMPORTANT="false">Parameters | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723639707">MIN_DATA_RETENTION_TIME_IN_DAYS¶
Type:

Account — Can be set only for Account</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723639743">DATA_RETENTION_TIME_IN_DAYS¶
Type:

Object (for databases, schemas, and tables) — Can be set for Account » Database » Schema » Table</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-s3#configuring-an-s3-bucket-for-unloading-data" ADD_DATE="1723639532" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-s3%23configuring-an-s3-bucket-for-unloading-data" DATA-IMPORTANT="false">Unloading into Amazon S3 | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723639532">Configuring an S3 bucket for unloading data¶

Snowflake requires the following permissions on an S3 bucket and folder to create new files in the folder (and any sub-folders):

s3:DeleteObject

s3:PutObject</mark>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/snowpark/index#key-features" ADD_DATE="1723639434" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fsnowpark%2Findex%23key-features" DATA-IMPORTANT="false">Snowpark API | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723639434">In comparison to using the Snowflake Connector for Spark, developing with Snowpark includes the following benefits:

Support for interacting with data within Snowflake using libraries and patterns purpose built for different languages without compromising on performance or functionality.

Support for authoring Snowpark code using local tools such as Jupyter, VS Code, or IntelliJ.

Support for pushdown for all operations, including Snowflake UDFs. This means Snowpark pushes down all data transformation and heavy lifting to the Snowflake data cloud, enabling you to efficiently work with data of any size.

No requirement for a separate cluster outside of Snowflake for computations. All of the computations are done within Snowflake. Scale and compute management are handled by Snowflake.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-micro-partitions" ADD_DATE="1723639349" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-micro-partitions" DATA-IMPORTANT="false">Understanding Snowflake Table Structures | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723639349">All data in Snowflake is stored in database tables, logically structured as collections of columns and rows. To best utilize Snowflake tables, particularly large tables, it is helpful to have an understanding of the physical structure behind the logical structure.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-materialized#effects-of-changes-to-base-tables-on-materialized-views" ADD_DATE="1723639184" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-materialized%23effects-of-changes-to-base-tables-on-materialized-views" DATA-IMPORTANT="false">Working with Materialized Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723639184">When a base table changes, all materialized views defined on the table are updated by a background service that uses compute resources provided by Snowflake.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723639215">Defining a clustering key on a materialized view is supported and can increase performance in many situations. However, it also adds costs.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-history" ADD_DATE="1723639056" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-history" DATA-IMPORTANT="false">Using the History Page to Monitor Queries | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723639056">You can view results only for queries you have executed. If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query, but, for data privacy reasons, the page does not display the actual query result.</mark>
		<DT><A HREF="https://other-docs.snowflake.com/en/collaboration/consumer-becoming" ADD_DATE="1723638414" LAST_MODIFIED="1730207878" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fother-docs.snowflake.com%2Fen%2Fcollaboration%2Fconsumer-becoming" DATA-IMPORTANT="false">About listing consumers | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723638414">Accept the Snowflake Provider and Consumer Terms of Service¶

The organization administrator only needs to accept the Snowflake Provider and Consumer Terms once for your organization. After the terms have been accepted, anyone in your organization that has a role with the necessary privileges can become a consumer of listings.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723638430">You must be an organization administrator (i.e. a user granted the ORGADMIN role) to accept the terms.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723639859">To access a listing, you must use the ACCOUNTADMIN role or another role with the CREATE DATABASE and IMPORT SHARE privileges. To pay for a paid listing, your role must also have the PURCHASE DATA EXCHANGE LISTING privilege.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/semistructured-considerations" ADD_DATE="1723638372" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsemistructured-considerations" DATA-IMPORTANT="false">Considerations for Semi-structured Data Stored in VARIANT | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723638372">If the data exceeds 16 MB, enable the STRIP_OUTER_ARRAY file format option for the COPY INTO &lt;table&gt; command to remove the outer array structure and load the records into separate table rows</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/show-network-policies" ADD_DATE="1723638343" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fshow-network-policies" DATA-IMPORTANT="false">SHOW NETWORK POLICIES | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723638343">SHOW NETWORK POLICIES¶

Lists all network policies defined in the system.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-share-consumers" ADD_DATE="1723638315" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-share-consumers" DATA-IMPORTANT="false">Consume shared data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723638315">Shared databases have the following limitations for consumers:

Shared databases are read-only. Users in a consumer account can view/query data, but cannot insert or update data, or create any objects in the database.

The following actions are not supported:

Creating a clone of a shared database or any schemas/tables in the database.

Time Travel for a shared database or any schemas/tables in the database.

Editing the comments for a shared database.

Shared databases and all the objects in the database cannot be re-shared with other accounts.

Shared databases cannot be replicated.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-materialized#limitations-on-creating-materialized-views" ADD_DATE="1723638068" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-materialized%23limitations-on-creating-materialized-views" DATA-IMPORTANT="false">Working with Materialized Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723638068">The following limitations apply to creating materialized views:

A materialized view can query only a single table.

Joins, including self-joins, are not supported.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-profile" ADD_DATE="1723637613" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-profile" DATA-IMPORTANT="false">Manage your user profile by using Snowsight | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723637613">On your profile, you can review and set the following user details:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637622">Default role &amp; warehouse:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637630">Default experience: Select the default user interface you see when you sign in to Snowflake, Snowsight or the Classic Console.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637636">Language</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637639">Notifications</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637644">Multi-factor authentication</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/task_history" ADD_DATE="1723637550" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Ftask_history" DATA-IMPORTANT="false">TASK_HISTORY | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723637550">This function returns results only for the ACCOUNTADMIN role, the task owner, or a role with the global MONITOR EXECUTION privilege.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-considerations" ADD_DATE="1723637300" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-considerations" DATA-IMPORTANT="false">Access control considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723637300">Assign this role to at least two users. We follow strict security procedures for resetting a forgotten or lost password for users with the ACCOUNTADMIN role. These procedures can take up to two business days. Assigning the ACCOUNTADMIN role to more than one user avoids having to go through these procedures because the users can reset each other’s passwords.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723969843">A user cannot view the result set from a query that another user executed. This behavior is intentional. For security reasons, only the user who executed a query can access the query results.

Note

This behavior is not connected to the Snowflake access control model for objects. Even a user with the ACCOUNTADMIN role cannot view the results for a query run by another user.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/external-functions" ADD_DATE="1723637210" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fexternal-functions" DATA-IMPORTANT="false">Writing external functions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723637210">External functions are user-defined functions that are stored and executed outside of Snowflake.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-table" ADD_DATE="1723637168" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-table" DATA-IMPORTANT="false">ALTER TABLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723637168">DROP CLUSTERING KEY

Drops the clustering key for the table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637183">ALTER TABLE</mark>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/stored-procedures-vs-udfs" ADD_DATE="1723637103" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fstored-procedures-vs-udfs" DATA-IMPORTANT="false">Choosing whether to write a stored procedure or a user-defined function | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723637103">A single SQL statement can call multiple UDFs.

A single SQL statement can call only one stored procedure.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/jarowinkler_similarity" ADD_DATE="1723636793" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fjarowinkler_similarity" DATA-IMPORTANT="false">JAROWINKLER_SIMILARITY | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636793">JAROWINKLER_SIMILARITY¶

Computes the Jaro-Winkler similarity between two input strings. The function returns an integer between 0 and 100, where 0 indicates no similarity and 100 indicates an exact match.

Note

The similarity computation is case-insensitive.

The computation is sensitive to all formatting characters, including white space characters.

The default scaling factor of 0.1 is used for the computation.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-temp-transient#potential-naming-conflicts-with-other-table-types" ADD_DATE="1723636599" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-temp-transient%23potential-naming-conflicts-with-other-table-types" DATA-IMPORTANT="false">Working with Temporary and Transient Tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636599">the temporary table takes precedence in the session over any other table with the same name in the same schema.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations" ADD_DATE="1723636555" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-visualizations" DATA-IMPORTANT="false">Visualizing worksheet data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636555">Snowsight supports the following types of charts:

Bar charts

Line charts

Scatterplots

Heat grids

Scorecards</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-privileges-shares" ADD_DATE="1723636521" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-privileges-shares" DATA-IMPORTANT="false">Enable non-ACCOUNTADMIN roles to perform data sharing tasks | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636521">By default, the privileges required to create and manage shares are granted only to the ACCOUNTADMIN role, ensuring that only account administrators can perform these tasks. However, the privileges can also be granted to other roles, enabling the tasks to be delegated to other users in the account.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tag-based-masking-policies#overview" ADD_DATE="1723636469" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftag-based-masking-policies%23overview" DATA-IMPORTANT="false">Tag-based masking policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636469">A tag can support one masking policy for each data type. For example, if a tag already has a masking policy for the NUMBER data type, you cannot assign another masking policy with the NUMBER data type to the same tag.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-overview#label-access-control-role-enforcement" ADD_DATE="1723636348" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-overview%23label-access-control-role-enforcement" DATA-IMPORTANT="false">Overview of Access Control | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636348">Enforcement model with primary role and secondary roles¶

Every active user session has a “current role,” also referred to as a primary role. When a session is initiated (e.g. a user connects via JDBC/ODBC or logs in to the Snowflake web interface), the current role is determined based on the following criteria:

If a role was specified as part of the connection and that role is a role that has already been granted to the connecting user, the specified role becomes the current role.

If no role was specified and a default role has been set for the connecting user, that role becomes the current role.

If no role was specified and a default role has not been set for the connecting user, the system role PUBLIC is used</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-into-single-or-multiple-files" ADD_DATE="1723636148" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-overview%23bulk-unloading-into-single-or-multiple-files" DATA-IMPORTANT="false">Overview of data unloading | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636148">The COPY INTO &lt;location&gt; command provides a copy option (SINGLE) for unloading data into a single file or multiple files. The default is SINGLE = FALSE (i.e. unload into multiple files).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-key-concepts#database-storage" ADD_DATE="1723636105" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-key-concepts%23database-storage" DATA-IMPORTANT="false">Key Concepts &amp; Architecture | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636105">When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format. Snowflake stores this optimized data in cloud storage.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/key-pair-auth" ADD_DATE="1723636044" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fkey-pair-auth" DATA-IMPORTANT="false">Key-pair authentication and key-pair rotation | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723636044">Client

	

Key Pair Authentication

	

Key Pair Rotation

	

Unencrypted Private Keys

	


SnowSQL (CLI client)

	

✔

	

✔

	

✔

	


Snowflake Connector for Python

	

✔

	

✔

	

✔

	


Snowflake Connector for Spark

	

✔

	

✔

	

✔

	


Snowflake Connector for Kafka

	

✔

	

✔

	

✔

	


Go driver

	

✔

	

✔

	

✔

	


JDBC Driver

	

✔

	

✔

	

✔

	


ODBC Driver

	

✔

	

✔

	

✔

	


Node.js Driver

	

✔

	

✔

	

✔

	


.NET Driver

	

✔

	

✔

	

✔

	


PHP PDO Driver for Snowflake

	

✔

	

✔

	

✔</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723636057">The following table summarizes support for key pair authentication among Snowflake Clients.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/drop-stage" ADD_DATE="1723635890" LAST_MODIFIED="1730207881" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fdrop-stage" DATA-IMPORTANT="false">DROP STAGE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723635890">Dropped stages cannot be recovered; they must be recreated.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-column-intro" ADD_DATE="1723635821" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-column-intro" DATA-IMPORTANT="false">Understanding Column-level Security | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723635821">Column-level Security includes two features:

Dynamic Data Masking

External Tokenization</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tasks-ts" ADD_DATE="1723635659" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftasks-ts" DATA-IMPORTANT="false">Troubleshooting tasks | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723635659">Task timed out or exceeded the schedule window¶

There is a 60 minute default limit on a single run of a task.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-rights" ADD_DATE="1723635463" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fstored-procedure%2Fstored-procedures-rights" DATA-IMPORTANT="false">Understanding caller’s rights and owner’s rights stored procedures | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723635463">A stored procedure runs with either the caller’s rights or the owner’s rights.</mark>
		<DT><A HREF="https://community.snowflake.com/s/article/Using-session-variables-in-a-stored-procedure" ADD_DATE="1723635413" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://www.snowflake.com/wp-content/themes/snowflake/assets/img/community/community-social-share.jpg" DATA-IMPORTANT="false">Snowflake Community</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723635413">By default, when a stored procedure is created in snowflake it consumes the Creator&#39;s rights(execute as owner) which do not allow the use of session variables.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635433">This problem can be resolved if we create the stored procedure with the option &quot;EXECUTE AS CALLER&quot;, it would use caller rights at the time of execution and would not cause any issues.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-query-profile#query-operator-details" ADD_DATE="1723635283" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-query-profile%23query-operator-details" DATA-IMPORTANT="false">Analyzing Queries Using Query Profile | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723635283">Execution Time¶

Execution time provides information about “where the time was spent” during the processing of a query. Time spent can be broken down into the following categories, displayed in the following order:

Processing — time spent on data processing by the CPU.

Local Disk IO — time when the processing was blocked by local disk access.

Remote Disk IO — time when the processing was blocked by remote disk access.

Network Communication — time when the processing was waiting for the network data transfer.

Synchronization — various synchronization activities between participating processes.

Initialization — time spent setting up the query processing.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-semistructured#dot-notation" ADD_DATE="1723635217" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-semistructured%23dot-notation" DATA-IMPORTANT="false">Querying Semi-structured Data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723635217">Use dot notation to traverse a path in a JSON object</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-configure#creating-custom-read-only-roles" ADD_DATE="1723625755" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-configure%23creating-custom-read-only-roles" DATA-IMPORTANT="false">Configuring access control | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723625755">SELECT

	

Table

	

To operate on any object in a schema, a role must have the USAGE privilege on the container database and schema.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-encryption-manage" ADD_DATE="1723625385" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-encryption-manage" DATA-IMPORTANT="false">Understanding Encryption Key Management in Snowflake | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723625385">All Snowflake customer data is encrypted by default using the latest security standards and best practices. Snowflake uses strong AES 256-bit encryption with a hierarchical key model rooted in a hardware security module.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723703155">When enabled, the combination of a Snowflake-maintained key and a customer-managed key creates a composite master key to protect the Snowflake data. This is called Tri-Secret Secure.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704938">Snowflake’s hierarchical key model consists of four levels of keys:

The root key

Account master keys

Table master keys

File keys</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723795128">Encryption key rotation¶

All Snowflake-managed keys are automatically rotated by Snowflake when they are more than 30 days old.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets#label-worksheets-manage" ADD_DATE="1723624999" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-worksheets%23label-worksheets-manage" DATA-IMPORTANT="false">Managing and using worksheets in Snowsight | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723624999">After you open a worksheet, select the
visible when you hover over the tab for a worksheet to manage the open worksheet in the following ways:

Rename the worksheet.

Move the worksheet to a folder or a dashboard.

Duplicate the worksheet.

Delete the worksheet.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage/warehouse_metering_history" ADD_DATE="1723624916" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage%2Fwarehouse_metering_history" DATA-IMPORTANT="false">WAREHOUSE_METERING_HISTORY view | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723624916">WAREHOUSE_METERING_HISTORY view¶

This Account Usage view can be used to return the hourly credit usage for a single warehouse (or all the warehouses in your account) within the last 365 days (1 year).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/current_task_graphs" ADD_DATE="1723624837" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fcurrent_task_graphs" DATA-IMPORTANT="false">CURRENT_TASK_GRAPHS | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723624837">CURRENT_TASK_GRAPHS¶

Returns the status of a graph run that is currently scheduled or is executing.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723624855">This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days. To retrieve the details for graph runs that have completed in the past 60 minutes, query the COMPLETE_TASK_GRAPHS table function.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723624874">Returns results only for the ACCOUNTADMIN role, the task owner (i.e. the role with the OWNERSHIP privilege on the task) or a role with the global MONITOR EXECUTION privilege. Note that unless a role with the MONITOR EXECUTION privilege also has the USAGE privilege on the database and schema that store the task, the DATABASE_NAME and SCHEMA_NAME values in the output are NULL.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/access-history" ADD_DATE="1723624794" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Faccess-history" DATA-IMPORTANT="false">Access History | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723624794">Records in the Account Usage QUERY_HISTORY view do not always get recorded in the ACCESS_HISTORY view. The structure of the SQL statement determines whether Snowflake records an entry in the ACCESS_HISTORY view.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723638185">The user access history can be found by querying the Account Usage ACCESS_HISTORY view. The records in this view facilitate regulatory compliance auditing and provide insights on popular and frequently accessed tables and columns because there is a direct link between the user (i.e. query operator), the query, the table or view, the column, and the data.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-overview#custom-roles" ADD_DATE="1723624443" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-overview%23custom-roles" DATA-IMPORTANT="false">Overview of Access Control | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723624443">When creating roles that will serve as the owners of securable objects in the system, Snowflake recommends creating a hierarchy of custom roles, with the top-most custom role assigned to the system role SYSADMIN.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-intro#about-providers" ADD_DATE="1723570824" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-intro%23about-providers" DATA-IMPORTANT="false">About Secure Data Sharing | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570824">A data provider is any Snowflake account that creates shares and makes them available to other Snowflake accounts to consume.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-pipe" ADD_DATE="1723570720" LAST_MODIFIED="1730207885" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-pipe" DATA-IMPORTANT="false">CREATE PIPE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570720">Using a query as the source for the COPY statement for column reordering, column omission, and casts (i.e. transforming data during a load) is supported.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723999881">Identifier for the pipe; must be unique for the schema in which the pipe is created.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/show-grants#variants" ADD_DATE="1723570673" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fshow-grants%23variants" DATA-IMPORTANT="false">SHOW GRANTS | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570673">SHOW GRANTS TO USER current_user. Lists all the roles granted to the current user.</mark>
		<DT><A HREF="https://docs.snowflake.com/developer-guide/stored-procedure/stored-procedures-overview#what-is-a-stored-procedure" ADD_DATE="1723570636" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fdeveloper-guide%2Fstored-procedure%2Fstored-procedures-overview%23what-is-a-stored-procedure" DATA-IMPORTANT="false">Stored procedures overview | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570636">You might want to use a stored procedure to automate a task that requires multiple SQL statements and is performed frequently.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-network-policy" ADD_DATE="1723570548" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-network-policy" DATA-IMPORTANT="false">CREATE NETWORK POLICY | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570548">Only security administrators (i.e. users with the SECURITYADMIN role) or higher or
 a role with the global CREATE NETWORK POLICY privilege can create network policies.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/udf/sql/udf-sql-tabular-functions" ADD_DATE="1723570512" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fudf%2Fsql%2Fudf-sql-tabular-functions" DATA-IMPORTANT="false">Tabular SQL UDFs (UDTFs) | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570512">CREATE OR REPLACE FUNCTION &lt;name&gt; ( [ &lt;arguments&gt; ] ) RETURNS
 TABLE
 ( &lt;output_col_name&gt; &lt;output_col_type&gt; [, &lt;output_col_name&gt; &lt;output_col_type&gt; ... ] ) AS &#39;&lt;sql_expression&gt;&#39;</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/get_stage_location" ADD_DATE="1723570359" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fget_stage_location" DATA-IMPORTANT="false">GET_STAGE_LOCATION | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570359">GET_STAGE_LOCATION¶

Retrieves the URL for an external or internal named stage using the stage name as the input.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/external-functions-introduction" ADD_DATE="1723570270" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fexternal-functions-introduction" DATA-IMPORTANT="false">Introduction to external functions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570270">An external function is a type of UDF
. Unlike other UDFs, an external function does not contain its own code; instead, the external function calls code that is stored and executed outside Snowflake.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-materialized#label-limitations-on-creating-materialized-views" ADD_DATE="1723570074" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-materialized%23label-limitations-on-creating-materialized-views" DATA-IMPORTANT="false">Working with Materialized Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570074">The following limitations apply to creating materialized views:

A materialized view can query only a single table.

Joins, including self-joins, are not supported.

A materialized view cannot query:

A materialized view.

A non-materialized view.

A UDTF (user-defined table function).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/system_clustering_information" ADD_DATE="1723570005" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fsystem_clustering_information" DATA-IMPORTANT="false">SYSTEM$CLUSTERING_INFORMATION | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723570005">SYSTEM$CLUSTERING_INFORMATION¶

Returns clustering information, including average clustering depth, for a table based on one or more columns in the table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570028">average_overlaps

Average number of overlapping micro-partitions for each micro-partition in the table. A high number indicates the table is not well-clustered.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-provider#general-data-sharing-considerations-and-usage" ADD_DATE="1723569510" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-provider%23general-data-sharing-considerations-and-usage" DATA-IMPORTANT="false">Create and configure shares | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723569510">For data security and privacy reasons, only secure views
 are supported in shares at this time. If a standard view is added to a share, Snowflake returns an error.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/search-optimization-service#understanding-the-search-optimization-service" ADD_DATE="1723569414" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsearch-optimization-service%23understanding-the-search-optimization-service" DATA-IMPORTANT="false">Search Optimization Service | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723639515">The search optimization service aims to significantly improve the performance of certain types of queries on tables, including:

Selective point lookup queries on tables.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/resource-monitors#actions" ADD_DATE="1723569269" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fresource-monitors%23actions" DATA-IMPORTANT="false">Working with resource monitors | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723569269">Resource monitors support the following actions:

Notify &amp; Suspend:

Send a notification and suspend all assigned warehouses after all statements being executed by the warehouse(s) have completed.

Notify &amp; Suspend Immediately:

Send a notification and suspend all assigned warehouses immediately, which cancels any statements being executed by the warehouses at the time.

Notify:

Perform no action on warehouses, but send a notification.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/resource-monitors#monitor-level" ADD_DATE="1723569190" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fresource-monitors%23monitor-level" DATA-IMPORTANT="false">Working with resource monitors | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723569190">A single monitor can be set at the account level to control credit usage for all warehouses in your account.</mark>
		<DT><A HREF="https://www.snowflake.com/en/legal/snowflakes-security-and-compliance-reports/" ADD_DATE="1723568962" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://publish-p57963-e462109.adobeaemcloud.com/content/dam/snowflake-site/general/technical/default-og-image/snowflake-social-share.png" DATA-IMPORTANT="false">Snowflake&#39;s Security and Compliance Reports</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568962">SNOWFLAKE’S SECURITY &amp; COMPLIANCE REPORTS</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/show-tables" ADD_DATE="1723568823" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fshow-tables" DATA-IMPORTANT="false">SHOW TABLES | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568823">SHOW TABLES</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723568888">bytes

	

Number of bytes that will be scanned if the entire table is scanned in a query. Note that this number may be different than the number of actual physical bytes (i.e. bytes stored on-disk) for the table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-intro#reader-accounts-for-third-party-access" ADD_DATE="1723568671" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-intro%23reader-accounts-for-third-party-access" DATA-IMPORTANT="false">About Secure Data Sharing | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568671">Data sharing is only supported between Snowflake accounts. As a data provider, you might want to share data with a consumer who does not already have a Snowflake account or is not ready to become a licensed Snowflake customer.

To facilitate sharing data with these consumers, you can create reader accounts. Reader accounts (formerly known as “read-only accounts”) provide a quick, easy, and cost-effective way to share data without requiring the consumer to become a Snowflake customer.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-are-credits-charged-for-warehouses" ADD_DATE="1723568533" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-considerations%23how-are-credits-charged-for-warehouses" DATA-IMPORTANT="false">Warehouse considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568533">The minimum billing charge for provisioning compute resources is 1 minute (i.e. 60 seconds).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/get" ADD_DATE="1723568394" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fget" DATA-IMPORTANT="false">GET | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568394">If the directory path includes special characters, the entire file URI must be enclosed in single quotes. Note that the drive and path separator is a forward slash (/
) in enclosed URIs (e.g. &#39;file://C:/temp/load
 data&#39;
 for a path in Windows that includes a directory named load
 data
).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-are-micro-partitions" ADD_DATE="1723568308" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-clustering-micropartitions%23what-are-micro-partitions" DATA-IMPORTANT="false">Micro-partitions &amp; Data Clustering | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568308">All data in Snowflake tables is automatically divided into micro-partitions, which are contiguous units of storage. Each micro-partition contains between 50 MB and 500 MB of uncompressed data (note that the actual size in Snowflake is smaller because data is always stored compressed). Groups of rows in tables are mapped into individual micro-partitions, organized in a columnar fashion.</mark>
		<DT><A HREF="https://www.snowflake.com/blog/best-practices-for-data-ingestion/" ADD_DATE="1723568245" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://www.snowflake.com/wp-content/uploads/2022/06/SF_Data_Ingestion.jpeg" DATA-IMPORTANT="false">Best Practices for Data Ingestion with Snowflake - Blog</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568245">Recommended file size for Snowpipe and cost considerations

There is a fixed, per-file overhead charge for Snowpipe in addition to the compute processing costs. We recommend files at least above 10 MB on average, with files in the 100 to 250 MB range offering the best cost-to-performance ratio.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/system_clustering_depth" ADD_DATE="1723568159" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fsystem_clustering_depth" DATA-IMPORTANT="false">SYSTEM$CLUSTERING_DEPTH | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568159">SYSTEM$CLUSTERING_DEPTH¶

Computes the average depth of the table according to the specified columns (or the clustering key defined for the table). The average depth of a populated table (i.e. a table containing data) is always 1 or more. The smaller the average depth, the better clustered the table is with regards to the specified columns.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage" ADD_DATE="1723568106" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-local-file-system-stage" DATA-IMPORTANT="false">Staging data files from a local file system | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723568106">Note that the @~
 character combination identifies a user stage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723568117">Note that the @%
 character combination identifies a table stage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723568124">Note that the @
 character by itself identifies a named stage.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage/table_storage_metrics" ADD_DATE="1723567813" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage%2Ftable_storage_metrics" DATA-IMPORTANT="false">TABLE_STORAGE_METRICS view | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567813">TABLE_STORAGE_METRICS view¶

This Account Usage view displays table-level storage utilization information, which is used to calculate the storage billing for each table in the account, including tables that have been dropped, but are still incurring storage costs.</mark>
		<DT><A HREF="https://other-docs.snowflake.com/en/collaboration/consumer-listings-access#accessing-listings-on-the-marketplace" ADD_DATE="1723567761" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fother-docs.snowflake.com%2Fen%2Fcollaboration%2Fconsumer-listings-access%23accessing-listings-on-the-marketplace" DATA-IMPORTANT="false">Access and install listings as a consumer | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567761">You must use the ACCOUNTADMIN role or another role with the CREATE DATABASE and IMPORT SHARE privileges to access a listing.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage/access_history" ADD_DATE="1723567598" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage%2Faccess_history" DATA-IMPORTANT="false">ACCESS_HISTORY view | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567598">This Account Usage view can be used to query the access history of Snowflake objects (e.g. table, view, column) within the last 365 days (1 year).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-column-ext-token-use" ADD_DATE="1723567506" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-column-ext-token-use" DATA-IMPORTANT="false">Using External Tokenization | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567506">Protegrity</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-failsafe#what-is-fail-safe" ADD_DATE="1723567399" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-failsafe%23what-is-fail-safe" DATA-IMPORTANT="false">Understanding and viewing Fail-safe | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567399">Fail-safe provides a (non-configurable) 7-day period during which historical data may be recoverable by Snowflake.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-metadata" ADD_DATE="1723567303" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-metadata" DATA-IMPORTANT="false">Querying Metadata for Staged Files | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567303">Metadata Columns¶

Currently, the following metadata columns can be queried or copied into tables:

METADATA$FILENAME

Name of the staged data file the current row belongs to. Includes the full path to the data file.

METADATA$FILE_ROW_NUMBER

Row number for each record in the staged data file.

METADATA$FILE_CONTENT_KEY

Checksum of the staged data file the current row belongs to.

METADATA$FILE_LAST_MODIFIED

Last modified timestamp of the staged data file the current row belongs to. Returned as TIMESTAMP_NTZ.

METADATA$START_SCAN_TIME

Start timestamp of operation for each record in the staged data file. Returned as TIMESTAMP_LTZ.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/semistructured-intro" ADD_DATE="1723567261" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsemistructured-intro" DATA-IMPORTANT="false">Introduction to Loading Semi-structured Data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567261">Semi-structured data is typically stored in the following Snowflake data types:

ARRAY: similar to an array in other languages.

OBJECT: similar to a JSON object, also called a “dictionary”, “hash”, or “map” in many languages. This contains key-value pairs.

VARIANT: a data type that can hold a value of any other data type (including ARRAY and OBJECT). VARIANT is used to build and store hierarchical data.</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/data-sharing-multiple-db" ADD_DATE="1723567221" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fdata-sharing-multiple-db" DATA-IMPORTANT="false">Share data from multiple databases | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567221">A provider stores customer data in separate databases and does not want to create new objects in those databases. To share data, the provider creates a new database with a secure view. The secure view references objects (schema, table, view) in the databases with customer data.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/snowcd" ADD_DATE="1723567111" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsnowcd" DATA-IMPORTANT="false">SnowCD (Connectivity Diagnostic Tool) | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567111">SnowCD (i.e. Snowflake Connectivity Diagnostic Tool) helps users to diagnose and troubleshoot their network connection to Snowflake.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724183099">For example, users can integrate SnowCD into these use cases:

Automated deployment scripts.

A prerequisite check before deploying a service that connects to Snowflake.

Environment checks while starting a new machine.

Periodic checks on running machines.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/parameters#label-allow-client-mfa-caching" ADD_DATE="1723567068" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fparameters%23label-allow-client-mfa-caching" DATA-IMPORTANT="false">Parameters | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723567068">ALLOW_CLIENT_MFA_CACHING¶
Type:

Account — Can only be set for Account</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723567082">Specifies whether an MFA token can be saved in the client-side operating system keystore to promote continuous, secure connectivity without users needing to respond to an MFA prompt at the start of each connection attempt to Snowflake.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-editions#enterprise-edition" ADD_DATE="1723566974" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-editions%23enterprise-edition" DATA-IMPORTANT="false">Snowflake Editions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566974">Column-level Security to apply masking policies to columns in tables or views.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-considerations#scaling-up-vs-scaling-out" ADD_DATE="1723566938" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-considerations%23scaling-up-vs-scaling-out" DATA-IMPORTANT="false">Warehouse considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566938">Decreasing the size of a running warehouse removes compute resources from the warehouse. When the computer resources are removed, the cache associated with those resources is dropped, which can impact performance in the same way that suspending the warehouse can impact performance after it is resumed.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-prepare#supported-file-formats" ADD_DATE="1723566836" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-prepare%23supported-file-formats" DATA-IMPORTANT="false">Preparing to unload data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566836">When unloading to JSON files, Snowflake outputs to the NDJSON
 (newline delimited JSON) standard format.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-gs" ADD_DATE="1723566460" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-gs" DATA-IMPORTANT="false">Getting started with Snowsight | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566460">Your active role determines which pages in Snowsight you can access, as well as which databases, tables, and other objects you can see and the actions you can perform on them.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723569377">To determine the fully qualified URL and port for Snowsight, run the SYSTEM$ALLOWLIST
 function and review the SNOWSIGHT_DEPLOYMENT
 entry in the return value.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/session-policies#session-policies" ADD_DATE="1723566412" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsession-policies%23session-policies" DATA-IMPORTANT="false">Snowflake Sessions &amp; Session Policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566412">The minimum configurable idle timeout value for a session policy is 5 minutes.

If a session policy is not set, Snowflake uses a default value of 240 minutes (four hours).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles" ADD_DATE="1723566143" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-overview%23system-defined-roles" DATA-IMPORTANT="false">Overview of Access Control | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566154">USERADMIN:

(aka User and Role Administrator)

Role that is dedicated to user and role management only.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723566162">SECURITYADMIN:

(aka Security Administrator)

Role that can manage any object grant globally, as well as create, monitor, and manage users and roles.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-snowpipe-billing" ADD_DATE="1723566084" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-snowpipe-billing" DATA-IMPORTANT="false">Snowpipe costs | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566084">Snowflake tracks the resource consumption of loads for all pipes in an account, with per-second/per-core granularity,</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723566108">er-core refers to the physical CPU cores in a compute server. The utilization recorded is then translated into familiar Snowflake credits, which are listed on the bill for your account.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-failsafe" ADD_DATE="1723566048" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-failsafe" DATA-IMPORTANT="false">Understanding and viewing Fail-safe | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723566048">Fail-safe provides a (non-configurable) 7-day period during which historical data may be recoverable by Snowflake.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/ddl-database" ADD_DATE="1723565997" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fddl-database" DATA-IMPORTANT="false">Database, schema, &amp; share DDL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565997">Together, a database and schema comprise a namespace
 in Snowflake.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570581">Databases and schemas are used to organize data stored in Snowflake:

A database is a logical grouping of schemas. Each database belongs to a single Snowflake account.

A schema is a logical grouping of database objects (tables, views, etc.). Each schema belongs to a single database.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-editions#data-sharing" ADD_DATE="1723565972" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-editions%23data-sharing" DATA-IMPORTANT="false">Snowflake Editions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565972">Data Sharing</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/unstructured-data-sharing" ADD_DATE="1723565859" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Funstructured-data-sharing" DATA-IMPORTANT="false">Sharing unstructured data with a secure view | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565859">Sharing unstructured data with a secure view</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723565874">Scoped URL¶

This example calls the BUILD_SCOPED_FILE_URL function to create a secure view with the scoped URLs for a set of staged files.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723565881">Pre-signed URL¶

This example calls the GET_PRESIGNED_URL function to retrieve the pre-signed URLs for a set of staged files.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services" ADD_DATE="1723565785" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-key-concepts%23cloud-services" DATA-IMPORTANT="false">Key Concepts &amp; Architecture | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565785">Services managed in this layer include:

Authentication

Infrastructure management

Metadata management

Query parsing and optimization

Access control</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/copy-into-location" ADD_DATE="1723565754" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcopy-into-location" DATA-IMPORTANT="false">COPY INTO location | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565754">VALIDATION_MODE = RETURN_ROWS

String (constant) that instructs the COPY command to return the results of the query in the SQL statement instead of unloading the results to the specified cloud storage location. The only supported validation option is RETURN_ROWS. This option returns all rows produced by the query.

When you have validated the query, you can remove the VALIDATION_MODE to perform the unload operation.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723625636">SINGLE = TRUE | FALSE
Definition:

Boolean that specifies whether to generate a single file or multiple files. If FALSE, a filename prefix must be included in path.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/copy-into-table" ADD_DATE="1723565698" LAST_MODIFIED="1730207889" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcopy-into-table" DATA-IMPORTANT="false">COPY INTO table | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565698">VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS

String (constant) that instructs the COPY command to validate the data files instead of loading them into the specified table; i.e. the COPY command tests the files for errors but does not load them. The command validates the data to be loaded and returns results based on the validation option specified:

Supported Values

	

Notes




RETURN_n_ROWS (e.g. RETURN_10_ROWS)

	

Validates the specified number of rows, if no errors are encountered; otherwise, fails at the first error encountered in the rows.




RETURN_ERRORS

	

Returns all errors (parsing, conversion, etc.) across all files specified in the COPY statement.




RETURN_ALL_ERRORS

	

Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723997920">VALIDATION_MODE does not support COPY statements that transform data during a load. If the parameter is specified, the COPY statement returns an error.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-considerations#empty-strings-and-null-values" ADD_DATE="1723565630" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-considerations%23empty-strings-and-null-values" DATA-IMPORTANT="false">Data unloading considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565630">NULL_IF = ( &#39;string1&#39; [ , &#39;string2&#39; ... ] )

When unloading data from tables: Snowflake converts SQL NULL values to the first value in the list. Be careful to specify a value that you want interpreted as NULL.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723565659">EMPTY_FIELD_AS_NULL = TRUE | FALSE

When unloading empty string data from tables, choose one of the following options:

Preferred: Enclose strings in quotes by setting the FIELD_OPTIONALLY_ENCLOSED_BY option, to distinguish empty strings from NULLs in output CSV files.

Leave string fields unenclosed by setting the FIELD_OPTIONALLY_ENCLOSED_BY option to NONE (default), and set the EMPTY_FIELD_AS_NULL value to FALSE to unload empty strings as empty fields.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-overview#default-warehouse-for-client-utilities-drivers-connectors" ADD_DATE="1723565499" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-overview%23default-warehouse-for-client-utilities-drivers-connectors" DATA-IMPORTANT="false">Overview of warehouses | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565499">In addition to default warehouses for users, any of the Snowflake clients (SnowSQL, JDBC driver, ODBC driver, Python connector, etc.) can have a default warehouse:

SnowSQL supports both a configuration file and command line option for specifying a default warehouse.

The drivers and connectors support specifying a default warehouse as a connection parameter when initiating a session.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/guides-overview-govern" ADD_DATE="1723565400" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fguides-overview-govern" DATA-IMPORTANT="false">Data Governance in Snowflake | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565400">Data Classification

Allows categorizing potentially personal and/or sensitive data to support compliance and privacy regulations.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-encryption-manage#hierarchical-key-model" ADD_DATE="1723565338" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-encryption-manage%23hierarchical-key-model" DATA-IMPORTANT="false">Understanding Encryption Key Management in Snowflake | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565338">A hierarchical key model provides a framework for Snowflake’s encryption key management. The hierarchy is composed of several layers of keys in which each higher layer of keys (parent keys) encrypts the layer below (child keys). In security terminology, a parent key encrypting all child keys is known as “wrapping”.

Snowflake’s hierarchical key model consists of four levels of keys:

The root key

Account master keys

Table master keys

File keys</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/scim-intro" ADD_DATE="1723565250" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fscim-intro" DATA-IMPORTANT="false">Snowflake SCIM support | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565250">The Snowflake SCIM API can address the following use cases.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723565262">Managing users: Administrators can provision and manage their users from their organization’s identity provider to Snowflake. User management is a one-to-one mapping from the identity provider to Snowflake.

Managing groups: Administrators can provision and manage their groups (i.e. Roles) from their organization’s identity provider to Snowflake. Role management is a one-to-one mapping from the identity provider to Snowflake.

Auditing SCIM API requests: Administrators can query the rest_event_history table to determine whether the identity provider is sending updates (i.e. SCIM API requests) to Snowflake.

SCIM API</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#semi-structured-data-size-limitations" ADD_DATE="1723565090" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-considerations-prepare%23semi-structured-data-size-limitations" DATA-IMPORTANT="false">Preparing your data files | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723565090">If the data exceeds 16 MB, enable the STRIP_OUTER_ARRAY file format option for the COPY INTO &lt;table&gt; command to remove the outer array structure and load the records into separate table rows</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-temp-transient" ADD_DATE="1723564913" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-temp-transient" DATA-IMPORTANT="false">Working with Temporary and Transient Tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723564913">Temporary tables only exist within the session in which they were created and persist only for the remainder of the session. As such, they are not visible to other users or sessions.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570108">because transient tables do not utilize Fail-safe, there are no Fail-safe costs</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-semistructured" ADD_DATE="1723562259" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-semistructured" DATA-IMPORTANT="false">Querying Semi-structured Data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723562259">Regardless of which notation you use, the column name is case-insensitive but element names are case-sensitive. For example, in the following list, the first two paths are equivalent, but the third is not:

src:salesperson.name

SRC:salesperson.name

SRC:Salesperson.Name</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723625707">FLATTEN is a table function that produces a lateral view of a VARIANT, OBJECT, or ARRAY column. The function returns a row for each object, and the LATERAL modifier joins the data with any information outside of the object.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/organizations#orgadmin-role" ADD_DATE="1723562183" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Forganizations%23orgadmin-role" DATA-IMPORTANT="false">Introduction to organizations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723562183">A user with the ORGADMIN role can perform the following actions:

Create an account in the organization. For more information, refer to Creating an account.

View/show all accounts within the organization. For more information, refer to Viewing accounts in your organization.

View/show a list of regions enabled for the organization. For more information, see Viewing a List of Regions Available for an Organization.

View usage information for all accounts in the organization. For more information, see Organization Usage.

Enable replication for an account in the organization. For more information, see Prerequisite: Enable replication for accounts in the organization.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-query-profile#inefficient-pruning" ADD_DATE="1723562118" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-query-profile%23inefficient-pruning" DATA-IMPORTANT="false">Analyzing Queries Using Query Profile | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723562118">Snowflake collects rich statistics on data allowing it not to read unnecessary parts of a table based on the query filters.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/performance-query-warehouse" ADD_DATE="1723562038" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fperformance-query-warehouse" DATA-IMPORTANT="false">Optimizing warehouses for performance | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723562038">Reduce queues

	

Minimizing queuing can improve performance because the time between submitting a query and getting its results is longer when the query must wait in a queue before starting.




Resolve memory spillage

	

Adjusting the available memory of a warehouse can improve performance because a query runs substantially slower when a warehouse runs out of memory, which results in bytes “spilling” onto storage.




Increase warehouse size

	

The larger a warehouse, the more compute resources are available to execute a query or set of queries.




Try query acceleration

	

The query acceleration service offloads portions of query processing to serverless compute resources, which speeds up the processing of a query while reducing its demand on the warehouse’s compute resources.




Optimize the warehouse cache

	

Query performance improves if a query can read from the warehouse’s cache instead of from tables.




Limit concurrently running queries

	

Limiting the number of queries that are running concurrently in a warehouse can improve performance because there are fewer queries putting demands on the warehouse’s resources.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-clustering-keys" ADD_DATE="1723561663" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-clustering-keys" DATA-IMPORTANT="false">Clustering Keys &amp; Clustered Tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723561663">Whether you want faster response times or lower overall costs, clustering is best for a table that meets all
 of the following criteria:

The table contains a large number of micro-partitions
. Typically, this means that the table contains multiple terabytes (TB) of data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561686">Snowflake recommends prioritizing keys in the order below:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561692">Cluster columns that are most actively used in selective filters.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561703">If there is room for additional cluster keys, then consider columns frequently used in join predicates</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561715">The number of distinct values (i.e. cardinality) in a column/expression is a critical aspect of selecting it as a clustering key. It is important to choose a clustering key that has:

A large enough number of distinct values to enable effective pruning on the table.

A small enough number of distinct values to allow Snowflake to effectively group rows in the same micro-partitions.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723796067">Defining a Clustering Key for a Table¶

A clustering key can be defined when a table is created by appending a CLUSTER BY clause to CREATE TABLE</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724068590">Therefore, clustering is generally most cost-effective for tables that are queried frequently and do not change frequently.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724068682">For most tables, Snowflake recommends a maximum of 3 or 4 columns (or expressions) per key. Adding more than 3-4 columns tends to increase costs more than benefits.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724068845">If you are defining a multi-column clustering key for a table, the order in which the columns are specified in the CLUSTER BY clause is important. As a general rule, Snowflake recommends ordering the columns from lowest cardinality to highest cardinality.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724068892">In some cases, clustering on columns used in GROUP BY or ORDER BY clauses can be helpful. However, clustering on these columns is usually less helpful than clustering on columns that are heavily used in filter or JOIN operations.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724069034">Use the system function, SYSTEM$CLUSTERING_INFORMATION, to calculate clustering details, including clustering depth, for a given table. This function can be run on any columns on any table, regardless of whether the table has an explicit clustering key</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-prepare" ADD_DATE="1723561460" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-prepare" DATA-IMPORTANT="false">Preparing to unload data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723561460">Structured

	

Delimited (CSV, TSV, etc.)

	

Any valid singlebyte delimiter is supported; default is comma (i.e. CSV).




Semi-structured

	

JSON, Parquet</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-releases" ADD_DATE="1723561388" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-releases" DATA-IMPORTANT="false">Snowflake Releases | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723561388">This topic describes the process we follow for weekly releases, including the option to request 12-hour early access for Enterprise Edition and Business Critical Edition accounts, or 24-hour early access for Virtual Private Snowflake (VPS) accounts to enable additional release testing (if desired).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561402">Each week, Snowflake deploys two planned/scheduled releases</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561428">Each month (except for November and December), Snowflake selects one of the weekly full releases for the month to introduce behavior changes.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/drop-role" ADD_DATE="1723561246" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fdrop-role" DATA-IMPORTANT="false">DROP ROLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723561246">Ownership of any objects owned by the dropped role is transferred to the role that executes the DROP ROLE command.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/resource-monitors" ADD_DATE="1723561149" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fresource-monitors" DATA-IMPORTANT="false">Working with resource monitors | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723561149">Select the Monitor Level. Choose Account to create an account monitor or choose Warehouse to select the warehouses to monitor.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723568034">Only users with the ACCOUNTADMIN role can create a resource monitor, but an account administrator can grant privileges to other roles to allow other users to view and modify resource monitors.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635321">You can use a resource monitor to monitor credit usage by virtual warehouses and the cloud services needed to support those warehouses.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723798590">However, roles that have been granted the following privileges on specific resource monitors can view and modify the resource monitor as needed using SQL:

MONITOR

MODIFY</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920648">A single monitor can be set at the account level to control credit usage for all warehouses in your account.

In addition, a one or more warehouses can be assigned to a resource monitor, thereby controlling the credit usage for each assigned warehouse. Note, however, that a warehouse can be assigned to only a single resource monitor below the account level.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-multicluster#maximized-vs-auto-scale" ADD_DATE="1723561029" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-multicluster%23maximized-vs-auto-scale" DATA-IMPORTANT="false">Multi-cluster warehouses | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723561029">You can choose to run a multi-cluster warehouse in either of the following modes:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561042">Maximized:

This mode is enabled by specifying the same value for both maximum and minimum number of clusters (note that the specified value must be larger than 1). In this mode, when the warehouse is started, Snowflake starts all the clusters so that maximum resources are available while the warehouse is running.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561049">Auto-scale:

This mode is enabled by specifying different values for maximum and minimum number of clusters. In this mode, Snowflake starts and stops clusters as needed to dynamically manage the load on the warehouse</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561064">Snowflake supports the following scaling policies:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561067">Standard (default)</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561074">After 2 to 3 consecutive successful checks (performed at 1 minute intervals), which determine whether the load on the least-loaded cluster could be redistributed to the other clusters without spinning up the cluster again.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561080">Economy</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561084">After 5 to 6 consecutive successful checks (performed at 1 minute intervals), which determine whether the load on the least-loaded cluster could be redistributed to the other clusters without spinning up the cluster again.

Note</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension" ADD_DATE="1723560993" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-considerations%23automating-warehouse-suspension" DATA-IMPORTANT="false">Warehouse considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560993">ou might want to consider disabling auto-suspend for a warehouse if:

You have a heavy, steady workload for the warehouse.

You require the warehouse to be available with no delay or lag time. Warehouse provisioning is generally very fast (e.g. 1 or 2 seconds); however, depending on the size of the warehouse and the availability of compute resources to provision, it can take longer.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-considerations-plan" ADD_DATE="1723560947" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-considerations-plan" DATA-IMPORTANT="false">Planning a data load | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560947">The number of data files that can be processed in parallel is determined by the amount of compute resources in a warehouse. I</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-stage" ADD_DATE="1723560892" LAST_MODIFIED="1730207894" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-stage" DATA-IMPORTANT="false">CREATE STAGE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560892">Specifies that the stage created is temporary and will be dropped at the end of the session in which it was created.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723625324">All files are also automatically encrypted using AES-256 strong encryption on the server side.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723796158">SNOWFLAKE_FULL: Client-side and server-side encryption. The files are encrypted by a client when it uploads them to the internal stage using PUT. Snowflake uses a 128-bit encryption key by default. You can configure a 256-bit key by setting the CLIENT_ENCRYPTION_KEY_SIZE parameter.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724094879">If you require Tri-Secret Secure for security compliance, use the SNOWFLAKE_FULL encryption type for internal stages. SNOWFLAKE_SSE does not support Tri-Secret Secure.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/network-policies" ADD_DATE="1723560828" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fnetwork-policies" DATA-IMPORTANT="false">Controlling network traffic with network policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560828">You need the CREATE NETWORK RULE privilege on the schema to create a network rule. By default, only the ACCOUNTADMIN and SECURITYADMIN roles, along with the schema owner, have this privilege.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561511">Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global CREATE NETWORK POLICY privilege can create network policies. Ownership of a network policy can be transferred to another role.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723636660">If a network policy has the same IP address values in both the ALLOWED_IP_LIST and the BLOCKED_IP_LIST parameters, Snowflake applies the values in the BLOCKED_IP_LIST parameter first. This behavior also applies to the ALLOWED_NETWORK_RULE_LIST and the BLOCKED_NETWORK_RULE_LIST parameters.</mark>
		<DT><A HREF="https://community.snowflake.com/s/article/How-to-Load-Terabytes-Into-Snowflake-Speeds-Feeds-and-Techniques" ADD_DATE="1723560715" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://www.snowflake.com/wp-content/themes/snowflake/assets/img/community/community-social-share.jpg" DATA-IMPORTANT="false">Snowflake Community</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560715">Loading from Gzipped CSV is several times faster than loading from ORC and Parquet at an impressive 15 TB/Hour.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-considerations#multi-cluster-warehouses-improve-concurrency" ADD_DATE="1723560669" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-considerations%23multi-cluster-warehouses-improve-concurrency" DATA-IMPORTANT="false">Warehouse considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560669">Multi-cluster warehouses are designed specifically for handling queuing and performance issues related to large numbers of concurrent users and/or queries.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/kafka-connector-install" ADD_DATE="1723560612" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fkafka-connector-install" DATA-IMPORTANT="false">Installing and configuring the Kafka connector | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560612">The package includes all dependencies required to use either an encrypted or unencrypted private key for key pair authentication.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/split_to_table" ADD_DATE="1723560527" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fsplit_to_table" DATA-IMPORTANT="false">SPLIT_TO_TABLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560527">SPLIT_TO_TABLE¶

This table function splits a string (based on a specified delimiter) and flattens the results into rows.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas" ADD_DATE="1723560342" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-configure%23label-managed-access-schemas" DATA-IMPORTANT="false">Configuring access control | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560342">In regular (i.e. non-managed) schemas, object owners (i.e. a role with the OWNERSHIP privilege on an object) can grant access on their objects to other roles, with the option to further grant those roles the ability to manage object grants</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723560377">With managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723921493">The following table indicates which roles can manage object privileges in a regular or managed access schema:

Role

	

Can grant object privileges in a regular schema

	

Can grant object privileges in a managed access schema




SYSADMIN

	

No

	

No




SECURITYADMIN or higher

	

Yes

	

Yes




Database owner

	

No

	

No




Schema owner

	

No

	

Yes




Object owner

	

Yes

	

No




Any role with the MANAGE GRANTS privilege

	

Yes

	

Yes</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724095801">Execute an ALTER SCHEMA statement with the ENABLE | DISABLE MANAGED ACCESS keywords.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-share#access-control-requirements" ADD_DATE="1723560255" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-share%23access-control-requirements" DATA-IMPORTANT="false">CREATE SHARE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560255">CREATE SHARE

	

Account

	

Only the ACCOUNTADMIN role has this privilege by default. The privilege can be granted to additional roles as needed.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-a-relational-table-to-json" ADD_DATE="1723560221" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-considerations%23unloading-a-relational-table-to-json" DATA-IMPORTANT="false">Data unloading considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560221">You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/validate" ADD_DATE="1723560158" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fvalidate" DATA-IMPORTANT="false">VALIDATE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723560158">VALIDATE¶

Validates the files loaded in a past execution of the COPY INTO &lt;table&gt; command and returns all the errors encountered during the load, rather than just the first error.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723560176">JOB_ID =&gt; query_id | _last

The ID for the COPY INTO &lt;table&gt; command to be validated:</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema" ADD_DATE="1723559880" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage%23differences-between-account-usage-and-information-schema" DATA-IMPORTANT="false">Account Usage | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559880">Certain account usage views provide historical usage metrics. The retention period for these views is 1 year (365 days).

In contrast, the corresponding views and table functions in the Snowflake Information Schema have much shorter retention periods, ranging from 7 days to 6 months, depending on the view.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723559907">Due to the process of extracting the data from Snowflake’s internal metadata store, the account usage views have some natural latency:

For most of the views, the latency is 2 hours (120 minutes).

For the remaining views, the latency varies between 45 minutes and 3 hours.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723559913">In contrast, views/table functions in the Snowflake Information Schema do not have any latency.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723559938">Account usage views include records for all objects that have been dropped.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-provider" ADD_DATE="1723559706" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-provider" DATA-IMPORTANT="false">Create and configure shares | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559706">Before creating a share, Snowflake recommends identifying the Snowflake objects you plan to share:

Databases

Tables

Dynamic tables

External tables

Iceberg tables

Secure views

Secure materialized views

Secure user-defined functions (UDFs)</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723624389">You can remove objects from an existing share at any time. Any objects that you remove from a share are instantly unavailable to the consumers accounts who have created databases from the share.

For example, if you remove a table from a share, users in consumer accounts can no longer query the data in the table as soon as the table is removed from the share.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723639786">Creating a share¶

You must use the ACCOUNTADMIN role or a role that has been granted the CREATE SHARE global privilege to create shares</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723639793">Use the CREATE SHARE command to create an empty share.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-share" ADD_DATE="1723559572" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-share" DATA-IMPORTANT="false">ALTER SHARE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559572">ADD | REMOVE ACCOUNTS = consumer_account [ , consumer_account , ... ]

Specifies the name of the account(s) to add or remove from the list of accounts for the share</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/performance-query-warehouse-memory" ADD_DATE="1723559431" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fperformance-query-warehouse-memory" DATA-IMPORTANT="false">Queries too large to fit in memory | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559438">Data spilling to storage can have a negative impact on query performance (especially if the query has to spill to remote storage). To alleviate this, Snowflake recommends:

Using a larger warehouse (effectively increasing the available memory/local storage space for the operation)

Processing data in smaller batches.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions" ADD_DATE="1723559377" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions" DATA-IMPORTANT="false">Scalar functions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559377">A scalar function is a function that returns one value per invocation</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-column-intro#what-are-masking-policies" ADD_DATE="1723559348" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-column-intro%23what-are-masking-policies" DATA-IMPORTANT="false">Understanding Column-level Security | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559348">Object owners (i.e. the role that has the OWNERSHIP privilege on the object) do not have the privilege to unset masking policies.

Object owners cannot view column data in which a masking policy applies.</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/data-load-snowpipe-intro" ADD_DATE="1723559293" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fdata-load-snowpipe-intro" DATA-IMPORTANT="false">Snowpipe | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559293">Snowpipe loads the new data files into the target table in a continuous, serverless fashion based on the parameters defined in a specified pipe object.</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/data-sharing-reader-create" ADD_DATE="1723559230" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fdata-sharing-reader-create" DATA-IMPORTANT="false">Manage reader accounts | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723559230">Reader accounts (formerly known as “read-only accounts”) enable providers to share data with consumers who are not already Snowflake customers, without requiring the consumers to become Snowflake customers.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/snowflake-scripting/loops" ADD_DATE="1723558707" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fsnowflake-scripting%2Floops" DATA-IMPORTANT="false">Working with loops | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723558707">Snowflake Scripting supports the following types of loops:

FOR

WHILE

REPEAT

LOOP</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723558718">A FOR loop repeats a sequence of steps for a specified number of times or for each row in a result set.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723558730">A WHILE loop iterates while a condition is true.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723558737">A REPEAT loop iterates until a condition is true.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723798721">A LOOP loop executes until a BREAK command is executed. A BREAK command is normally embedded inside branching logic (e.g. IF statements or CASE statements).</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/security-column-intro#what-is-column-level-security" ADD_DATE="1723558675" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fsecurity-column-intro%23what-is-column-level-security" DATA-IMPORTANT="false">Understanding Column-level Security | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723558675">Currently, Column-level Security includes two features:

Dynamic Data Masking

External Tokenization</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-data-protection" ADD_DATE="1723558645" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-editions%23security-governance-data-protection" DATA-IMPORTANT="false">Snowflake Editions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723558645">Business Critical Edition, formerly known as Enterprise for Sensitive Data (ESD), offers even higher levels of data protection to support the needs of organizations with extremely sensitive data, particularly PHI data that must comply with HIPAA and HITRUST CSF regulations.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period" ADD_DATE="1723558586" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-time-travel%23data-retention-period" DATA-IMPORTANT="false">Understanding &amp; using Time Travel | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723558586">When the retention period ends for an object, the historical data is moved into Snowflake Fail-safe:

Historical data is no longer available for querying.

Past objects can no longer be cloned.

Past objects that were dropped can no longer be restored.</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/secure-data-sharing-across-regions-platforms" ADD_DATE="1723558533" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fsecure-data-sharing-across-regions-platforms" DATA-IMPORTANT="false">Share data securely across regions and cloud platforms | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723558533">replication to allow data providers to securely share data with data consumers across different regions and cloud platforms.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920050">Since cross-region data sharing utilizes Snowflake data replication functionality, understand how replication works in Snowflake as part of your planning process. For more information, see:

Introduction to replication and failover across multiple accounts

Replication considerations

Replicating databases and account objects across multiple accounts</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920061">Data providers only need to create one copy of the dataset per region; and not a copy per consumer.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920076">When sharing a view that references objects in multiple databases, each of these other databases must be included in the replication group. Sharing data from more than one database requires additional steps. For instructions, see Share data from multiple databases.

You can share content to a Virtual Private Snowflake (VPS) using a listing if the VPS customer has enabled auto-fulfillment. See Support for Auto-fulfillment in Virtual Private Snowflake for more details. Sharing to and from VPS is not supported using a direct share.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724095253">Before configuring data replication, you must create an account in a region where you wish to share data and link it to your local account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724095267">ORGADMIN role must enable replication for the source account</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-clone" ADD_DATE="1723558328" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-clone" DATA-IMPORTANT="false">CREATE object … CLONE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723558328">CREATE &lt;object&gt; … CLONE¶

Creates a copy of an existing object in the system. This command is primarily used for creating zero-copy clones of databases, schemas, and tables; however, it can also be used to quickly/easily create clones of other schema objects , such as external stages, file formats, and sequences, and database roles.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723640222">The clone of the view references the source table with the same fully-qualified name</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ecosystem-all" ADD_DATE="1723558105" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fecosystem-all" DATA-IMPORTANT="false">All Partners &amp; Technologies (Alphabetical) | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723558105">Alation — enterprise data catalog

	

Security, Governance &amp; Observability

	

Snowflake Partner Connect

Snowflake Ready Validated</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570406">If you need to connect to Snowflake using a tool or technology that is not listed here, we suggest attempting to connect through our JDBC
 or ODBC
 drivers.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview#what-is-a-federated-environment" ADD_DATE="1723557681" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fadmin-security-fed-auth-overview%23what-is-a-federated-environment" DATA-IMPORTANT="false">Overview of federated authentication and SSO | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723557681">In a federated environment, user authentication is separated from user access</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-dirtables-query" ADD_DATE="1723557633" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-dirtables-query" DATA-IMPORTANT="false">Querying directory tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723557633">The output from a directory table query can include the following columns:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723557643">RELATIVE_PATH

	

TEXT

	

Path to the files to access using the file URL.




SIZE

	

NUMBER

	

Size of the file (in bytes).




LAST_MODIFIED

	

TIMESTAMP_LTZ

	

Timestamp when the file was last updated in the stage.




MD5

	

HEX

	

MD5 checksum for the file.




ETAG

	

HEX

	

ETag header for the file.




FILE_URL

	

TEXT

	

Snowflake file URL to the file.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723639470">Syntax for querying a directory table:

SELECT * FROM DIRECTORY( @&lt;stage_name&gt; )</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-considerations-manage" ADD_DATE="1723557385" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-considerations-manage" DATA-IMPORTANT="false">Managing regular data loads | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723557385">Staged files can be deleted from a Snowflake stage (user stage, table stage, or named stage) using the following methods:

Files that were loaded successfully can be deleted from the stage during a load by specifying the PURGE copy option in the COPY INTO &lt;table&gt;
 command.

After the load completes, use the REMOVE
 command to remove the files in the stage.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour" ADD_DATE="1723557302" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-quick-tour" DATA-IMPORTANT="false">Snowsight quick tour | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723557302">Monitor activity in Snowsight¶

You can monitor and view query details, explore the performance of executed queries, monitor data loading status and errors, review task graphs, and debug and re-run them as needed. You can also monitor the refresh state of your Dynamic Tables and review the various tagging and security policies that you create to maintain data governance.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/client-redirect" ADD_DATE="1723557137" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fclient-redirect" DATA-IMPORTANT="false">Redirecting client connections | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723557137">Client Redirect enables redirecting your client connections to Snowflake accounts in different regions
 for business continuity and disaster recovery, or when migrating your account to another region or cloud platform.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/object-tagging" ADD_DATE="1723556427" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fobject-tagging" DATA-IMPORTANT="false">Object Tagging | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723556427">This topic provides concepts and instructions on how to use tags in Snowflake.

To learn more about using a masking policy with a tag, see Tag-based masking policies.

 Enterprise Edition Feature

This feature requires Enterprise Edition or higher.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723556480">The string value for each tag can be up to 256 characters</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723560294">Tags enable data stewards to monitor sensitive data for compliance, discovery, protection, and resource usage use cases through either a centralized or decentralized data governance management approach.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/account-replication-intro" ADD_DATE="1723556193" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Faccount-replication-intro" DATA-IMPORTANT="false">Introduction to replication and failover across multiple accounts | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723556193">This feature enables the replication of objects from a source account to one or more target accounts in the same organization. Replicated objects in each target account are referred to as secondary objects and are replicas of the primary objects in the source account. Replication is supported across regions and across cloud platforms.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724154621">Database and share replication are available to all accounts.

Replication of other account objects &amp; failover/failback require Business Critical Edition (or higher). To inquire about upgrading, please contact Snowflake Support.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/replication-intro" ADD_DATE="1723556109" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Freplication-intro" DATA-IMPORTANT="false">Introduction to business continuity &amp; disaster recovery | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723556109">Database and share replication are available to all accounts.

Replication of other account objects, failover/failback, and Client Redirect require Business Critical (or higher).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/organizations-gs" ADD_DATE="1723555977" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Forganizations-gs" DATA-IMPORTANT="false">Getting started with organizations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723555977">If you want to change the name of an organization, for example to change a system-generated name to a more user-friendly one, contact Snowflake Support.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723556058">Once enabled in an account, the ORGADMIN role can be granted to any user or role in the account by an ACCOUNTADMIN using the GRANT ROLE command.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/organizations" ADD_DATE="1723555952" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Forganizations" DATA-IMPORTANT="false">Introduction to organizations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723555952">Once an account is created, ORGADMIN can view the account properties but does not have access to the account data.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-user" ADD_DATE="1723555829" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-user" DATA-IMPORTANT="false">CREATE USER | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723555829">MINS_TO_BYPASS_MFA = &lt;integer&gt;</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api" ADD_DATE="1723553235" LAST_MODIFIED="1730207897" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-unstructured-rest-api" DATA-IMPORTANT="false">REST API for unstructured data support | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723553235">Scoped URL:

Only the user who generated the scoped URL can use the URL to access the referenced file.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570294">GET
 /api/files/
¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920990">File URL:

Any role that has sufficient privileges on the stage can access the file:

External stage: USAGE

Internal stage: READ</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-mfa" ADD_DATE="1723553175" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-mfa" DATA-IMPORTANT="false">Multi-factor authentication (MFA) | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723553175">Snowflake supports MFA token caching with the following drivers and connectors on macOS and Windows. This feature is not supported on Linux.

ODBC driver version 2.23.0 (or later).

JDBC driver version 3.12.16 (or later).

Python Connector for Snowflake version 2.3.7 (or later).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723555658">At a minimum, Snowflake strongly recommends that all users with the ACCOUNTADMIN role be required to use MFA.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723636835">MFA is enabled on a per-user basis; however, at this time, users are not automatically enrolled in MFA. To use MFA, users must enroll themselves.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723640081">MFA support is provided as an integrated Snowflake feature, powered by the Duo Security service, which is managed completely by Snowflake.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/parameters#statement-queued-timeout-in-seconds" ADD_DATE="1723553010" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fparameters%23statement-queued-timeout-in-seconds" DATA-IMPORTANT="false">Parameters | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723553010">Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the MAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723553021">STATEMENT_QUEUED_TIMEOUT_IN_SECONDS</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723553039">Type:

Session and Object (for warehouses)</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/network-policies#bypassing-a-network-policy" ADD_DATE="1723552887" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fnetwork-policies%23bypassing-a-network-policy" DATA-IMPORTANT="false">Controlling network traffic with network policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552887">It is possible to temporarily bypass a network policy for a set number of minutes by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY
, which can be viewed by executing DESCRIBE USER
. Only Snowflake can set the value for this object property. Please contact Snowflake Support
 to set a value for this property.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-considerations" ADD_DATE="1723552827" LAST_MODIFIED="1730207901" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-considerations" DATA-IMPORTANT="false">Data unloading considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552827">When floating-point number
 columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).

The values are not
 truncated when unloading floating-point number columns to Parquet files.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723566376">exporting data from Snowflake tables into files in stages using the COPY INTO &lt;location&gt; command.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570334">You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723796999">By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files. The maximum file size supported is 5 GB for Amazon S3, Google Cloud Storage, or Microsoft Azure stages.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/flatten#output" ADD_DATE="1723552693" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fflatten%23output" DATA-IMPORTANT="false">FLATTEN | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552693">Output¶

The returned rows consist of a fixed set of columns:

+-----+------+------+-------+-------+------+
| SEQ |  KEY | PATH | INDEX | VALUE | THIS |
|-----+------+------+-------+-------+------|

SEQ:

A unique sequence number associated with the input record; the sequence is not guaranteed to be gap-free or ordered in any particular way.

KEY:

For maps or objects, this column contains the key to the exploded value.

PATH:

The path to the element within a data structure which needs to be flattened.

INDEX:

The index of the element, if it is an array; otherwise NULL.

VALUE:

The value of the element of the flattened array/object.

THIS:

The element being flattened (useful in recursive flattening).

Note

The columns of the original (correlated) table which was used as the source of data for FLATTEN are also accessible. If a single row from the original table resulted in multiple rows in the flattened view, the values in this input row are replicated to match the number of rows produced by FLATTEN.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552701">The columns of the original (correlated) table which was used as the source of data for FLATTEN are also accessible. If a single row from the original table resulted in multiple rows in the flattened view, the values in this input row are replicated to match the number of rows produced by FLATTEN.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552711">Output¶

The returned rows consist of a fixed set of columns:

+-----+------+------+-------+-------+------+
| SEQ |  KEY | PATH | INDEX | VALUE | THIS |
|-----+------+------+-------+-------+------|

SEQ:

A unique sequence number associated with the input record; the sequence is not guaranteed to be gap-free or ordered in any particular way.

KEY:

For maps or objects, this column contains the key to the exploded value.

PATH:

The path to the element within a data structure which needs to be flattened.

INDEX:

The index of the element, if it is an array; otherwise NULL.

VALUE:

The value of the element of the flattened array/object.

THIS:

The element being flattened (useful in recursive flattening).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552715">Output¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552727">The returned rows consist of a fixed set of columns:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552733">SEQ:

A unique sequence number associated with the input record; the sequence is not guaranteed to be gap-free or ordered in any particular way.

KEY:

For maps or objects, this column contains the key to the exploded value.

PATH:

The path to the element within a data structure which needs to be flattened.

INDEX:

The index of the element, if it is an array; otherwise NULL.

VALUE:

The value of the element of the flattened array/object.

THIS:

The element being flattened (useful in recursive flattening).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/remove" ADD_DATE="1723552632" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fremove" DATA-IMPORTANT="false">REMOVE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552632">REMOVE¶

Removes files from either an external (external cloud storage) or internal (i.e. Snowflake) stage.

For internal stages, the following stage types are supported:

Named internal stage

Stage for a specified table

Stage for the current user

REMOVE can be abbreviated to RM.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-sharing-reader-create" ADD_DATE="1723552518" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-sharing-reader-create" DATA-IMPORTANT="false">Manage reader accounts | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552518">A reader account is intended primarily for querying data shared by the provider of the account. You can work with data, for example, by creating materialized views.

You cannot perform the following tasks in a reader account:

Set a data metric function on objects in the reader account.

Upload new data.

Modify existing data.

Unload data using a storage integration. However, you can use the COPY INTO &lt;location&gt; command with your connection credentials to unload data into a cloud storage location.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/show-managed-accounts" ADD_DATE="1723552445" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fshow-managed-accounts" DATA-IMPORTANT="false">SHOW MANAGED ACCOUNTS | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552445">SHOW MANAGED ACCOUNTS</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552457">Lists the managed accounts created for your account. Currently used by data providers to create reader accounts for their consumers.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/login_history" ADD_DATE="1723552218" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Flogin_history" DATA-IMPORTANT="false">LOGIN_HISTORY , LOGIN_HISTORY_BY_USER | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552218">LOGIN_HISTORY , LOGIN_HISTORY_BY_USER¶

The LOGIN_HISTORY family of table functions can be used to query login attempts by Snowflake users along various dimensions:

LOGIN_HISTORY returns login events within a specified time range.

LOGIN_HISTORY_BY_USER returns login events of a specified user within a specified time range.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552226">These functions return login activity within the last 7 days.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/show-file-formats" ADD_DATE="1723552012" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fshow-file-formats" DATA-IMPORTANT="false">SHOW FILE FORMATS | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723552012">SHOW FILE FORMATS¶

Lists the file formats for which you have access privileges. This command can be used to list the file formats for a specified database or schema (or the current database/schema for the session), or your entire account.

See also:</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-considerations#using-the-accountadmin-role" ADD_DATE="1723551978" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-considerations%23using-the-accountadmin-role" DATA-IMPORTANT="false">Access control considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551978">By default, when your account is provisioned, the first user is assigned the ACCOUNTADMIN role. This user should then create one or more additional users who are assigned the USERADMIN role. All remaining users should be created by the user(s) with the USERADMIN role or another role that is granted the global CREATE USER privilege.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-snowpipe-manage#label-snowpipe-management-recreate-pipes" ADD_DATE="1723551947" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-snowpipe-manage%23label-snowpipe-management-recreate-pipes" DATA-IMPORTANT="false">Managing Snowpipe | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551947">When a pipe is recreated, the load history is dropped. In general, this condition only affects users if they subsequently execute an ALTER PIPE … REFRESH statement on the pipe. Doing so could load duplicate data from staged files in the storage location for the pipe if the data was already loaded successfully and the files were not deleted subsequently.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/account-usage/login_history" ADD_DATE="1723551824" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Faccount-usage%2Flogin_history" DATA-IMPORTANT="false">LOGIN_HISTORY view | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551824">This Account Usage view can be used to query login attempts by Snowflake users within the last 365 days (1 year).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-storage-integration" ADD_DATE="1723551719" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-storage-integration" DATA-IMPORTANT="false">CREATE STORAGE INTEGRATION | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551719">A storage integration is a Snowflake object that stores a generated identity and access management (IAM) entity for your external cloud storage, along with an optional set of allowed or blocked storage locations (Amazon S3, Google Cloud Storage, or Microsoft Azure).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/streams-intro#types-of-streams" ADD_DATE="1723551565" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fstreams-intro%23types-of-streams" DATA-IMPORTANT="false">Introduction to Streams | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551565">Types of Streams</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551574">Standard:

Supported for streams on standard tables, dynamic tables, Snowflake-managed Iceberg tables, directory tables, or views.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551578">Append-only:

Supported for streams on standard tables, dynamic tables, Snowflake-managed Iceberg tables, or views.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551585">Insert-only:

Supported for streams on dynamic tables, Iceberg tables, or external tables.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter" ADD_DATE="1723551506" LAST_MODIFIED="1730207905" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fsystem_global_account_set_parameter" DATA-IMPORTANT="false">SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551506">SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER¶

Enables replication and failover features for a specified account in an organization.

Once an organization administrator (a user with the ORGADMIN role) has called this function, the following features are enabled for the account:

Replication

Client Redirect</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551524">Only organization administrators (i.e. users with the ORGADMIN role) can call this SQL function.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/current_warehouse" ADD_DATE="1723551219" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fcurrent_warehouse" DATA-IMPORTANT="false">CURRENT_WAREHOUSE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551219">CURRENT_WAREHOUSE¶

Returns the name of the warehouse in use for the current session.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter#usage-notes" ADD_DATE="1723551109" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fsystem_global_account_set_parameter%23usage-notes" DATA-IMPORTANT="false">SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551109">Only organization administrators (i.e. users with the ORGADMIN role) can call this SQL function.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551164">SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER¶

Enables replication and failover features for a specified account in an organization.

Once an organization administrator (a user with the ORGADMIN role) has called this function, the following features are enabled for the account:

Replication

Client Redirect</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/organizations-manage-accounts-rename" ADD_DATE="1723551020" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Forganizations-manage-accounts-rename" DATA-IMPORTANT="false">Renaming an account | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723551020">An organization administrator (i.e. a user granted the ORGADMIN role) can rename an account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551047">When an account is renamed, Snowflake creates a new account URL that is used to access the account. During the renaming, the administrator can accept the default to save the original account URL so users can continue to use it, or they can delete the original URL to force users to use the new URL. Saved URLs can be deleted at a later time. You cannot save the original URL for a reader account.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions" ADD_DATE="1723550618" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-clustering-micropartitions" DATA-IMPORTANT="false">Micro-partitions &amp; Data Clustering | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723550618">In other words, the closer the ratio of scanned micro-partitions and columnar data is to the ratio of actual data selected, the more efficient is the pruning performed on the table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723550872">Columns are also compressed individually within micro-partitions. Snowflake automatically determines the most efficient compression algorithm for the columns in each micro-partition.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551406">All data in Snowflake tables is automatically divided into micro-partitions, which are contiguous units of storage. Each micro-partition contains between 50 MB and 500 MB of uncompressed data (note that the actual size in Snowflake is smaller because data is always stored compressed). Groups of rows in tables are mapped into individual micro-partitions, organized in a columnar fashion.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-materialized#deciding-when-to-create-a-materialized-view" ADD_DATE="1723550358" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-materialized%23deciding-when-to-create-a-materialized-view" DATA-IMPORTANT="false">Working with Materialized Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723550358">Materialized views are particularly useful when:

Query results contain a small number of rows and/or columns relative to the base table (the table on which the view is defined).

Query results contain results that require significant processing, including:

Analysis of semi-structured data.

Aggregates that take a long time to calculate.

The query is on an external table, which might have slower performance compared to querying native database tables or Iceberg tables.

The view’s base table does not change frequently.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/data-types-semistructured" ADD_DATE="1723550268" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fdata-types-semistructured" DATA-IMPORTANT="false">Semi-structured data types | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723550268">VARIANT (can contain a value of any other data type).

OBJECT (can directly contain a VARIANT value, and thus indirectly contain a value of any other data type, including itself).

ARRAY (can directly contain a VARIANT value, and thus indirectly contain a value of any other data type, including itself).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723557737">A VARIANT value can have a maximum size of up to 16 MB of uncompressed data.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/revoke-role" ADD_DATE="1723539809" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Frevoke-role" DATA-IMPORTANT="false">REVOKE ROLE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539809">REVOKE ROLE¶

Removes a role from another role or a user.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/show-grants" ADD_DATE="1723539701" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fshow-grants" DATA-IMPORTANT="false">SHOW GRANTS | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539701">SHOW
 GRANTS

Syntactically equivalent to SHOW
 GRANTS
 TO
 USER
 current_user
. Lists all the roles granted to the current user.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539717">ROLE
 role_name

Lists all privileges and roles granted to the role. If the role has a grant on a temporary object, then the grant only exists in the session that the temporary object was created.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637000">SHOW GRANTS OF...</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637004">ROLE role_name

Lists all users and roles to which the role has been granted.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637012">SHOW GRANTS TO ...</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-editions" ADD_DATE="1723539668" LAST_MODIFIED="1730207909" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-editions" DATA-IMPORTANT="false">Snowflake Editions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539668">Row-level Security
 to apply row access policies to determine which rows are visible in a query result.
		

✔

	

✔

	

✔</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723558214">Extended Time Travel (up to 90 days).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561925">Dedicated metadata store and pool of compute resources (used in virtual warehouses).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561955">Network policies for limiting/controlling site access by user IP address.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561962">Column-level Security to apply masking policies to columns in tables or views.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561974">Customer-managed encryption keys through Tri-Secret Secure.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561987">Support for private connectivity to Snowflake internal stages using AWS PrivateLink and Azure Private Link.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723561995">Support for private connectivity to the Snowflake service using AWS PrivateLink, Azure Private Link, or Google Cloud Private Service Connect.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723562006">Multi-cluster virtual warehouses for scaling compute resources to meet concurrency needs.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723624758">Audit the user access history through the Account Usage ACCESS_HISTORY view.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704977">By default, VPS does not permit data sharing outside of the VPS.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704984">Snowflake Marketplace and Listings, where providers and consumers meet to share data securely.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793168">Failover and failback between Snowflake accounts for business continuity and disaster recovery.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723793179">Database and share replication between Snowflake accounts (within an organization) to keep database and share objects and stored data synchronized.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723796328">Periodic rekeying of encrypted data for increased protection.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723798142">Support for classifying potentially sensitive data using classification.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980109">Object Tagging to apply tags to Snowflake objects to facilitate tracking sensitive data and resource usage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980207">Query acceleration for parallel processing portions of eligible queries.

		

✔

	

✔

	

✔




Search optimization for point lookup queries, with automatic maintenance.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980214">Materialized views, with automatic maintenance of results.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980269">Snowflake Connector for Kafka for loading data from Apache Kafka topics.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980272">Snowpipe Streaming for low-latency loading of streaming data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980277">Snowpipe for continuous micro-batch loading.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980285">Bulk unloading to delimited flat files and JSON files.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980288">Bulk loading from delimited flat files (CSV, TSV, etc.) and semi-structured data files (JSON, Avro, ORC, Parquet, and XML).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980355">As a provider, create and share a Snowflake Data Clean Room.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723980358">As a consumer, install and use a Snowflake Data Clean Room.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/functions/pipe_usage_history" ADD_DATE="1723539629" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ffunctions%2Fpipe_usage_history" DATA-IMPORTANT="false">PIPE_USAGE_HISTORY | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539629">This function returns pipe activity within the last 14 days.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539635">PIPE_USAGE_HISTORY</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-overview" ADD_DATE="1723539613" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-overview" DATA-IMPORTANT="false">Overview of data unloading | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539613">Partitioned data unloading¶

The COPY INTO &lt;location&gt;
 command includes a PARTITION BY copy option for partitioned unloading of data to stages.

The ability to partition data during the unload operation enables a variety of use cases, such as using Snowflake to transform data for output to a data lake. In addition, partitioning unloaded data into a directory structure in cloud storage can increase the efficiency with which third-party tools consume the data.

The PARTITION BY copy option accepts an expression by which the unload operation partitions table rows into separate files unloaded to the specified stage.</mark>
		<DT><A HREF="https://docs.snowflake.com/user-guide/security-encryption-manage" ADD_DATE="1723539572" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fuser-guide%2Fsecurity-encryption-manage" DATA-IMPORTANT="false">Understanding Encryption Key Management in Snowflake | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539572">All Snowflake customer data is encrypted by default using the latest security standards and best practices. Snowflake uses strong AES 256-bit encryption with a hierarchical key model rooted in a hardware security module.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/list" ADD_DATE="1723539534" LAST_MODIFIED="1730207914" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Flist" DATA-IMPORTANT="false">LIST | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539534">Returns a list of files that have been staged</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539544">Use the abbreviated form of the command to list all the files in the stage for the current user:

LS
 @~;</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-prepare" ADD_DATE="1723539518" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-prepare" DATA-IMPORTANT="false">Preparing to load data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539518">Structured/Semi-structured

	

Type

	

Notes




Structured

	

Delimited (CSV, TSV, etc.)

	

Any valid singlebyte delimiter is supported; default is comma (i.e. CSV).




Semi-structured

	

JSON

	
	

Avro

	

Includes automatic detection and processing of compressed Avro files.


	

ORC

	

Includes automatic detection and processing of compressed ORC files.


	

Parquet

	

Includes automatic detection and processing of compressed Parquet files. .
 .
 Currently, Snowflake supports the schema of Parquet files produced using the Parquet writer v1. Files produced using v2 of the writer are not supported.


	

XML

	

Supported as a preview
 feature.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/transactions" ADD_DATE="1723539400" LAST_MODIFIED="1730207917" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Ftransactions" DATA-IMPORTANT="false">Transactions | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539400">A transaction is a sequence of SQL statements that are committed or rolled back as a unit.

Introduction</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723640039">Aborting transactions¶

If a transaction is running in a session and the session disconnects abruptly, preventing the transaction from committing or rolling back, the transaction is left in a detached state, including any locks that the transaction is holding on resources. If this happens, you might need to abort the transaction.

To abort a running transaction, the user who started the transaction or an account administrator can call the system function, SYSTEM$ABORT_TRANSACTION.

If the transaction is not aborted by the user:

And it blocks another transaction from acquiring a lock on the same table and is idle for 5 minutes, it is automatically aborted and rolled back.

And it does not block other transactions from modifying the same table and is older than 4 hours, it is automatically aborted and rolled back.

And it reads from or writes to hybrid tables, and is idle for 5 minutes, it is automatically aborted and rolled back, regardless of whether it blocks other transactions from modifying the same table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723705460">A transaction can be ended explicitly by executing COMMIT or ROLLBACK. Snowflake supports the synonym COMMIT WORK for COMMIT, and the synonym ROLLBACK WORK for ROLLBACK.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724097244">Transactions are never nested.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724097249">A transaction is associated with a single session.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724097287">A transaction can be started explicitly by executing a BEGIN statement.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-security-integration" ADD_DATE="1723539357" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fadmin-security-fed-auth-security-integration" DATA-IMPORTANT="false">Configuring Snowflake to use federated authentication | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539357">Snowflake uses a SAML2 security integration to integrate with the IdP you are using to implement federated authentication. Use the CREATE SECURITY INTEGRATION
 command to start configuring Snowflake for SSO.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-persisted-results" ADD_DATE="1723539330" LAST_MODIFIED="1730207923" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-persisted-results" DATA-IMPORTANT="false">Using Persisted Query Results | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539330">For persisted query results of all sizes, the cache expires after 24 hours.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539340">Each time the persisted result for a query is reused, Snowflake resets the 24-hour retention period for the result, up to a maximum of 31 days from the date and time that the query was first executed. After 31 days, the result is purged and the next time the query is submitted, a new result is generated and persisted.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635704">By default, result reuse is enabled, but can be overridden at the account, user, and session level using the USE_CACHED_RESULT session parameter.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/snowsql-use" ADD_DATE="1723539310" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsnowsql-use" DATA-IMPORTANT="false">Using SnowSQL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539310">Exporting data¶

Output query results to a file in a defined format using the following configuration options
:

output_format=
output_format

output_file=
output_filename</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723638580">To execute a SQL script while connecting to Snowflake, use the -f &lt;input_filename&gt; connection parameter.

An output file for the script can be specified using -o output_file=&lt;output_filename&gt;. In addition, you can use -o quiet=true to turn off the standard output and -o friendly=false to turn off the startup and exit messages.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/developer-guide/snowpark/index" ADD_DATE="1723539285" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fdeveloper-guide%2Fsnowpark%2Findex" DATA-IMPORTANT="false">Snowpark API | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539285">In comparison to using the Snowflake Connector for Spark
, developing with Snowpark includes the following benefits:

Support for interacting with data within Snowflake using libraries and patterns purpose built for different languages without compromising on performance or functionality.

Support for authoring Snowpark code using local tools such as Jupyter, VS Code, or IntelliJ.

Support for pushdown for all operations, including Snowflake UDFs. This means Snowpark pushes down all data transformation and heavy lifting to the Snowflake data cloud, enabling you to efficiently work with data of any size.

No requirement for a separate cluster outside of Snowflake for computations. All of the computations are done within Snowflake. Scale and compute management are handled by Snowflake.</mark>
		<DD><mark COLOR="green" ADD_DATE="1723635769">Snowflake currently provides Snowpark libraries for three languages: Java, Python, and Scala.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/intro-key-concepts" ADD_DATE="1723539249" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fintro-key-concepts" DATA-IMPORTANT="false">Key Concepts &amp; Architecture | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539249">When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539262">Services managed in this layer include:

Authentication

Infrastructure management

Metadata management

Query parsing and optimization

Access control</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551076">Snowflake’s unique architecture consists of three key layers:

Database Storage

Query Processing

Cloud Services</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723557469">Each virtual warehouse is an MPP compute cluster composed of multiple compute nodes allocated by Snowflake from a cloud provider.

Each virtual warehouse is an independent compute cluster that does not share compute resources with other virtual warehouses. As a result, each virtual warehouse has no impact on the performance of other virtual warehouses.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-unload-s3" ADD_DATE="1723539211" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-unload-s3" DATA-IMPORTANT="false">Unloading into Amazon S3 | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539211">Snowflake requires the following permissions on an S3 bucket and folder to create new files in the folder (and any sub-folders):

s3:DeleteObject

s3:PutObject</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/put" ADD_DATE="1723539149" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fput" DATA-IMPORTANT="false">PUT | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539149">The command cannot be executed from the Worksheets
page in either Snowflake web interface; instead, use the SnowSQL client
 or Drivers
 to upload data files, or check the documentation for a specific Snowflake client to verify support for this command.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539163">OVERWRITE = TRUE | FALSE

Specifies whether Snowflake overwrites an existing file with the same name during upload:

TRUE: An existing file with the same name is overwritten.

FALSE: An existing file with the same name is not overwritten.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723703732">All files stored on internal stages for data loading and unloading operations are automatically encrypted using AES-256 strong encryption on the server side. By default, Snowflake provides additional client-side encryption with a 128-bit key (with the option to configure a 256-bit key).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/cost-understanding-compute" ADD_DATE="1723539118" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fcost-understanding-compute" DATA-IMPORTANT="false">Understanding compute cost | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539118">The credit numbers shown above are for a full hour of usage; however, credits are billed per-second, with a 60-second (i.e. 1-minute) minimum:</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-query-profile" ADD_DATE="1723539018" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-query-profile" DATA-IMPORTANT="false">Analyzing Queries Using Query Profile | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723539028">A collapsible panel in the operator tree pane lists nodes by execution time in descending order, enabling users to quickly locate the costliest operator nodes in terms of execution time. The panel lists all nodes that lasted for 1% or longer of the total execution time of the query (or the execution time for the displayed query step, if the query was executed in multiple processing steps).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539050">Metadata Operators¶

Some queries include steps that are pure metadata/catalog operations rather than data-processing operations. These steps consist of a single operator. Some examples include:

DDL and Transaction Commands:

Used for creating or modifying objects, session, transactions, etc. Typically, these queries are not processed by a virtual warehouse and result in a single-step profile that corresponds to the matching SQL statement. For example:

CREATE DATABASE | SCHEMA | …

ALTER DATABASE | SCHEMA | TABLE | SESSION | …

DROP DATABASE | SCHEMA | TABLE | …

COMMIT

Table Creation Command:

DDL command for creating a table. For example:

CREATE TABLE

Similar to other DDL commands, these queries result in a single-step profile; however, they can also be part of a multi-step profile, such as when used in a CTAS statement. For example:

CREATE TABLE … AS SELECT …

Query Result Reuse:

A query that reuses the result of a previous query.

Metadata-based Result:

A query whose result is computed based purely on metadata, without accessing any data. These queries are not processed by a virtual warehouse. For example:

SELECT COUNT(*) FROM …

SELECT CURRENT_DATABASE()</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539059">Execution Time¶

Execution time provides information about “where the time was spent” during the processing of a query. Time spent can be broken down into the following categories, displayed in the following order:

Processing
 — time spent on data processing by the CPU.

Local Disk IO
 — time when the processing was blocked by local disk access.

Remote Disk IO
 — time when the processing was blocked by remote disk access.

Network Communication
 — time when the processing was waiting for the network data transfer.

Synchronization
 — various synchronization activities between participating processes.

Initialization
 — time spent setting up the query processing.</mark>
		<DD><mark COLOR="green" ADD_DATE="1723539075">Total invocations
 — number of times that an external function was called. (This can be different from the number of external function calls in the text of the SQL statement due to the number of batches that rows are divided into, the number of retries (if there are transient network problems), etc.)</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539085">For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling
 the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.

This spilling can have a profound effect on query performance (especially if remote disk is used for spilling). To alleviate this, we recommend:

Using a larger warehouse (effectively increasing the available memory/local disk space for the operation), and/or

Processing data in smaller batches.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539094">Snowflake collects rich statistics on data allowing it not to read unnecessary parts of a table based on the query filters. However, for this to have an effect, the data storage order needs to be correlated with the query filter attributes.

The efficiency of pruning can be observed by comparing Partitions scanned
 and Partitions total
 statistics in the TableScan
 operators. If the former is a small fraction of the latter, pruning is efficient. If not, the pruning did not have an effect.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723539178">Query Profile, available through the Classic Console, provides execution details for a query. For the selected query, it provides a graphical representation of the main components of the processing plan for the query, with statistics for each component, along with details and statistics for the overall query.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551454">Common Query Problems Identified by Query Profile¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551459">“Exploding” Joins</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551464">UNION Without ALL¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551468">Queries Too Large to Fit in Memory</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551472">Inefficient Pruning¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551625">Spilling — information about disk usage for operations where intermediate results do not fit in memory:

Bytes spilled to local storage — volume of data spilled to local disk.

Bytes spilled to remote storage — volume of data spilled to remote disk.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723797853">TableScan:

Represents access to a single table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/undrop" ADD_DATE="1723538986" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fundrop" DATA-IMPORTANT="false">UNDROP object | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538986">Organization Objects:

UNDROP ACCOUNT

Account Objects:

UNDROP DATABASE

Database Objects:

UNDROP DYNAMIC TABLE

UNDROP EXTERNAL VOLUME

UNDROP ICEBERG TABLE

UNDROP SCHEMA

UNDROP TABLE

UNDROP TAG</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses" ADD_DATE="1723538932" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses" DATA-IMPORTANT="false">Virtual warehouses | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538932">A virtual warehouse, often referred to simply as a “warehouse”, is a cluster of compute resources in Snowflake. A virtual warehouse is available in two types:

Standard

Snowpark-optimized</mark>
		<DD><mark COLOR="green" ADD_DATE="1723538948">A warehouse provides the required resources, such as CPU, memory, and temporary storage, to perform the following operations in a Snowflake session:

Executing SQL SELECT
 statements that require compute resources (e.g. retrieving rows from tables and views).

Performing DML operations, such as:

Updating rows in tables (DELETE
 , INSERT
 , UPDATE
).

Loading data into tables (COPY INTO &lt;table&gt;
).

Unloading data from tables (COPY INTO &lt;location&gt;
).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-overview" ADD_DATE="1723538819" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-overview" DATA-IMPORTANT="false">Overview of warehouses | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538819">Warehouses can be started and stopped at any time. They can also be resized at any time, even while running, to accommodate the need for more or less compute resources, based on the type of operations being performed by the warehouse.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538834">Default size for warehouses created in Snowsight and using CREATE WAREHOUSE
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538840">X-Small</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538854">X-Large</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538863">Default size for warehouses created using the Classic Console.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538883">The additional resources do not impact any queries that are already running, but once they are fully provisioned they become available for use by any queries that are queued or newly submitted.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538906">SnowSQL supports both a configuration file and command line option for specifying a default warehouse.

The drivers and connectors support specifying a default warehouse as a connection parameter when initiating a session.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552307">Auto-suspension and auto-resumption¶

A warehouse can be set to automatically resume or suspend, based on activity:

By default, auto-suspend is enabled. Snowflake automatically suspends the warehouse if it is inactive for the specified period of time.

By default, auto-resume is enabled. Snowflake automatically resumes the warehouse when any statement that requires a warehouse is submitted and the warehouse is the current warehouse for the session.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552319">Auto-suspend and auto-resume apply only to the entire warehouse and not to the individual clusters in the warehouse.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723920396">Snowflake provides some object-level parameters that can be set to help control query processing and concurrency:

STATEMENT_QUEUED_TIMEOUT_IN_SECONDS

STATEMENT_TIMEOUT_IN_SECONDS</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-multicluster" ADD_DATE="1723538731" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-multicluster" DATA-IMPORTANT="false">Multi-cluster warehouses | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538731">Auto-scale:

This mode is enabled by specifying different
 values for maximum and minimum number of clusters.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538737">You can choose to run a multi-cluster warehouse in either of the following modes:

Maximized:

This mode is enabled by specifying the same
 value for both maximum and minimum number of clusters (note that the specified value must be larger than 1). In this mode, when the warehouse is started, Snowflake starts all the clusters so that maximum resources are available while the warehouse is running.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538755">Snowflake supports the following scaling policies:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538758">Standard (default)</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538762">After 2 to 3 consecutive successful checks (performed at 1 minute intervals), which determine whether the load on the least-loaded cluster could be redistributed to the other clusters without spinning up the cluster again.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538765">Economy</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538768">After 5 to 6 consecutive successful checks (performed at 1 minute intervals), which determine whether the load on the least-loaded cluster could be redistributed to the other clusters without spinning up the cluster again.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723550988">Multi-cluster warehouses are best utilized for scaling resources to improve concurrency for users/queries. They are not as beneficial for improving the performance of slow-running queries or data loading. For these types of operations, resizing the warehouse provides more benefits.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723552262">Multi-cluster warehouses enable you to scale compute resources to manage your user and query concurrency needs as they change, such as during peak and off hours.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635531">Only if the system estimates there’s enough query load to keep the cluster busy for at least 6 minutes.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635536">The first cluster starts immediately when either a query is queued or the system detects that there’s one more query than the currently-running clusters can execute.

Each successive cluster waits to start 20 seconds after the prior one has started. For example, if your warehouse is configured with 10 max clusters, it can take a full 200+ seconds to start all 10 clusters.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-considerations" ADD_DATE="1723538658" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-considerations" DATA-IMPORTANT="false">Warehouse considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538658">The overall size of the tables being queried has more impact than the number of rows.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538665">the larger the warehouse and, therefore, more compute resources in the warehouse, the larger the cache).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538674">This cache is dropped when the warehouse is suspended, which may result in slower initial performance for some queries after the warehouse is resumed.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538684">Decreasing the size of a running warehouse removes compute resources from the warehouse. When the computer resources are removed, the cache associated with those resources is dropped, which can impact performance in the same way that suspending the warehouse can impact performance after it is resumed.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-tasks" ADD_DATE="1723538620" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-tasks" DATA-IMPORTANT="false">Working with warehouses | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538620">Credits are billed on a per-second basis while the warehouse is running, with a 1-minute minimum each time the warehouse is resumed; however, credit consumption is reported in 60-minute (i.e. hourly) increments.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538628">Compute resources waiting to shut down are considered to be in “quiesce” mode.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538636">To verify the additional compute resources for your warehouse have been fully provisioned, add the WAIT_FOR_COMPLETION
 parameter to the ALTER WAREHOUSE
 command. You can also use SHOW WAREHOUSES
 to check its state
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635165">Compute resources are removed from a warehouse only when they are no longer being used to execute any current statements.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635171">Resizing a warehouse doesn’t have any impact on statements that are currently being executed by the warehouse. When resizing to a larger size, the new compute resources, once fully provisioned, are used only to execute statements that are already in the warehouse queue, as well as all future statements submitted to the warehouse.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704007">Resizing a suspended warehouse does not provision any new compute resources for the warehouse. It simply instructs Snowflake to provision the additional compute resources when the warehouse is next resumed, at which time all the usage and credit rules associated with starting a warehouse apply.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723707046">Snowflake does not begin executing SQL statements submitted to a warehouse until all of the compute resources for the warehouse are successfully provisioned, unless any of the resources fail to provision</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723707055">If any of the compute resources for the warehouse fail to provision during start-up, Snowflake attempts to repair the failed resources.

During the repair process, the warehouse starts processing SQL statements once 50% or more of the requested compute resources are successfully provisioned.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring" ADD_DATE="1723538536" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-load-monitoring" DATA-IMPORTANT="false">Monitoring warehouse load | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538536">To view the load monitoring chart, you must be using a role that has the MONITOR privilege on the warehouse.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538544">Query load is calculated by dividing the execution time (in seconds) of all queries in an interval by the total time (in seconds) for the interval.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized" ADD_DATE="1723538520" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fwarehouses-snowpark-optimized" DATA-IMPORTANT="false">Snowpark-optimized warehouses | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538520">Changing the warehouse type using the ALTER WAREHOUSE command is only supported for a warehouse in the SUSPENDED
 state. T</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/performance-query-warehouse-max-concurrency" ADD_DATE="1723538504" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fperformance-query-warehouse-max-concurrency" DATA-IMPORTANT="false">Limiting concurrently running queries | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538504">You can use the MAX_CONCURRENCY_LEVEL
 parameter to limit the number of concurrent queries running in a warehouse.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/create-warehouse" ADD_DATE="1723538433" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fcreate-warehouse" DATA-IMPORTANT="false">CREATE WAREHOUSE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538433">AUTO_SUSPEND
 =
 {
 &lt;num&gt;
 |
 NULL
 }
 AUTO_RESUME
 =
 {
 TRUE
 |
 FALSE
 }
 INITIALLY_SUSPENDED
 =
 {
 TRUE
 |
 FALSE
 }</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538447">Creating a virtual warehouse automatically sets it as the warehouse in use for the current session (equivalent to using the USE WAREHOUSE
 command for the warehouse).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538455">Snowpark-optimized warehouses are not supported on XSMALL
, SMALL
, X5LARGE
, or X6LARGE
 warehouse sizes.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse" ADD_DATE="1723538403" LAST_MODIFIED="1730207926" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Falter-warehouse" DATA-IMPORTANT="false">ALTER WAREHOUSE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538403">The granting of the global MANAGE WAREHOUSES privilege is equivalent to granting the MODIFY, MONITOR, and OPERATE privileges on all warehouses in an account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723796453">When resizing a warehouse, you can use this parameter to block the return of the ALTER WAREHOUSE command until the resize has finished provisioning all its compute resources. Blocking the return of the command when resizing to a larger warehouse serves to notify you that your compute resources have been fully provisioned and the warehouse is now ready to execute queries using all the new resources.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/drop-warehouse" ADD_DATE="1723538375" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fdrop-warehouse" DATA-IMPORTANT="false">DROP WAREHOUSE | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538375">Dropped warehouses cannot be recovered; they must be recreated.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538382">To prevent in-progress queries from being aborted for a dropped warehouse (i.e. you wish the queries to be completed):

First suspend the warehouse.

After all the queries have completed, drop the warehouse.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/unstructured-intro" ADD_DATE="1723538341" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Funstructured-intro" DATA-IMPORTANT="false">Introduction to unstructured data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538341">The following types of URLs are available to access files in cloud storage:

Scoped URL:

Encoded URL that permits temporary access to a staged file without granting privileges to the stage.

The URL expires when the persisted query result period
 ends (i.e. the results cache expires), which is currently 24 hours.

File URL:

URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files.

Pre-signed URL:

Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538350">Used to download or access files without authenticating into Snowflake or passing an authorization token.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538357">Note

You cannot change the encryption type for an internal stage after you create the stage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723636685">Permanent URL to a file on a stage. To download or access a file, users send the file URL in a GET request to the REST API endpoint along with the authorization token. Ideal for custom applications that require access to unstructured data file</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-external-intro" ADD_DATE="1723538223" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-external-intro" DATA-IMPORTANT="false">Introduction to external tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538223">External tables are read-only. You cannot perform data manipulation language (DML) operations on them. However, you can use external tables for query and join operations. You can also create views against external tables.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538230">If Snowflake encounters an error while scanning a file in cloud storage during a query operation, the file is skipped and scanning continues on the next file. A query can partially scan a file and return the rows scanned before the error was encountered.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538243">All external tables include the following columns:

VALUE:

A VARIANT type column that represents a single row in the external file.

METADATA$FILENAME:

A pseudocolumn that identifies the name of each staged data file included in the external table, including its path in the stage.

METADATA$FILE_ROW_NUMBER:

A pseudocolumn that shows the row number for each record in a staged data file.</mark>
		<DD><mark COLOR="green" ADD_DATE="1723538255">Parquet files

	

256 - 512 MB</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538263">For optimal performance when querying large data files, create and query materialized views over external tables
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538269">Parquet row groups

	

16 - 256 MB

	

Note that when Parquet files include multiple row groups, Snowflake can operate on each row group in a different server. For improved query performance, we recommend sizing Parquet files in the recommended range; or, if large file sizes are necessary, including multiple row groups in each file.




All other supported file formats</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538278">Partition columns are defined when an external table is created, using the CREATE EXTERNAL TABLE … PARTITION BY syntax. After an external table is created, the method by which partitions are added cannot be changed.</mark>
		<DD><mark COLOR="green" ADD_DATE="1723559742">To optimize the number of parallel scanning operations when querying external tables, we recommend the following file or row group sizes per format:</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/search-optimization-service" ADD_DATE="1723538204" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsearch-optimization-service" DATA-IMPORTANT="false">Search Optimization Service | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538204">The search optimization service aims to significantly improve the performance of certain types of queries on tables, including:

Selective point lookup queries on tables. A point lookup query returns only one or a small number of distinct rows. Use case examples include:

Business users who need fast response times for critical dashboards with highly selective filters.

Data scientists who are exploring large data volumes and looking for specific subsets of data.

Data applications retrieving a small set of results based on an extensive set of filtering predicates.

For more information, see Speeding up point lookup queries with search optimization
.

Substring and regular expression searches (e.g. [ NOT ] LIKE
, [ NOT ] ILIKE
, [ NOT ] RLIKE
, etc.). For more information, see Speeding up substring and regular expression queries with search optimization
.

Queries on fields in VARIANT, OBJECT, and ARRAY
 (semi-structured) columns that use the following types of predicates:

Equality predicates.

IN predicates.

Predicates that use ARRAY_CONTAINS
.

Predicates that use ARRAYS_OVERLAP
.

Substring and regular expression predicates.

Predicates that check for NULL values.

For more information, see Speeding up queries of semi-structured data with search optimization
.

Queries that use selected geospatial functions with GEOGRAPHY
 values. For more information, see Speeding up geospatial queries with search optimization
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724098097">To improve performance of search queries, the search optimization service creates and maintains a persistent data structure called a search access path.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1724098111">The search access path keeps track of which values of the table’s columns might be found in each of its micro-partitions, allowing some micro-partitions to be skipped when scanning the table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-introduction" ADD_DATE="1723538172" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-introduction" DATA-IMPORTANT="false">Overview of Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538172">If the schema is not specified, then Snowflake assumes that the table is in the same schema as the view
. (If the table were assumed to be in the active schema, then the view could refer to different tables at different times.)</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-secure" ADD_DATE="1723538150" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-secure" DATA-IMPORTANT="false">Working with Secure Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723538150">When using secure views with Secure Data Sharing
, use the CURRENT_ACCOUNT
 function to authorize users from a specific account to access rows in a base table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635994">Why Should I Use Secure Views?¶

For a non-secure view, internal optimizations can indirectly expose data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723635998">Secure views do not utilize these optimizations, ensuring that users have no access to the underlying data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723636015">With secure views, the view definition and details are visible only to authorized users (i.e. users who are granted the role that owns the view).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/views-materialized" ADD_DATE="1723537983" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fviews-materialized" DATA-IMPORTANT="false">Working with Materialized Views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537983">Materialized views are particularly useful when:

Query results contain a small number of rows and/or columns relative to the base table (the table on which the view is defined).

Query results contain results that require significant processing, including:

Analysis of semi-structured data.

Aggregates that take a long time to calculate.

The query is on an external table
, which might have slower performance compared to querying native database tables or Iceberg tables
.

The view’s base table does not change frequently.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537991">If a query is run before the materialized view is up-to-date, Snowflake either updates the materialized view or uses the up-to-date portions of the materialized view and retrieves any required newer data from the base table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538005">Materialized views are faster than tables because of their “cache” (i.e. the query results for the view); in addition, if data has changed, they can use their “cache” for data that hasn’t changed and use the base table for any data that has changed.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538041">Performance Benefits

	

Security Benefits

	

Simplifies Query Logic

	

Supports Clustering

	

Uses Storage

	

Uses Credits for Maintenance

	

Notes




Regular table

				

✔

	

✔

		


Regular view

		

✔

	

✔

				


Cached query result

	

✔

						

Used only if data has not changed and if query only uses deterministic functions (e.g. not CURRENT_DATE).




Materialized view

	

✔

	

✔

	

✔

	

✔

	

✔

	

✔

	

Storage and maintenance requirements typically result in increased costs
.




External table

							

Data is maintained outside Snowflake and, therefore, does not incur any storage charges within Snowflake.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538050">As with non-materialized views, a materialized view does not automatically inherit the privileges of its base table. You should explicitly grant privileges on the materialized view to the roles that should use that view.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538069">The following limitations apply to creating materialized views:

A materialized view can query only a single table.

Joins, including self-joins, are not supported.

A materialized view cannot query:

A materialized view.

A non-materialized view.

A UDTF (user-defined table function).

A materialized view cannot include:

UDFs (this limitation applies to all types of user-defined functions, including external functions).

Window functions.

HAVING clauses.

ORDER BY clause.

LIMIT clause.

GROUP BY keys that are not within the SELECT list. All GROUP BY keys in a materialized view must be part of the SELECT list.

GROUP BY GROUPING SETS.

GROUP BY ROLLUP.

GROUP BY CUBE.

Nesting of subqueries within a materialized view.

The MINUS, EXCEPT, or INTERSECT set operators
.

Many aggregate functions are not allowed in a materialized view definition.

The aggregate functions that are supported
 in materialized views are:

APPROX_COUNT_DISTINCT (HLL)
.

AVG
 (except when used in PIVOT
).

BITAND_AGG
.

BITOR_AGG
.

BITXOR_AGG
.

COUNT
.

COUNT_IF
.

MAX
.

MIN
.

STDDEV, STDDEV_SAMP
.

STDDEV_POP
.

SUM
.

VARIANCE (VARIANCE_SAMP, VAR_SAMP)
.

VARIANCE_POP (VAR_POP)
.

The other aggregate functions are not supported
 in materialized views.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538077">Functions used in a materialized view must be deterministic. For example, using CURRENT_TIME
 or CURRENT_TIMESTAMP
 is not permitted.

A materialized view should not be defined using a function that produces different results for different settings of parameters, such as the session-level parameter TIMESTAMP_TYPE_MAPPING.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538089">You cannot directly clone a materialized view by using the CREATE
 MATERIALIZED
 VIEW
 ...
 CLONE...
 command. However, if you clone a schema or a database that contains a materialized view, the materialized view will be cloned and included in the new schema or database.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723538102">If columns are added to the base table, those new columns are not
 propagated to the materialized view automatically.

This is true even if the materialized view was defined with SELECT
 *
 (e.g. CREATE MATERIALIZED VIEW AS SELECT * FROM table2 ...).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723551782">A materialized view is a pre-computed data set derived from a query specification (the SELECT in the view definition) and stored for later use. Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/table-considerations" ADD_DATE="1723537951" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftable-considerations" DATA-IMPORTANT="false">Table Design Considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537951">For better pruning and less storage consumption, Snowflake recommends flattening your object and key data into separate relational columns if your semi-structured data includes:

Dates and timestamps, especially non-ISO 8601 dates and timestamps, as string values

Numbers within strings

Arrays</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537957">Currently, it is not possible to change a permanent table to a transient
 table using the ALTER TABLE
 command. The TRANSIENT property is set at table creation and cannot be modified.

Similarly, it is not possible to directly change a transient table to a permanent table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/object-clone" ADD_DATE="1723537830" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fobject-clone" DATA-IMPORTANT="false">Cloning considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537830">If the source object is a database or schema, the clone inherits all
 granted privileges on the clones of all child objects contained in the source object:

For databases, contained objects include schemas, tables, views, etc.

For schemas, contained objects include tables, views, etc.

Note that the clone of the container itself (database or schema) does not inherit the privileges granted on the source container.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537842">In a table, a column can reference a sequence that generates default values. When a table is cloned, the cloned table references the source or cloned sequence:

If the database or schema containing both the table and sequence is cloned, the cloned table references the cloned sequence.

Otherwise, the cloned table references the source sequence.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537852">By default, Automatic Clustering
 is suspended for the new table. To resume automatic clustering for the new table, run the following command:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537860">Individual external named stages can be cloned.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537866">Internal (i.e. Snowflake) named stages cannot
 be cloned.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537875">When a database or schema is cloned, any pipes in the source container that reference an internal (i.e. Snowflake) stage are not
 cloned.

However, any pipes that reference an external stage are cloned. This includes any pipe objects where the INTEGRATION parameter is set.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537882">If a table is fully qualified in the COPY statement in the pipe definition (in the form of db_name
.
schema_name
.
table_name
 or schema_name
.
table_name
), then Snowpipe loads duplicate data into the source table (i.e. the database
.
schema
.
table
 in the COPY statement) for each pipe.

If a table is not
 fully qualified in the pipe definition, then Snowpipe loads the data into the table (e.g. mytable
) in the source and cloned databases/schemas.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537889">When a database or schema that contains tasks is cloned, the tasks in the clone are suspended by default.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537897">When a database or schema that contains alerts is cloned, the alerts in the clone are suspended
 by default.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537906">Cloning an individual policy object is not supported.

Cloning a schema results in the cloning of all policies within the schema.

A cloned table maps to the same policies as the source table. In other words, if a policy is set on the base table or its columns, the policy is attached to the cloned table or its columns.

When a table is cloned in the context of its parent schema cloning, if the source table has a reference to a policy in the same parent schema (i.e. a local reference), the cloned table will have a reference to the cloned policy.

If the source table refers to a policy in a different schema (i.e. a foreign reference), then the cloned table retains the foreign reference.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537914">Cloning is fast, but not instantaneous, particularly for large objects (e.g. tables). As such, if DDL statements are executed on source objects (e.g. renaming tables in a schema) while the cloning operation is in progress, the changes may not be represented in the clone. This is because DDL statements are atomic and not part of multi-statement transactions.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537924">In the following example, a CREATE TABLE … CLONE statement attempts to clone the source table at a point in the past (30 minutes prior) when it didn’t exist:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537932">For example, the data retention period
 for database db1
 is seven days and the data retention period for table t1
 in db1
 is one day. If you clone db1
 using Time Travel at a point 12 hours in the past, the cloning operation successfully creates a clone of db1
 and it contains the cloned table t1
.

However, if you try to clone db1
 at a point two days in the past, the historical data for table t1
 at that point is no longer available in Time Travel and the cloning operation fails.

As a workaround, use the IGNORE TABLES WITH INSUFFICIENT DATA RETENTION
 parameter of the CREATE &lt;object&gt; … CLONE
 command to clone a database or schema. The parameter skips tables that no longer have historical data available in Time Travel at the time specified for the cloning operation.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723550804">If the source object is a database or schema, the clone inherits all granted privileges on the clones of all child objects contained in the source object:

For databases, contained objects include schemas, tables, views, etc.

For schemas, contained objects include tables, views, etc.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tables-storage-considerations" ADD_DATE="1723537741" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftables-storage-considerations" DATA-IMPORTANT="false">Data storage considerations | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537741">Of the three methods, TABLE_STORAGE_METRICS
 provides the most detailed information because it includes a breakdown of the physical storage (in bytes) for table data in the following three states of the CDP life-cycle:

Active (ACTIVE_BYTES column)

Time Travel (TIME_TRAVEL_BYTES column)

Fail-safe (FAILSAFE_BYTES column)</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537755">Every Snowflake table has an ID that uniquely identifies the table. In addition, every table is also associated with a CLONE_GROUP_ID. If a table has no clones, then the ID and CLONE_GROUP_ID are identical. These IDs are displayed in the TABLE_STORAGE_METRICS
 view.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537771">Snowflake temporary tables have no Fail-safe and have a Time Travel retention period of only 0 or 1 day; however, the Time Travel period ends when the table is dropped.

Thus, the maximum total CDP charges incurred for a temporary table are 1 day (or less if the table is explicitly dropped or dropped as a result of terminating the session). During this period, Time Travel can be performed on the table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537782">A Snowflake session is only terminated if the user explicitly terminates the session or the session times out due to inactivity after 4 hours. Disconnecting from Snowflake does not terminate the active sessions.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537790">High-churn dimension tables can be identified by calculating the ratio of FAILSAFE_BYTES divided by ACTIVE_BYTES in the TABLE_STORAGE_METRICS
 view. Any table with a large ratio is considered to be a high-churn table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706138">TABLE_STORAGE_METRICS view (in the Snowflake Information Schema).

TABLE_STORAGE_METRICS view view (in Account Usage).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706141">Any user with the appropriate privileges can view data storage for individual tables. Snowflake provides the following methods for viewing table data storage:</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/data-types-numeric" ADD_DATE="1723537691" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fdata-types-numeric" DATA-IMPORTANT="false">Numeric data types | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537691">NUMBER¶

Numbers up to 38 digits, with an optional precision and scale:

Precision:

Total number of digits allowed.

Scale:

Number of digits allowed to the right of the decimal point.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537703">However, scale (number of digits following the decimal point) does have an impact on storage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537708">Precision (total number of digits) does not impact storage.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-overview" ADD_DATE="1723537659" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-overview" DATA-IMPORTANT="false">Overview of data loading | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537659">A table stage has no grantable privileges of its own. To stage files to a table stage, list the files, query them on the stage, or drop them, you must be the table owner (have the role with the OWNERSHIP privilege on the table).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537669">Snowflake supports transforming data while loading it into a table using the COPY command. Options include:

Column reordering

Column omission

Casts

Truncating text strings that exceed the target column length</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare" ADD_DATE="1723537599" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-considerations-prepare" DATA-IMPORTANT="false">Preparing your data files | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537599">Loading very large files (e.g. 100 GB or larger) is not recommended.

If you must load a large file, carefully consider the ON_ERROR
 copy option value. Aborting or skipping a file due to a small number of errors could result in delays and wasted credits. In addition, if a data loading operation continues beyond the maximum allowed duration of 24 hours, it could be aborted without any portion of the file being committed.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537607">A VARIANT value can have a maximum size of up to 16 MB of uncompressed data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537624">If the data exceeds 16 MB, enable the STRIP_OUTER_ARRAY file format option for the COPY INTO &lt;table&gt;
 command to remove the outer array structure and load the records into separate table rows:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537633">Consider the following guidelines when preparing your delimited text (CSV) files for loading:

UTF-8 is the default character set, however, additional encodings are supported. Use the ENCODING file format option to specify the character set for the data files. For more information, see CREATE FILE FORMAT
.

Fields that contain delimiter characters should be enclosed in quotes (single or double). If the data contains single or double quotes, then those quotes must be escaped.

Carriage returns are commonly introduced on Windows systems in conjunction with a line feed character to mark the end of a line (\r
 \n
). Fields that contain carriage returns should also be enclosed in quotes (single or double).

The number of columns in each row should be consistent.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537643">If the element was extracted into a column, the engine scans only the extracted column.

If the element was not
 extracted into a column, the engine must scan the entire JSON structure, and then for each row traverse the structure to output values. This impacts performance.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723569088">To optimize the number of parallel operations for a load, we recommend aiming to produce data files roughly 100-250 MB (or larger) in size compressed.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-considerations-load" ADD_DATE="1723537558" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-considerations-load" DATA-IMPORTANT="false">Loading data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537558">Of the three options for identifying/specifying data files to load from a stage, providing a discrete list of files is generally the fastest; however, the FILES parameter supports a maximum of 1,000 files, meaning a COPY command executed with the FILES parameter can only load up to 1,000 files.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537580">Workarounds¶

To load files whose metadata has expired, set the LOAD_UNCERTAIN_FILES copy option to true. The copy option references load metadata, if available, to avoid data duplication, but also attempts to load files with expired load metadata.

Alternatively, set the FORCE option to load all files, ignoring load metadata if it exists. Note that this option reloads files, potentially duplicating data in a table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723569479">Load metadata¶

Snowflake maintains detailed metadata for each table into which data is loaded, including:

Name of each file from which data was loaded

File size

ETag for the file

Number of rows parsed in the file

Timestamp of the last load for the file

Information about any errors encountered in the file during loading

This load metadata expires after 64 days. If the LAST_MODIFIED date for a staged data file is less than or equal to 64 days, the COPY command can determine its load status for a given table and prevent reloading (and data duplication). The LAST_MODIFIED date is the timestamp when the file was initially staged or when it was last modified, whichever is later.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage-ui" ADD_DATE="1723537527" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-local-file-system-stage-ui" DATA-IMPORTANT="false">Staging files using Snowsight | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537527">You can’t upload files onto user stages or table stages using Snowsight.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537540">The maximum file size is 250 MB.

To upload files onto an internal stage, you must use a role that is granted or inherits the USAGE privilege on the database and schema and the WRITE privilege on the stage. For more information, see Stage privileges
.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage" ADD_DATE="1723537472" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-local-file-system-create-stage" DATA-IMPORTANT="false">Choosing an internal stage for local files | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537472">Each user has a Snowflake stage allocated to them by default for storing files.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537484">User stages are referenced using @~
; e.g. use LIST
 @~
 to list the files in a user stage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537490">User stages do not support setting file format options. Instead, you must specify file format and copy options as part of the COPY INTO &lt;table&gt;
 command.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537499">By default, each table has a Snowflake stage allocated to it for storing files.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537507">A table stage has the same name as the table. For example, a table named mytable
 has a stage referenced as @%mytable
.</mark>
		<DD><mark COLOR="green" ADD_DATE="1723568701">By default, each user and table in Snowflake is automatically allocated an internal stage for staging data files to be loaded. In addition, you can create named internal stages.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-local-file-system-copy" ADD_DATE="1723537434" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-local-file-system-copy" DATA-IMPORTANT="false">Copying data from an internal stage | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537434">Note that when copying data from files in a table stage, the FROM clause can be omitted because Snowflake automatically checks for files in the table stage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537444">Named stage¶

The following example loads data from all files from the my_stage
 named stage, which was created in Choosing an internal stage for local files
:

COPY
 INTO
 mytable
 from
 @
my_stage
;



Note that a file format does not need to be specified because it is included in the stage definition.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537452">To validate data in an uploaded file, execute COPY INTO &lt;table&gt;
 in validation mode using the VALIDATION_MODE parameter. The VALIDATION_MODE parameter returns any errors that it encounters in a file. You can then modify the data in the file to ensure it loads without error.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro" ADD_DATE="1723537250" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-snowpipe-intro" DATA-IMPORTANT="false">Snowpipe | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537250">Snowpipe enables loading data from files as soon as they’re available in a stage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537261">Snowpipe loads the new data files into the target table in a continuous, serverless fashion based on the parameters defined in a specified pipe object.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537270">When calling the REST endpoints:
 Requires key pair authentication with JSON Web Token (JWT). JWTs are signed using a public/private key pair with RSA encryption.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723558411">Snowpipe uses file loading metadata associated with each pipe object to prevent reloading the same files (and duplicating data) in a table. This metadata stores the path (i.e. prefix) and name of each loaded file, and prevents loading files with the same name even if they were later modified (i.e. have a different eTag).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723558421">Snowpipe:

Uses Snowflake-supplied compute resources.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723798049">Bulk data load:

Stored in the metadata of the target table for 64 days. Available upon completion of the COPY statement as the statement output.

Snowpipe:

Stored in the metadata of the pipe for 14 days. Must be requested from Snowflake via a REST endpoint, SQL table function, or ACCOUNT_USAGE view.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-snowpipe-rest-apis" ADD_DATE="1723537192" LAST_MODIFIED="1730207929" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-snowpipe-rest-apis" DATA-IMPORTANT="false">Snowpipe REST API | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537192">The Snowpipe API provides REST endpoints for fetching load reports.

Endpoint: insertReport
¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537203">Endpoint: loadHistoryScan¶</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723537221">Endpoint: insertFiles¶</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-snowpipe-manage" ADD_DATE="1723537164" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-snowpipe-manage" DATA-IMPORTANT="false">Managing Snowpipe | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537164">Pipe objects do not support the PURGE copy option.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723558489">The load history for Snowpipe operations is stored in the metadata of the pipe object. When a pipe is recreated, the load history is dropped.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-dirtables" ADD_DATE="1723537132" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-dirtables" DATA-IMPORTANT="false">Directory tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537132">A directory table is an implicit object layered on a stage (not a separate database object) and is conceptually similar to an external table because it stores file-level metadata about the data files in the stage. A directory table has no grantable privileges of its own.

Both external (external cloud storage) and internal (Snowflake) stages support directory tables. You can add a directory table to a stage when you create a stage (using CREATE STAGE
) or later (using ALTER STAGE
).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723703583">Table functions¶
AUTO_REFRESH_REGISTRATION_HISTORY

Retrieve the history of data files registered in the metadata of specified objects and the credits billed for these operations.

STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY

Retrieve information about the metadata history for a directory table, including any errors found when refreshing the metadata.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage" ADD_DATE="1723537105" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-dirtables-manage" DATA-IMPORTANT="false">Managing directory tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537105">Directory tables on internal stages require manual metadata refreshes
. You could also choose to include a directory table on external stages and refresh the metadata manually.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-dirtables-auto" ADD_DATE="1723537085" LAST_MODIFIED="1730207933" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-dirtables-auto" DATA-IMPORTANT="false">Automated directory table metadata refreshes | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537085">Snowflake doesn’t support refreshing the directory table metadata on an internal stage. You must manually refresh the directory table metadata for an internal stage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723705387">You can automatically refresh the metadata for a directory table by using the following event notification services:

Amazon S3: Amazon SQS (Simple Queue Service)

Google Cloud Storage: Google Cloud Pub/Sub

Microsoft Azure: Microsoft Azure Event Grid</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-load-transform" ADD_DATE="1723537051" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-load-transform" DATA-IMPORTANT="false">Transforming data during a load | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723537062">The VALIDATION_MODE parameter does not support COPY statements that transform data during a load.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637948">The COPY command supports:

Column reordering, column omission, and casts using a SELECT statement. There is no requirement for your data files to have the same number and ordering of columns as your target table.

The ENFORCE_LENGTH | TRUNCATECOLUMNS option, which can truncate text strings that exceed the target column length.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-intro" ADD_DATE="1723536997" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-intro" DATA-IMPORTANT="false">Dynamic tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536997">Easy switching: Transition seamlessly from batch to streaming with a single ALTER DYNAMIC TABLE command.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-about" ADD_DATE="1723536962" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-about" DATA-IMPORTANT="false">How dynamic tables work | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536962">Dynamic tables are best used when:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536969">You do need to materialize the results of a query of multiple base tables.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536974">You don’t need to use unsupported dynamic query constructs such as stored procedures
, non-deterministic functions not
 listed in Supported non-deterministic functions in full refresh
, or external functions
, or need to use sources for dynamic tables that are external tables, streams, or materialized views.

Note</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536982">Dynamic tables can be used as the source of a stream.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-refresh" ADD_DATE="1723536916" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-refresh" DATA-IMPORTANT="false">Understanding dynamic table refresh | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536916">The dynamic table refresh process operates in one of two ways:

Incremental refresh:
 This automated process analyzes the dynamic table’s query and calculates changes since the last refresh. It then merges these changes into the table. See Supported queries in incremental refresh
 for details on supported queries.

Full refresh:
 When the automated process can’t perform an incremental refresh, it conducts a full refresh. This involves executing the query for the dynamic table and completely replacing the previous materialized results.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536923">Snowflake schedules refreshes to keep the actual lag of your dynamic tables below their target lag. The duration of each refresh depends on the query, data pattern, and warehouse size. When choosing a target lag, consider the time needed to refresh each dynamic table in a chain
 to the root. If you don’t, some refreshes might be skipped, leading to a higher actual lag.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536938">Target lag is specified in one of following ways:

Measure of freshness
: Defines the maximum amount of time that the dynamic table’s content should lag behind updates to the base tables.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536943">Downstream
: Specifies that the dynamic table should refresh on demand when other dependent dynamic tables refresh. This refresh can be triggered by a manual or scheduled refresh of a downstream dynamic table.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-comparison" ADD_DATE="1723536893" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-comparison" DATA-IMPORTANT="false">Dynamic tables compared to streams and tasks and to materialized views | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536893">Dynamic tables are designed to build multi-level data pipelines.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536897">Materialized views are designed to improve query performance transparently.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-create" ADD_DATE="1723536807" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-create" DATA-IMPORTANT="false">Create dynamic tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536807">Before you begin, ensure you have the privileges for creating dynamic tables
, and all objects used by the dynamic table query have change tracking
 enabled.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536824">Snowflake automatically attempts to enable change tracking on them.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536830">Snowflake doesn’t automatically attempt to enable change tracking on dynamic tables created with full refresh mode.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-manage" ADD_DATE="1723536701" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-manage" DATA-IMPORTANT="false">About managing dynamic tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536701">Dynamic tables are shareable objects.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536716">A dynamic table is suspended if the system observes five continuous refresh errors.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-best-practices" ADD_DATE="1723536667" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-best-practices" DATA-IMPORTANT="false">Best practices for dynamic tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536667">If a grouping key contains a compound expression rather than a base column, materialize the expression in one dynamic table and then apply the grouping operation on the materialized column in another dynamic table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536675">Dynamic tables can be used to implement Type 1 and 2 slowly changing dimensions (SCDs)</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536684">By default, dynamic table data is retained for 7 days in fail-safe
 storage. For dynamic tables with high refresh throughput, this can significantly increase storage consumption. Therefore, you should make a dynamic table transient only if its data doesn’t need the same level of data protection and recovery provided by permanent tables.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-limitations" ADD_DATE="1723536627" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-limitations" DATA-IMPORTANT="false">Known limitations for dynamic tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536627">You can’t create a temporary dynamic table.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536634">You can’t set the DATA_RETENTION_TIME_IN_DAYS
 object parameter in your source tables to zero.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536642">The following constructs are not currently supported in the query for a dynamic table. If you specify these in the query, an error occurs:

External functions
.

Sequences
.

Functions that rely on CURRENT_USER
. Dynamic table refreshes act as their owner role with a special SYSTEM user.

Sources that include directory tables, external tables, streams, and materialized views.

Views on dynamic tables or other unsupported objects.

User-defined functions (UDFs and UDTFs) written in SQL and containing a subquery.

UNPIVOT
 constructs are not supported in dynamic table incremental or full refresh.

SAMPLE / TABLESAMPLE
 constructs are not supported in dynamic table incremental or full refresh.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536650">Non-deterministic functions are not supported with incremental refreshes, but some non-deterministic functions are supported with full refreshes
.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-performance-refresh-mode" ADD_DATE="1723536610" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-performance-refresh-mode" DATA-IMPORTANT="false">How refresh mode affects dynamic table performance | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536610">As an extreme example, consider the effect of deleting all of the data from a source: a full refresh just sees an empty table, which can be processed very quickly. In contrast, an incremental refresh has to process every deleted row, making it much slower.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-performance-warehouses" ADD_DATE="1723536594" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-performance-warehouses" DATA-IMPORTANT="false">How warehouse configurations affect dynamic table performance | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536594">If your dynamic tables refresh incrementally, the initial refresh
 often requires a larger warehouse than subsequent refreshes. Adjust your workflow by starting with a larger warehouse size, creating your dynamic tables, and then sizing down the warehouse again.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/dynamic-tables-troubleshooting" ADD_DATE="1723536577" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdynamic-tables-troubleshooting" DATA-IMPORTANT="false">Troubleshooting dynamic tables | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536577">My dynamic table is reinitializing.

	

Your dynamic table might be reinitializing due to one of the following reasons:

One or more of the inputs of the dynamic table are replaced. For example, if your dynamic table is defined on a view, and you replace the view, the dynamic table has to reinitialize.

If the schema of the inputs changed and your dynamic table relies on the changed columns.

Data access policies
 are added, removed, or changed on the dynamic table’s inputs.

Cloned incremental dynamic tables
 might need to reinitialize on their first refresh after being created.

Replicated dynamic tables
 with incremental refresh reinitialize after failover before they can resume incremental refresh.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/streams-intro" ADD_DATE="1723536328" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fstreams-intro" DATA-IMPORTANT="false">Introduction to Streams | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536328">Streams can be created to query change data on the following objects:

Standard tables, including shared tables.

Views, including secure views

Directory tables

Dynamic tables

Iceberg tables
 with Limitations
.

Event tables

External tables</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536337">The change tracking system utilized by the stream then records information about the DML changes after this snapshot was taken. Change records provide the state of a row before and after the change.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536345">When the first stream for a table is created, several hidden columns are added to the source table and begin storing change tracking metadata. These columns consume a small amount of storage.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536352">Note that for streams on views, change tracking must be enabled explicitly for the view and underlying tables to add the hidden columns to these tables.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536361">Querying a stream alone does not advance its offset, even within an explicit transaction; the stream contents must be consumed in a DML statement.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536368">To ensure multiple statements access the same change records in the stream, surround them with an explicit transaction statement (BEGIN
 .. COMMIT
).</mark>
		<DD><mark COLOR="green" ADD_DATE="1723536388">When queried, a stream accesses and returns the historic data in the same shape as the source object (i.e. the same column names and ordering) with the following additional columns:

METADATA$ACTION:

Indicates the DML operation (INSERT, DELETE) recorded.

METADATA$ISUPDATE:

Indicates whether the operation was part of an UPDATE statement. Updates to rows in the source object are represented as a pair of DELETE and INSERT records in the stream with a metadata column METADATA$ISUPDATE values set to TRUE.

Note that streams record the differences between two offsets. If a row is added and then updated in the current offset, the delta change is a new row. The METADATA$ISUPDATE row records a FALSE value.

METADATA$ROW_ID:

Specifies the unique and immutable ID for the row, which can be used to track changes to specific rows over time.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536397">Snowflake provides the following guarantees with respect to METADATA$ROW_ID:

The METADATA$ROW_ID depends on the stream’s source object.

For instance, a stream stream1
 on table table1
 and stream stream2
 on table table1
 produce the same METADATA$ROW_IDs for the same rows, but a stream stream_view
 on view view1
 is not guaranteed to produce the same METADATA$ROW_IDs as stream1
, even if view
 is defined using the statement CREATE
 VIEW
 view
 AS
 SELECT
 *
 FROM
 table1
.

A stream on a source object and a stream on the source object’s clone produce the same METADATA$ROW_IDs for the rows that exist at the time of the cloning.

A stream on a source object and a stream on the source object’s replica produce the same METADATA$ROW_IDs for the rows that were replicated.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536412">Standard:

Supported for streams on standard tables, dynamic tables, Snowflake-managed Iceberg tables, directory tables, or views.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536422">Types of Streams¶

The following stream types are available based on the metadata recorded by each:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536429">Standard streams cannot retrieve change data for geospatial data. We recommend creating append-only streams on objects that contain geospatial data.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536443">Append-only:

Supported for streams on standard tables, dynamic tables, Snowflake-managed Iceberg tables, or views.
 An append-only stream exclusively tracks row inserts. Update, delete, and truncate operations are not captured by append-only streams.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536450">Insert-only:

Supported for streams on dynamic tables, Iceberg tables, or external tables.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536466">A stream becomes stale when its offset falls outside of the data retention period for its source table</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536473">To continue tracking new change records, you must recreate the stream using the CREATE STREAM
 command.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536486">This restriction doesn’t apply to streams on directory tables or external tables, which have no data retention period.

In addition, streams on shared tables or views don’t extend the data retention period for the table or underlying tables, respectively.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536492">If the data retention period for a table is less than 14 days and a stream hasn’t been consumed, Snowflake temporarily extends this period to prevent the stream from going stale. The retention period is extended to the stream’s offset, up to a maximum of 14 days by default, regardless of your Snowflake edition
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536505">Recreating an object (using the CREATE OR REPLACE TABLE syntax) drops its history, which also makes any stream on the table or view stale. In addition, recreating or dropping any of the underlying tables for a view makes any stream on the view stale.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536509">Renaming a source object does not break a stream or cause it to go stale. In addition, if a source object is dropped and a new object is created with the same name, any streams linked to the original object are not
 linked to the new object.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536518">We recommend that users create a separate stream for each consumer of change records for an object. “Consumer” refers to a task, script, or other mechanism that consumes the change records for an object using a DML transaction.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536525">Streams on views support both local views and views shared using Snowflake Secure Data Sharing, including secure views. Currently, streams cannot track changes in materialized views.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536535">Views with the following operations are not yet supported:

GROUP BY clauses

QUALIFY clauses

Subqueries not in the FROM clause

Correlated subqueries

LIMIT clauses

DISTINCT clauses

Functions:

Functions in the select list must be system-defined, scalar functions.</mark>
		<DD><mark COLOR="green" ADD_DATE="1723551377">A stream object records data manipulation language (DML) changes made to tables, including inserts, updates, and deletes, as well as metadata about each change, so that actions can be taken using the changed data. This process is referred to as change data capture (CDC).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tasks-intro" ADD_DATE="1723536236" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftasks-intro" DATA-IMPORTANT="false">Introduction to tasks | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536236">The maximum compute size for a serverless task is equivalent to an XXLARGE user-managed virtual warehouse.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536245">To avoid unexpected task executions due to daylight saving time, consider the following:

Don’t schedule tasks to run between 1 AM and 3 AM.

Manually adjust the cron expression for tasks scheduled between 1 AM and 3 AM twice each year to compensate for the time change.

Use a time format that does not apply daylight savings time, such as UTC.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536259">Triggered Tasks considerations¶

The following are details about managing, configuring, and monitoring Triggered Tasks:

In the SHOW
 TASKS
 and DESC
 TASK
 output, the SCHEDULE
 property displays NULL
 for Triggered Tasks.

In the output of the task_history view of the information_schema and account_usage schemas, the SCHEDULED_FROM column displays TRIGGER.

If the stream or table that the stream is tracking is dropped or re-created, the triggered task automatically suspends. After the table or stream is re-created, the user can run ALTER
 TASK
 &lt;task_name&gt;
 RESUME
 to resume triggered processing.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536267">Triggered Tasks Limitations¶

The following are limitations of Triggered Tasks:

Streams on Data Shares, Directory Tables, External Tables, and Hybrid Tables are not supported.

Serverless Tasks are not supported.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536276">To retrieve the history of task versions, query TASK_VERSIONS
 Account Usage view
 (in the SNOWFLAKE shared database).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536283">If any task completes in a FAILED state, Snowflake can automatically retry the task. The automatic task retry is disabled by default. To enable this feature, set TASK_AUTO_RETRY_ATTEMPTS to a value greater than 0.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536291">You can set session parameters for the session in which a task runs. To do so, modify an existing task and set the desired parameter values using ALTER TASK
 … SET
 session_parameter
 =
 value
[,
 session_parameter
 =
 value
 ...
 ]
 or edit the task in Snowsight.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536303">Viewing task history¶

To view tasks, you must have one or more of the following privileges:

The ACCOUNTADMIN role

The OWNERSHIP privilege on the task

The global MONITOR EXECUTION privilege</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536311">Drop a task owner role¶

When you delete the owner role of a task, the task transfers ownership to the role that dropped the owner role. When a task transfers ownership, it is automatically paused and new executions aren’t scheduled until the new owner resumes the task.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723637052">A task can execute any one of the following types of functions:

Single SQL statement

Call to a stored procedure

Procedural logic using Snowflake Scripting</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/tasks-graphs" ADD_DATE="1723536204" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Ftasks-graphs" DATA-IMPORTANT="false">Manage task dependencies with task graphs | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536204">When you transfer ownership of the tasks in a task graph using these methods, the tasks in the task graph retain their relationships to each other.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536217">The behavior is controlled by the ALLOW_OVERLAPPING_EXECUTION parameter on the root task; the default value is FALSE. Setting the parameter value to TRUE permits task graph runs to overlap.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723550655">Task graph considerations

A task graph is limited to a maximum of 1000 tasks.

A single task can have a maximum of 100 parent tasks and 100 child tasks.

The compute running the task graph must be sized to handle concurrent task runs. For more information see, Compute resources.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-joins" ADD_DATE="1723536187" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-joins" DATA-IMPORTANT="false">Working with Joins | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536187">If two tables have multiple columns in common, then all the common columns are used in the ON
 clause.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-subqueries" ADD_DATE="1723536164" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-subqueries" DATA-IMPORTANT="false">Working with Subqueries | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536164">A subquery is a query within another query. Subqueries in a FROM
 or WHERE
 clause are used to provide data that will be used to limit or compare/evaluate the data returned by the containing query.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723568575">Snowflake currently supports the following types of subqueries:

Uncorrelated scalar subqueries in any place that a value expression can be used.

Correlated scalar subqueries in WHERE clauses.

EXISTS, ANY / ALL, and IN subqueries in WHERE clauses. These subqueries can be correlated or uncorrelated.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/queries-hierarchical" ADD_DATE="1723536148" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fqueries-hierarchical" DATA-IMPORTANT="false">Querying Hierarchical Data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536148">This topic describes how to store and query hierarchical data using:

JOINs

Recursive CTEs (common table expressions)

CONNECT BY</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723624632">Snowflake provides two ways to query hierarchical data in which the number of levels is not known in advance:

Recursive CTEs (common table expressions).

CONNECT BY clauses.

A recursive CTE allows you to create a WITH clause that can refer to itself. This lets you iterate through each level of your hierarchy and accumulate results.

A CONNECT BY clause allows you to create a type of JOIN operation that processes the hierarchy one level at a time, and allows each level to refer to data in the prior level.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-construct-at-runtime" ADD_DATE="1723536122" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-construct-at-runtime" DATA-IMPORTANT="false">Constructing SQL at runtime | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536122">The following techniques are available for constructing SQL statements dynamically at runtime:

The TO_QUERY function
 - This function takes a SQL string with optional parameters as input.

Dynamic SQL
 - Code in a stored procedure or application takes input and constructs a dynamic SQL statement using this input. The code can be part of a Snowflake Scripting
 or Javascript
 stored procedure, or a Snowflake Scripting anonymous block. You can also use this technique in your application code that uses a Snowflake driver
 or the Snowflake SQL REST API
.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/querying-time-series-data" ADD_DATE="1723536098" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fquerying-time-series-data" DATA-IMPORTANT="false">Analyzing time-series data | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536098">You can downsample a data set that is stored in a table by using the TIME_SLICE function. This function calculates the start and end times of fixed-width “buckets” so that individual records can be grouped and summarized, using standard aggregate functions, such as SUM and AVG.

Similarly, the DATE_TRUNC
 function truncates part of a series of date or timestamp values, reducing their granularity.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/ui-snowsight-activity" ADD_DATE="1723536078" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fui-snowsight-activity" DATA-IMPORTANT="false">Monitor query activity with Query History | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536078">Common query problems identified by Query Profile¶

This section describes some of the problems you can identify and troubleshoot using Query Profile.

“Exploding” joins¶

One of the common mistakes SQL users make is joining tables without providing a join condition (resulting in a “Cartesian product”), or providing a condition where records from one table match multiple records from another table. For such queries, the Join
 operator produces significantly (often by orders of magnitude) more tuples than it consumes.

This can be observed by looking at the number of records produced by a Join
 operator, and typically is also reflected in Join
 operator consuming a lot of time.

UNION without ALL¶

In SQL, it is possible to combine two sets of data with either UNION or UNION ALL constructs. The difference between them is that UNION ALL simply concatenates inputs, while UNION does the same, but also performs duplicate elimination.

A common mistake is to use UNION when the UNION ALL semantics are sufficient. These queries show in Query Profile as a UnionAll
 operator with an extra Aggregate
 operator on top (which performs duplicate elimination).

Queries too large to fit in memory¶

For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the servers used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling
 the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.

This spilling can have a profound effect on query performance (especially if remote disk is used for spilling). To alleviate this, we recommend:

Using a larger warehouse (effectively increasing the available memory/local disk space for the operation), and/or

Processing data in smaller batches.

Inefficient pruning¶

Snowflake collects rich statistics on data allowing it not to read unnecessary parts of a table based on the query filters. However, for this to have an effect, the data storage order needs to be correlated with the query filter attributes.

The efficiency of pruning can be observed by comparing Partitions scanned
 and Partitions total
 statistics in the TableScan
 operators. If the former is a small fraction of the latter, pruning is efficient. If not, the pruning did not have an effect.

Of course, pruning can only help for queries that actually filter out a significant amount of data. If the pruning statistics do not show data reduction, but there is a Filter
 operator above TableScan
 which filters out a number of records, this might signal that a different data organization might be beneficial for this query.

For more information about pruning, see Understanding Snowflake Table Structures
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723703043">To monitor query activity in your account, you can use:

The Query History page in Snowsight.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723798813">With the Query History page in Snowsight, you can do the following:

Monitor queries executed by users in your account.

View details about queries, including performance data. In some cases, query details are unavailable.

Explore each step of an executed query in the query profile.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/guides-overview-sharing" ADD_DATE="1723536055" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fguides-overview-sharing" DATA-IMPORTANT="false">Data sharing and collaboration in Snowflake | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536055">Direct share¶

Use a direct share to share data with one or more accounts in the same Snowflake region. You don’t need to copy or move data shared with a direct share.</mark>
		<DT><A HREF="https://other-docs.snowflake.com/en/collaboration/provider-becoming" ADD_DATE="1723536015" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fother-docs.snowflake.com%2Fen%2Fcollaboration%2Fprovider-becoming" DATA-IMPORTANT="false">About listing providers | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723536015">If your account is in a U.S. government region, you must also accept the cross-region disclaimer.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536023">To offer paid listings or any listings on the Snowflake Marketplace, you must create a provider profile and have it approved by Snowflake.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723536030">To offer paid listings, you must set up a Stripe account to get paid for listings.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-overview" ADD_DATE="1723535893" LAST_MODIFIED="1730207936" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-overview" DATA-IMPORTANT="false">Overview of Access Control | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535893">Discretionary Access Control (DAC):
 Each object has an owner, who can in turn grant access to that object.

Role-based Access Control (RBAC):
 Access privileges are assigned to roles, which are in turn assigned to users.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535911">Securable object:
 An entity to which access can be granted. Unless allowed by a grant, access is denied</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535927">There are a small number of system-defined roles
 in a Snowflake account. System-defined roles cannot be dropped. In addition, the privileges granted to these roles by Snowflake cannot be revoked.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535939">SECURITYADMIN:

(aka Security Administrator)

Role that can manage any object grant globally, as well as create, monitor, and manage users and roles</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535945">ACCOUNTADMIN:

(aka Account Administrator)

Role that encapsulates the SYSADMIN and SECURITYADMIN system-defined roles. It is the top-level role in the system and should be granted only to a limited/controlled number of users in your account.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535955">USERADMIN:

(aka User and Role Administrator)

Role that is dedicated to user and role management only.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535966">Role hierarchy and privilege inheritance</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535996">If a role was specified as part of the connection and that role is a role that has already been granted to the connecting user, the specified role becomes the current role.

If no role was specified and a default role has been set for the connecting user, that role becomes the current role.

If no role was specified and a default role has not been set for the connecting user, the system role PUBLIC is used.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723639587">To own an object means that a role has the OWNERSHIP privilege on the object.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723706197">in a managed access schema, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/intro-summary-data-types" ADD_DATE="1723535863" LAST_MODIFIED="1730207941" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fintro-summary-data-types" DATA-IMPORTANT="false">Summary of data types | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535863">FLOAT, FLOAT4, FLOAT8

	

[1]




DOUBLE, DOUBLE PRECISION, REAL

	

Synonymous with FLOAT. [1]</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723705547">VARCHAR

	

Default (and maximum) is 16,777,216 bytes.




CHAR, CHARACTER

	

Synonymous with VARCHAR except default length is VARCHAR(1).




STRING

	

Synonymous with VARCHAR.




TEXT

	

Synonymous with VARCHAR.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/session-policies" ADD_DATE="1723535821" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsession-policies" DATA-IMPORTANT="false">Snowflake Sessions &amp; Session Policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535821">A session policy defines the idle
 session timeout period in minutes and provides the option to override the default idle timeout value. The timeout period begins upon a successful authentication to Snowflake. The minimum configurable idle timeout value for a session policy is 5
 minutes.

If a session policy is not set, Snowflake uses a default value of 240
 minutes (four hours).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/security-access-control-privileges" ADD_DATE="1723535774" LAST_MODIFIED="1730207944" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsecurity-access-control-privileges" DATA-IMPORTANT="false">Access control privileges | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535774">CREATE &lt;object_type&gt;

	

Global, Database, Schema

	

Grants the ability to create an object of &lt;object_type&gt;
 (e.g. CREATE TABLE grants the ability to create a table within a schema).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723566615">Grants the ability to drop, alter, and grant or revoke access to an object. Required to rename an object and create a temporary object with the same name as the object itself. OWNERSHIP is a special privilege on an object that is automatically granted to the role that created the object, but can also be transferred using the GRANT OWNERSHIP command to a different role by the owning role or any role with the MANAGE GRANTS privilege.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723566618">OWNERSHIP</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723705348">ADD SEARCH OPTIMIZATION

	

Enables adding search optimization to a table in a schema.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/parameters" ADD_DATE="1723535679" LAST_MODIFIED="1730207950" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fparameters" DATA-IMPORTANT="false">Parameters | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535679">ALLOW_CLIENT_MFA_CACHING</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535702">Type:

Account — Can only be set for Account</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704134">ABORT_DETACHED_QUERY</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704137">Specifies the action that Snowflake performs for in-progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704143">TRUE: In-progress queries are aborted 5 minutes after connectivity is lost.

FALSE: In-progress queries are completed.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704150">When the value is set to FALSE, asynchronous queries continue to run until they complete, until they are canceled, or until the time limit specified for the STATEMENT_TIMEOUT_IN_SECONDS parameter expires. The default for the STATEMENT_TIMEOUT_IN_SECONDS parameter is two days.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723704694">Values:

0 to 604800 (i.e. 7 days) — a value of 0 specifies that the maximum timeout value is enforced.

Default:

172800 (i.e. 2 days)</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/data-time-travel" ADD_DATE="1723535642" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fdata-time-travel" DATA-IMPORTANT="false">Understanding &amp; using Time Travel | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535642">The standard retention period is 1 day (24 hours) and is automatically enabled for all Snowflake accounts:</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723560052">To support Time Travel, the following SQL extensions have been implemented:

AT | BEFORE clause which can be specified in SELECT statements and CREATE … CLONE commands</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723560056">UNDROP command for tables, schemas, and databases.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723565458">Snowflake Time Travel enables accessing historical data (i.e. data that has been changed or deleted) at any point within a defined period. It serves as a powerful tool for performing the following tasks:

Restoring data-related objects (tables, schemas, and databases) that might have been accidentally or intentionally deleted.

Duplicating and backing up data from key points in the past.

Analyzing data usage/manipulation over specified periods of time.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723797915">The MIN_DATA_RETENTION_TIME_IN_DAYS account parameter can be set by users with the ACCOUNTADMIN role to set a minimum retention period for the account. This parameter does not alter or replace the DATA_RETENTION_TIME_IN_DAYS parameter value. However it may change the effective data retention time. When this parameter is set at the account level, the effective minimum data retention period for an object is determined by MAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS).</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/use-secondary-roles" ADD_DATE="1723535596" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fuse-secondary-roles" DATA-IMPORTANT="false">USE SECONDARY ROLES | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535596">Note that authorization to execute CREATE &lt;object&gt;
 statements to create objects is provided by the primary role.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/sql-reference/sql/desc-user" ADD_DATE="1723535579" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fsql-reference%2Fsql%2Fdesc-user" DATA-IMPORTANT="false">DESCRIBE USER | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535579">The user object property MINS_TO_BYPASS_NETWORK_POLICY
 defines the number of minutes in which a user can access Snowflake without conforming to an existing network policy
. The number of minutes can only be set by Snowflake (Default: NULL
) and is intended as a temporary workaround to allow user access to Snowflake. To set a value for this property, please contact Snowflake Support
.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/snowsql-start" ADD_DATE="1723535523" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fsnowsql-start" DATA-IMPORTANT="false">Connecting through SnowSQL | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535523">Connection syntax¶
$ 
snowsql 
&lt;connection_parameters&gt;


Where &lt;connection_parameters&gt;
 are one or more of the following. For detailed descriptions of each parameter, see Connection parameters reference
 (in this topic).

Parameter

	

Description




-a,
 --accountname
 TEXT

	

Your account identifier. Honors $SNOWSQL_ACCOUNT.




-u,
 --username
 TEXT

	

Username to connect to Snowflake. Honors $SNOWSQL_USER.




-d,
 --dbname
 TEXT

	

Database to use. Honors $SNOWSQL_DATABASE.




-s,
 --schemaname
 TEXT

	

Schema in the database to use. Honors $SNOWSQL_SCHEMA.




-r,
 --rolename
 TEXT

	

Role name to use. Honors $SNOWSQL_ROLE.




-w,
 --warehouse
 TEXT

	

Warehouse to use. Honors $SNOWSQL_WAREHOUSE.




-h,
 --host
 TEXT

	

Host address for the connection. Honors $SNOWSQL_HOST. (Deprecated)




-p,
 --port
 INTEGER

	

Port number for the connection. Honors $SNOWSQL_PORT. (Deprecated)




--region
 TEXT

	

Region. Honors $SNOWSQL_REGION. (Deprecated; use -a or –accountname instead)




-m,
 --mfa-passcode
 TEXT

	

Token to use for multi-factor authentication (MFA)




--mfa-passcode-in-password

	

Appends the MFA passcode to the end of the password.




--abort-detached-query

	

Aborts a query if the connection between the client and server is lost. By default, it won’t abort even if the connection is lost.




--probe-connection

	

Test connectivity to Snowflake. This option is mainly used to print out the TLS (Transport Layer Security) certificate chain.




--proxy-host
 TEXT

	

(DEPRECATED. Use HTTPS_PROXY and HTTP_PROXY environment variables.) Proxy server hostname. Honors $SNOWSQL_PROXY_HOST.




--proxy-port
 INTEGER

	

(DEPRECATED. Use HTTPS_PROXY and HTTP_PROXY environment variables.) Proxy server port number. Honors $SNOWSQL_PROXY_PORT.




--proxy-user
 TEXT

	

(DEPRECATED. Use HTTPS_PROXY and HTTP_PROXY environment variables.) Proxy server username. Honors $SNOWSQL_PROXY_USER. Set $SNOWSQL_PROXY_PWD for the proxy server password.




--authenticator
 TEXT

	

Authenticator: ‘snowflake’, ‘externalbrowser’ (to use any IdP and a web browser), https:/
/&lt;okta_account_name&gt;.okta.com (to use Okta natively), or ‘oauth’ to authenticate using OAuth.




-v,
 --version

	

Shows the current SnowSQL version, or uses a specific version if provided as a value.




--noup

	

Disables auto-upgrade for this run. If no version is specified for -v, the latest version in ~/.snowsql/ is used.




-D,
 --variable
 TEXT

	

Sets a variable to be referred by &amp;&lt;var&gt;. -D tablename=CENUSTRACKONE or –variable db_key=$DB_KEY




-o,
 --option
 TEXT

	

Set SnowSQL options. See the options reference in the Snowflake documentation.




-f,
 --filename
 PATH

	

File to execute.




-q,
 --query
 TEXT

	

Query to execute.




--query_tags
 TEXT

	

Tags to use when running queries. By default, --query_tag
 reads the value of the SNOWSQL_QUERY_TAG
 environment variable.




--config
 PATH

	

Path and name of the SnowSQL configuration file. By default, ~/.snowsql/config.




-P,
 --prompt

	

Forces an interactive password prompt
 to allow you to specify a password that differs from the one stored in the $SNOWSQL_PWD environment variable.




-M,
 --mfa-prompt

	

Forces a prompt for the second token for MFA.




-c,
 --connection
 TEXT

	

Named set of connection parameters to use.




--single-transaction

	

Connects with autocommit disabled. Wraps BEGIN/COMMIT around statements to execute them as a single transaction, ensuring all commands complete successfully or no change is applied.




--private-key-path
 PATH

	

Path to private key file.




--disable-request-pooling

	

Disables connection pooling.




-U,
 --upgrade

	

Force upgrade of SnowSQL to the latest version.




-K,
 --client-session-keep-alive

	

Keep the session active indefinitely, even if there is no activity from the user.




--include_connector_version

	

Display the version of the Snowflake Connector for Python software that is packaged in the SnowSQL binary.




-?,
 --help

	

Show this message and exit.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570755">-a, --accountname TEXT

	

Your account identifier. Honors $SNOWSQL_ACCOUNT.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723570760">-d, --dbname TEXT

	

Database to use. Honors $SNOWSQL_DATABASE.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/identifier-first-login" ADD_DATE="1723535496" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fidentifier-first-login" DATA-IMPORTANT="false">Identifier-first login | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535496">An identifier-first login reduces confusion and login issues by only showing users’ valid authentication options.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535503">A user with the ACCOUNTADMIN role can use the ENABLE_IDENTIFIER_FIRST_LOGIN
 parameter to enable the identifier-first login flow for an account. For example:</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/authentication-policies" ADD_DATE="1723535408" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fauthentication-policies" DATA-IMPORTANT="false">Authentication policies | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535408">Authentication policies provide you with control over how a client or user authenticates by allowing you to specify:

Whether users must enroll in multi-factor authentication (MFA)
.

Which authentication methods require multi-factor authentication.

The allowed authentication methods, such as SAML
, passwords, OAuth
, or Key pair authentication
.

The SAML2 security integrations
 that are available to users during the login experience. For example, if there are multiple security integrations, you can specify which identity provider (IdP) can be selected and used to authenticate.

If you are using authentication policies to control which IdP a user can use to authenticate, you can further refine that control using the ALLOWED_USER_DOMAINS
 and ALLOWED_EMAIL_PATTERNS
 properties of the SAML2 security integrations associated with the IdPs. For more details, see Using multiple identity providers for federated authentication
.

The clients that users can use to connect to Snowflake, such as Snowsight
, drivers
, or SnowSQL (CLI client)
. The CLIENT_TYPES
 property of an authentication policy is a best effort method to block user logins based on specific clients. It should not be used as the sole control to establish a security boundary.

You can set authentication policies on the account or users in the account. If you set an authentication policy on the account, then the authentication policy applies to all users in the account. If you set an authentication policy on both an account and a user, then the user-level authentication policy overrides the account-level authentication policy.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535417">Ensure authentication methods and security integrations listed in your authentication policies do not conflict. For example, if you add a SAML2 security integration in the list of allowed security integrations, and you only allow OAuth as an allowed authentication method, then you cannot create an authentication policy.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535424">The following list describes the order in which security policies are evaluated:

Network policies
: Allow or deny IP addresses, VPC IDs, and VPCE IDs.

Authentication policies - Allow or deny clients, authentication methods, and security integrations.

Password policies
 (For local authentication only): Specify password requirements such as character length, characters, password age, retries, and lockout time.

Session policies
: Require users to re-authenticate after a period of inactivity

If a policy is assigned to both the account and the user authenticating, the user-level policy is enforced.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535438">An administrator can use the CREATE AUTHENTICATION POLICY
 command to create a new authentication policy, specifying which clients can connect to Snowflake, which authentication methods can be used, and which security integrations are available to users.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535445">You can use the ALTER ACCOUNT
 or ALTER USER
 commands to set an authentication policy on an account or user.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535454">Only a security administrator (a user with the SECURITYADMIN role) or users with a role that has the APPLY AUTHENTICATION POLICY privilege can set authentication policies on accounts or users.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535461">If you set the MFA_ENROLLMENT
 parameter to REQUIRED
, then the CLIENT_TYPES
 parameter must include SNOWFLAKE_UI
, because Snowsight is the only place users can enroll in multi-factor authentication (MFA)
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535474">CREATE

	

Enables creating a new authentication policy in a schema.




APPLY AUTHENTICATION POLICY

	

Enables applying an authentication policy at the account or user level.




OWNERSHIP

	

Grants full control over the authentication policy. Required to alter most properties of an authentication policy.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/api-authentication" ADD_DATE="1723535294" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fapi-authentication" DATA-IMPORTANT="false">External API authentication and secrets | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723535325">External API authentication provides a pathway to authenticate to a service that is hosted outside of Snowflake. The API request to access the service requires the API request to be authenticated. Snowflake supports the following methods of authentication while using External API Authentication:

Basic authentication.

OAuth with code grant flow.

OAuth with client credentials flow.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535333">A secret is a schema-level object that stores sensitive information, limits access to the sensitive information using RBAC
, and is encrypted using the Snowflake key encryption hierarchy
.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535347">After you create a secret, only dedicated Snowflake components such as integrations and external functions can read the sensitive information.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview" ADD_DATE="1723534879" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fadmin-security-fed-auth-overview" DATA-IMPORTANT="false">Overview of federated authentication and SSO | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723534879">In a federated environment, user authentication is separated from user access through the use of one or more external entities that provide independent authentication of user credentials.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535092">A federated environment consists of the following components:

Service provider (SP):

In a Snowflake federated environment, Snowflake serves as the SP.

Identity provider (IdP):

The external, independent entity responsible for providing the following services to the SP:

Creating and maintaining user credentials and other profile information.

Authenticating users for SSO access to the SP.

Snowflake supports most
 SAML 2.0-compliant vendors as an IdP; however, certain vendors include native support for Snowflake (see below for details).</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535100">The following vendors provide native
 Snowflake support for federated authentication and SSO:

Okta
 — hosted service

Microsoft AD FS
 (Active Directory Federation Services) — on-premises software (installed on Windows Server)</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535108">Note

To use an IdP other than Okta or AD FS, you must define a custom application for Snowflake in the IdP.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535115">Currently, only a subset of Snowflake drivers support the use of multiple identity providers. These drivers include JDBC, ODBC, and Python.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535133">Federated authentication enables the following SSO workflows:

Logging into Snowflake.

Logging out of Snowflake.

System timeout due to inactivity.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535141">When a user logs out, the available options are dictated by whether the IdP supports global
 logout or only standard
 logout:

Standard:

Requires users to explicitly log out of both the IdP and Snowflake to completely disconnect. All IdPs support standard logout.

Global:

Enables a user to log out of the IdP and subsequently all their Snowflake sessions. Support for global logout is IdP-dependent.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535152">In addition, the behavior of the system is determined by whether the logout is initiated through Snowflake or the IdP:

Snowflake-initiated logout:

Global logout is not supported from within Snowflake, regardless of whether the IdP supports it. When a user logs out of a Snowflake session, they are logged out of that session only. All their other current Snowflake sessions stay open, as does their IdP session. As a result, they can continue working in their other sessions or they can initiate additional sessions without having to re-authenticate through the IdP.

To completely disconnect, users must explicitly log out of both Snowflake and the IdP.

IdP-initiated logout:

When a user logs out through an IdP, the behavior depends on whether the IdP supports standard logout only or also global logout:

AD FS supports both standard and global logout. If global logout is enabled, the AD FS IdP login page provides an option for signing out from all sites that the user has accessed. Selecting this option and clicking Sign Out
 logs the user out of AD FS and all their Snowflake sessions. To access Snowflake again, they must re-authenticate using AD FS.

Okta supports standard logout only. When a user logs out of Okta, they are not automatically logged out of any of their active Snowflake sessions and they can continue working. However, to initiate any new Snowflake sessions, they must authenticate again through Okta.

All custom providers support standard logout; support for global logout varies by provider.

Note

For a web-based IdP (e.g. Okta), closing the browser tab/window does not necessarily end the IdP session. If a user’s IdP session is still active, they can still access Snowflake until the IdP session times out.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535162">Snowflake supports SSO with private connectivity to the Snowflake service for Snowflake accounts on Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP).

Currently, for any given Snowflake account, SSO works with only one account URL at a time: either the public account URL or the URL associated with the private connectivity service on AWS, Microsoft Azure, or Google Cloud Platform.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535168">Snowflake supports replication and failover/failback of the SAML2 security integration
 from a source account to a target account.</mark>
		<DD><mark COLOR="green" ADD_DATE="1723535239">Federated authentication enables the following SSO workflows:

Logging into Snowflake.

Logging out of Snowflake.

System timeout due to inactivity.

The behavior for each workflow is determined by whether the action is initiated within Snowflake or your IdP.</mark>
		<DT><A HREF="https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-use" ADD_DATE="1723534852" LAST_MODIFIED="1730143863" TAGS="" DATA-COVER="https://rdl.ink/render/https%3A%2F%2Fdocs.snowflake.com%2Fen%2Fuser-guide%2Fadmin-security-fed-auth-use" DATA-IMPORTANT="false">Managing/Using federated authentication | Snowflake Documentation</A>
		<DD><mark COLOR="yellow" ADD_DATE="1723534852">With federated authentication enabled for your account, Snowflake still allows maintaining and using Snowflake user credentials (login name and password). In other words:

Account and security administrators can still create users with passwords maintained in Snowflake.

Users can still log into Snowflake using their Snowflake credentials.

However, if federated authentication is enabled for your account, Snowflake does not
 recommend maintaining user passwords in Snowflake. Instead, user passwords should be maintained solely in your IdP.</mark>
		<DD><mark COLOR="yellow" ADD_DATE="1723535042">Specifically, we recommend that you disable Snowflake authentication for all non-administrator users.</mark>
	</DL><p>
</DL><p>